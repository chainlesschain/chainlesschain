/**
 * OpenAI å…¼å®¹ API å®¢æˆ·ç«¯
 *
 * æ”¯æŒ: OpenAI, DeepSeek, ä»¥åŠå…¶ä»–å…¼å®¹OpenAI APIçš„æœåŠ¡
 */

const { logger } = require("../utils/logger.js");
const axios = require("axios");
const EventEmitter = require("events");

/**
 * OpenAIå…¼å®¹å®¢æˆ·ç«¯ç±»
 */
class OpenAIClient extends EventEmitter {
  constructor(config = {}) {
    super();

    // APIé…ç½®
    this.apiKey = config.apiKey;
    this.baseURL = config.baseURL || "https://api.openai.com/v1";
    this.model = config.model || "gpt-3.5-turbo";
    this.embeddingModel = config.embeddingModel || "text-embedding-ada-002";
    this.timeout = config.timeout || 120000;
    this.organization = config.organization;

    // åˆ›å»ºaxioså®ä¾‹
    this.client = axios.create({
      baseURL: this.baseURL,
      timeout: this.timeout,
      headers: {
        "Content-Type": "application/json",
        ...(this.apiKey && { Authorization: `Bearer ${this.apiKey}` }),
        ...(this.organization && { "OpenAI-Organization": this.organization }),
      },
    });
  }

  /**
   * æ£€æŸ¥æœåŠ¡çŠ¶æ€
   */
  async checkStatus() {
    try {
      // ç«å±±å¼•æ“ç‰¹æ®Šå¤„ç†ï¼šä½¿ç”¨ç®€å•çš„èŠå¤©æµ‹è¯•ä»£æ›¿æ¨¡å‹åˆ—è¡¨
      if (this.baseURL && this.baseURL.includes("volces.com")) {
        logger.info("[OpenAIClient] æ£€æµ‹åˆ°ç«å±±å¼•æ“ï¼Œä½¿ç”¨èŠå¤©æµ‹è¯•ä»£æ›¿æ¨¡å‹åˆ—è¡¨");

        const testResponse = await this.client.post(
          "/chat/completions",
          {
            model: this.model,
            messages: [{ role: "user", content: "hi" }],
            max_tokens: 5,
          },
          {
            timeout: 10000, // 10ç§’å¿«é€Ÿè¶…æ—¶
          },
        );

        return {
          available: true,
          models: [
            {
              name: this.model,
              created: Date.now(),
              owned_by: "volcengine",
            },
          ],
          testResponse: testResponse.data,
        };
      }

      // æ ‡å‡†OpenAI APIï¼šå°è¯•åˆ—å‡ºæ¨¡å‹
      const response = await this.client.get("/models");

      const models = response.data.data || [];

      return {
        available: true,
        models: models.map((m) => ({
          name: m.id,
          created: m.created,
          owned_by: m.owned_by,
        })),
      };
    } catch (error) {
      return {
        available: false,
        error: error.response?.data?.error?.message || error.message,
        models: [],
      };
    }
  }

  /**
   * èŠå¤©è¡¥å…¨ï¼ˆéæµå¼ï¼‰
   * @param {Array} messages - æ¶ˆæ¯æ•°ç»„
   * @param {Object} options - é€‰é¡¹
   */
  async chat(messages, options = {}) {
    try {
      // æ„å»ºè¯·æ±‚ä½“
      const requestBody = {
        model: options.model || this.model,
        messages,
        temperature: options.temperature || 0.7,
        top_p: options.top_p || 1,
        max_tokens: options.max_tokens,
        presence_penalty: options.presence_penalty || 0,
        frequency_penalty: options.frequency_penalty || 0,
        stream: false,
      };

      // ğŸ”¥ ä¿®å¤ï¼šåªæœ‰åœ¨ tools æœ‰æ•ˆä¸”éç©ºæ—¶æ‰æ·»åŠ ï¼ˆé¿å…é˜¿é‡Œäº‘ç­‰APIæŠ¥é”™ï¼‰
      if (
        options.tools &&
        Array.isArray(options.tools) &&
        options.tools.length > 0
      ) {
        // éªŒè¯æ¯ä¸ªtooléƒ½æœ‰å¿…è¦çš„å­—æ®µ
        const validTools = options.tools.filter((tool) => {
          if (tool.type === "function") {
            return tool.function && tool.function.name;
          }
          return true; // å…¶ä»–ç±»å‹çš„å·¥å…·æš‚æ—¶å…è®¸
        });

        if (validTools.length > 0) {
          requestBody.tools = validTools;
        }
      }

      const response = await this.client.post("/chat/completions", requestBody);

      const choice = response.data.choices[0];

      return {
        message: choice.message,
        finish_reason: choice.finish_reason,
        model: response.data.model,
        usage: response.data.usage,
        tokens: response.data.usage.total_tokens,
      };
    } catch (error) {
      logger.error("[OpenAIClient] èŠå¤©å¤±è´¥:", error.response?.data || error);
      throw new Error(error.response?.data?.error?.message || error.message);
    }
  }

  /**
   * èŠå¤©è¡¥å…¨ï¼ˆæµå¼ï¼‰
   * @param {Array} messages - æ¶ˆæ¯æ•°ç»„
   * @param {Function} onChunk - å›è°ƒå‡½æ•°
   * @param {Object} options - é€‰é¡¹
   */
  async chatStream(messages, onChunk, options = {}) {
    try {
      // æ„å»ºè¯·æ±‚ä½“
      const requestBody = {
        model: options.model || this.model,
        messages,
        temperature: options.temperature || 0.7,
        top_p: options.top_p || 1,
        max_tokens: options.max_tokens,
        presence_penalty: options.presence_penalty || 0,
        frequency_penalty: options.frequency_penalty || 0,
        stream: true,
      };

      // ğŸ”¥ ä¿®å¤ï¼šåªæœ‰åœ¨ tools æœ‰æ•ˆä¸”éç©ºæ—¶æ‰æ·»åŠ ï¼ˆé¿å…é˜¿é‡Œäº‘ç­‰APIæŠ¥é”™ï¼‰
      if (
        options.tools &&
        Array.isArray(options.tools) &&
        options.tools.length > 0
      ) {
        // éªŒè¯æ¯ä¸ªtooléƒ½æœ‰å¿…è¦çš„å­—æ®µ
        const validTools = options.tools.filter((tool) => {
          if (tool.type === "function") {
            return tool.function && tool.function.name;
          }
          return true; // å…¶ä»–ç±»å‹çš„å·¥å…·æš‚æ—¶å…è®¸
        });

        if (validTools.length > 0) {
          requestBody.tools = validTools;
        }
      }

      const response = await this.client.post(
        "/chat/completions",
        requestBody,
        {
          responseType: "stream",
        },
      );

      const fullMessage = {
        role: "assistant",
        content: "",
      };

      return new Promise((resolve, reject) => {
        response.data.on("data", (chunk) => {
          const lines = chunk
            .toString()
            .split("\n")
            .filter((line) => line.trim().startsWith("data: "));

          for (const line of lines) {
            const data = line.replace(/^data: /, "");

            if (data === "[DONE]") {
              resolve({
                message: fullMessage,
                model: options.model || this.model,
                finish_reason: "stop",
              });
              return;
            }

            try {
              const parsed = JSON.parse(data);
              const delta = parsed.choices[0]?.delta;

              if (delta?.content) {
                fullMessage.content += delta.content;
                // ä¼ é€’å¯¹è±¡æ ¼å¼çš„chunkï¼Œä¿æŒç»Ÿä¸€æ¥å£
                onChunk({
                  content: delta.content,
                  delta: delta,
                  fullContent: fullMessage.content,
                });
              }

              if (parsed.choices[0]?.finish_reason) {
                resolve({
                  message: fullMessage,
                  model: parsed.model,
                  finish_reason: parsed.choices[0].finish_reason,
                });
              }
            } catch (e) {
              // å¿½ç•¥è§£æé”™è¯¯
            }
          }
        });

        response.data.on("error", (error) => {
          reject(error);
        });

        response.data.on("end", () => {
          // å¦‚æœæ²¡æœ‰æ”¶åˆ°[DONE]ï¼Œä¹Ÿè¦resolve
          resolve({
            message: fullMessage,
            model: options.model || this.model,
            finish_reason: "stop",
          });
        });
      });
    } catch (error) {
      logger.error(
        "[OpenAIClient] æµå¼èŠå¤©å¤±è´¥:",
        error.response?.data || error,
      );
      throw new Error(error.response?.data?.error?.message || error.message);
    }
  }

  /**
   * æ–‡æœ¬è¡¥å…¨ï¼ˆéæµå¼ï¼‰- å…¼å®¹è€ç‰ˆAPI
   * @param {string} prompt - æç¤ºè¯
   * @param {Object} options - é€‰é¡¹
   */
  async complete(prompt, options = {}) {
    try {
      const response = await this.client.post("/completions", {
        model: options.model || "gpt-3.5-turbo-instruct",
        prompt,
        temperature: options.temperature || 0.7,
        max_tokens: options.max_tokens || 1000,
        top_p: options.top_p || 1,
        stream: false,
      });

      const choice = response.data.choices[0];

      return {
        text: choice.text,
        finish_reason: choice.finish_reason,
        model: response.data.model,
        usage: response.data.usage,
        tokens: response.data.usage.total_tokens,
      };
    } catch (error) {
      logger.error("[OpenAIClient] è¡¥å…¨å¤±è´¥:", error.response?.data || error);
      throw new Error(error.response?.data?.error?.message || error.message);
    }
  }

  /**
   * ç”ŸæˆåµŒå…¥å‘é‡
   * @param {string|Array} input - æ–‡æœ¬æˆ–æ–‡æœ¬æ•°ç»„
   * @param {string} model - æ¨¡å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®çš„embeddingModelï¼‰
   */
  async embeddings(input, model = null) {
    try {
      const embeddingModel = model || this.embeddingModel;

      const response = await this.client.post("/embeddings", {
        model: embeddingModel,
        input,
      });

      if (Array.isArray(input)) {
        return response.data.data.map((d) => d.embedding);
      } else {
        return response.data.data[0].embedding;
      }
    } catch (error) {
      logger.error(
        "[OpenAIClient] ç”ŸæˆåµŒå…¥å¤±è´¥:",
        error.response?.data || error,
      );
      throw new Error(error.response?.data?.error?.message || error.message);
    }
  }

  /**
   * åˆ—å‡ºå¯ç”¨æ¨¡å‹
   */
  async listModels() {
    try {
      const response = await this.client.get("/models");
      return response.data.data;
    } catch (error) {
      logger.error(
        "[OpenAIClient] åˆ—å‡ºæ¨¡å‹å¤±è´¥:",
        error.response?.data || error,
      );
      throw new Error(error.response?.data?.error?.message || error.message);
    }
  }

  /**
   * è·å–æ¨¡å‹ä¿¡æ¯
   * @param {string} modelId - æ¨¡å‹ID
   */
  async getModel(modelId) {
    try {
      const response = await this.client.get(`/models/${modelId}`);
      return response.data;
    } catch (error) {
      logger.error(
        "[OpenAIClient] è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥:",
        error.response?.data || error,
      );
      throw new Error(error.response?.data?.error?.message || error.message);
    }
  }
}

/**
 * DeepSeek å®¢æˆ·ç«¯ (ä½¿ç”¨OpenAIå…¼å®¹API)
 */
class DeepSeekClient extends OpenAIClient {
  constructor(config = {}) {
    super({
      ...config,
      baseURL: config.baseURL || "https://api.deepseek.com/v1",
      model: config.model || "deepseek-chat",
    });
  }
}

module.exports = {
  OpenAIClient,
  DeepSeekClient,
};
