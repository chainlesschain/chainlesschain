/**
 * LLM æœåŠ¡ç®¡ç†å™¨
 *
 * ç»Ÿä¸€ç®¡ç†ä¸åŒçš„LLMæœåŠ¡æä¾›å•†
 *
 * ğŸ”¥ Manus ä¼˜åŒ–é›†æˆ (2026-01-17):
 * - Context Engineering: KV-Cache å‹å¥½çš„ Prompt æ„å»º
 * - Tool Masking: é€šè¿‡æ©ç æ§åˆ¶å·¥å…·å¯ç”¨æ€§
 * - Task Tracking: ä»»åŠ¡ç›®æ ‡é‡è¿°æœºåˆ¶
 *
 * @see https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus
 */

const EventEmitter = require("events");
const OllamaClient = require("./ollama-client");
const { OpenAIClient, DeepSeekClient } = require("./openai-client");
const { AnthropicClient } = require("./anthropic-client");
const { getModelSelector, TaskTypes } = require("./volcengine-models");
const { VolcengineToolsClient } = require("./volcengine-tools");

// ğŸ”¥ Manus ä¼˜åŒ–æ¨¡å—
const { getManusOptimizations } = require("./manus-optimizations");

/**
 * LLM æä¾›å•†ç±»å‹
 */
const LLMProviders = {
  OLLAMA: "ollama",
  OPENAI: "openai",
  DEEPSEEK: "deepseek",
  VOLCENGINE: "volcengine",
  ANTHROPIC: "anthropic",
  CLAUDE: "claude",
  CUSTOM: "custom",
};

const normalizeProvider = (provider) => {
  if (!provider) return provider;
  if (provider === LLMProviders.CLAUDE) {
    return LLMProviders.ANTHROPIC;
  }
  return provider;
};

/**
 * LLMç®¡ç†å™¨ç±»
 */
class LLMManager extends EventEmitter {
  constructor(config = {}) {
    super();

    this.config = config;
    this.provider = normalizeProvider(config.provider) || LLMProviders.OLLAMA;
    this.client = null;
    this.isInitialized = false;

    // ä¼šè¯ä¸Šä¸‹æ–‡
    this.conversationContext = new Map();

    // ç«å±±å¼•æ“å·¥å…·è°ƒç”¨å®¢æˆ·ç«¯
    this.toolsClient = null;

    // Token è¿½è¸ªå™¨ï¼ˆå¯é€‰ï¼‰
    this.tokenTracker = config.tokenTracker || null;
    if (this.tokenTracker) {
      console.log("[LLMManager] Token è¿½è¸ªå·²å¯ç”¨");

      // ğŸ”¥ ç›‘å¬é¢„ç®—å‘Šè­¦äº‹ä»¶
      this.tokenTracker.on("budget-alert", this._handleBudgetAlert.bind(this));
    }

    // ğŸ”¥ å“åº”ç¼“å­˜ï¼ˆå¯é€‰ï¼‰
    this.responseCache = config.responseCache || null;
    if (this.responseCache) {
      console.log("[LLMManager] å“åº”ç¼“å­˜å·²å¯ç”¨");
    }

    // ğŸ”¥ Prompt å‹ç¼©å™¨ï¼ˆå¯é€‰ï¼‰
    this.promptCompressor = config.promptCompressor || null;
    if (this.promptCompressor) {
      console.log("[LLMManager] Prompt å‹ç¼©å·²å¯ç”¨");
    }

    // ğŸ”¥ æš‚åœæ ‡å¿—ï¼ˆé¢„ç®—è¶…é™æ—¶ï¼‰
    this.paused = false;

    // ğŸ”¥ é¢„ç®—é…ç½®ç¼“å­˜ï¼ˆç”¨äºè‡ªåŠ¨åˆ‡æ¢æ¨¡å‹ï¼‰
    this.budgetConfig = null;

    // ğŸ”¥ Manus ä¼˜åŒ–ï¼ˆContext Engineering + Tool Maskingï¼‰
    this.manusOptimizations = null;
    if (config.enableManusOptimizations !== false) {
      try {
        this.manusOptimizations = getManusOptimizations({
          enableKVCacheOptimization: config.enableKVCacheOptimization !== false,
          enableToolMasking: config.enableToolMasking !== false,
          enableTaskTracking: config.enableTaskTracking !== false,
          enableRecoverableCompression: config.enableRecoverableCompression !== false,
          logMaskChanges: config.logMaskChanges !== false,
        });
        console.log("[LLMManager] Manus ä¼˜åŒ–å·²å¯ç”¨ (Context Engineering + Tool Masking)");
      } catch (manusError) {
        console.warn("[LLMManager] Manus ä¼˜åŒ–åˆå§‹åŒ–å¤±è´¥:", manusError.message);
      }
    }
  }

  /**
   * åˆå§‹åŒ–ç®¡ç†å™¨
   */
  async initialize() {
    console.log("[LLMManager] åˆå§‹åŒ–LLMç®¡ç†å™¨...");
    console.log("[LLMManager] æä¾›å•†:", this.provider);

    try {
      this.client = await this.createClient(this.provider);

      // ğŸ”¥ åˆå§‹åŒ–ç«å±±å¼•æ“å·¥å…·è°ƒç”¨å®¢æˆ·ç«¯
      if (this.provider === LLMProviders.VOLCENGINE) {
        try {
          this.toolsClient = new VolcengineToolsClient({
            apiKey: this.config.apiKey,
            baseURL:
              this.config.baseURL || "https://ark.cn-beijing.volces.com/api/v3",
            model: this.config.model || "doubao-seed-1.6-lite",
          });
          console.log("[LLMManager] ç«å±±å¼•æ“å·¥å…·è°ƒç”¨å®¢æˆ·ç«¯å·²åˆå§‹åŒ–");
        } catch (toolsError) {
          console.warn(
            "[LLMManager] å·¥å…·è°ƒç”¨å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥:",
            toolsError.message,
          );
        }
      }

      if (this.client) {
        // æ£€æŸ¥æœåŠ¡çŠ¶æ€ï¼ˆä¸é˜»å¡åˆå§‹åŒ–ï¼‰
        try {
          const status = await this.client.checkStatus();

          if (status.available) {
            this.isInitialized = true;
            console.log("[LLMManager] LLMæœåŠ¡å¯ç”¨");
            console.log("[LLMManager] å¯ç”¨æ¨¡å‹æ•°:", status.models?.length || 0);
            this.emit("initialized", status);
          } else {
            console.warn("[LLMManager] LLMæœåŠ¡çŠ¶æ€æ£€æŸ¥å¤±è´¥:", status.error);
            // å³ä½¿çŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼Œä¹Ÿæ ‡è®°ä¸ºå·²åˆå§‹åŒ–ï¼ˆå…è®¸åç»­è°ƒç”¨æ—¶é‡è¯•ï¼‰
            this.isInitialized = true;
            this.emit("unavailable", status);
          }
        } catch (statusError) {
          console.warn(
            "[LLMManager] æ— æ³•æ£€æŸ¥æœåŠ¡çŠ¶æ€ï¼ˆå°†åœ¨å®é™…è°ƒç”¨æ—¶é‡è¯•ï¼‰:",
            statusError.message,
          );
          // å³ä½¿çŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼Œä¹Ÿæ ‡è®°ä¸ºå·²åˆå§‹åŒ–ï¼ˆå…è®¸åç»­è°ƒç”¨æ—¶é‡è¯•ï¼‰
          this.isInitialized = true;
        }
      }

      return this.isInitialized;
    } catch (error) {
      console.error("[LLMManager] åˆå§‹åŒ–å¤±è´¥:", error);
      this.isInitialized = false;
      throw error;
    }
  }

  /**
   * åˆ›å»ºå®¢æˆ·ç«¯
   * @param {string} provider - æä¾›å•†ç±»å‹
   */
  async createClient(provider) {
    const normalizedProvider = normalizeProvider(provider);

    switch (normalizedProvider) {
      case LLMProviders.OLLAMA:
        return new OllamaClient({
          baseURL: this.config.ollamaURL || "http://localhost:11434",
          model: this.config.model || "llama2",
          timeout: this.config.timeout,
        });

      case LLMProviders.ANTHROPIC:
        return new AnthropicClient({
          apiKey: this.config.apiKey,
          baseURL: this.config.baseURL || "https://api.anthropic.com",
          model: this.config.model || "claude-3-opus-20240229",
          timeout: this.config.timeout,
          anthropicVersion: this.config.anthropicVersion,
          maxTokens: this.config.maxTokens,
        });

      case LLMProviders.OPENAI:
        return new OpenAIClient({
          apiKey: this.config.apiKey,
          baseURL: this.config.baseURL,
          model: this.config.model || "gpt-3.5-turbo",
          embeddingModel:
            this.config.embeddingModel || "text-embedding-ada-002",
          organization: this.config.organization,
          timeout: this.config.timeout,
        });

      case LLMProviders.DEEPSEEK:
        return new DeepSeekClient({
          apiKey: this.config.apiKey,
          baseURL: this.config.baseURL,
          model: this.config.model || "deepseek-chat",
          embeddingModel:
            this.config.embeddingModel || "text-embedding-ada-002",
          timeout: this.config.timeout,
        });

      case LLMProviders.VOLCENGINE:
        return new OpenAIClient({
          apiKey: this.config.apiKey,
          baseURL:
            this.config.baseURL || "https://ark.cn-beijing.volces.com/api/v3",
          model: this.config.model || "doubao-seed-1.6-lite",
          embeddingModel:
            this.config.embeddingModel || "doubao-embedding-large",
          timeout: this.config.timeout,
        });

      case LLMProviders.CUSTOM:
        return new OpenAIClient({
          apiKey: this.config.apiKey,
          baseURL: this.config.baseURL,
          model: this.config.model,
          embeddingModel: this.config.embeddingModel,
          timeout: this.config.timeout,
        });

      default:
        throw new Error(`ä¸æ”¯æŒçš„æä¾›å•†: ${provider}`);
    }
  }

  /**
   * åˆ‡æ¢æä¾›å•†
   * @param {string} provider - æä¾›å•†ç±»å‹
   * @param {Object} config - é…ç½®
   */
  async switchProvider(provider, config = {}) {
    console.log("[LLMManager] åˆ‡æ¢æä¾›å•†:", provider);

    try {
      this.provider = normalizeProvider(provider);
      this.config = { ...this.config, ...config };

      await this.initialize();

      this.emit("provider-changed", this.provider);

      return true;
    } catch (error) {
      console.error("[LLMManager] åˆ‡æ¢æä¾›å•†å¤±è´¥:", error);
      throw error;
    }
  }

  /**
   * æ£€æŸ¥æœåŠ¡çŠ¶æ€
   */
  async checkStatus() {
    if (!this.client) {
      return {
        available: false,
        error: "LLMæœåŠ¡æœªåˆå§‹åŒ–",
        provider: this.provider,
      };
    }

    try {
      const status = await this.client.checkStatus();
      return {
        ...status,
        provider: this.provider,
      };
    } catch (error) {
      return {
        available: false,
        error: error.message,
        provider: this.provider,
      };
    }
  }

  /**
   * å‘é€æŸ¥è¯¢ï¼ˆéæµå¼ï¼‰
   * @param {string} prompt - æç¤ºè¯
   * @param {Object} options - é€‰é¡¹
   */
  async query(prompt, options = {}) {
    if (!this.isInitialized) {
      throw new Error("LLMæœåŠ¡æœªåˆå§‹åŒ–");
    }

    // ğŸ”¥ æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²æš‚åœï¼ˆé¢„ç®—è¶…é™ï¼‰
    if (this.paused) {
      throw new Error(
        "LLMæœåŠ¡å·²æš‚åœï¼šé¢„ç®—è¶…é™ã€‚è¯·å‰å¾€è®¾ç½®é¡µé¢è°ƒæ•´é¢„ç®—æˆ–æ¢å¤æœåŠ¡ã€‚",
      );
    }

    const startTime = Date.now();

    try {
      const conversationId = options.conversationId;
      let result;

      if (this.provider === LLMProviders.OLLAMA) {
        // Ollamaä½¿ç”¨generateæˆ–chat
        if (conversationId && this.conversationContext.has(conversationId)) {
          // æœ‰ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨chat
          const context = this.conversationContext.get(conversationId);
          const messages = [
            ...context.messages,
            { role: "user", content: prompt },
          ];

          result = await this.client.chat(messages, options);

          // æ›´æ–°ä¸Šä¸‹æ–‡
          context.messages.push(
            { role: "user", content: prompt },
            result.message,
          );
        } else {
          // æ— ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨generate
          result = await this.client.generate(prompt, options);

          // åˆ›å»ºä¸Šä¸‹æ–‡
          if (conversationId) {
            this.conversationContext.set(conversationId, {
              messages: [
                { role: "user", content: prompt },
                { role: "assistant", content: result.text },
              ],
              context: result.context,
            });
          }
        }
      } else {
        // OpenAIå…¼å®¹çš„APIä½¿ç”¨chat
        const messages = [];

        if (conversationId && this.conversationContext.has(conversationId)) {
          const context = this.conversationContext.get(conversationId);
          messages.push(...context.messages);
        }

        if (options.systemPrompt) {
          messages.unshift({ role: "system", content: options.systemPrompt });
        }

        messages.push({ role: "user", content: prompt });

        result = await this.client.chat(messages, options);

        // æ›´æ–°ä¸Šä¸‹æ–‡
        if (conversationId) {
          if (!this.conversationContext.has(conversationId)) {
            this.conversationContext.set(conversationId, { messages: [] });
          }
          const context = this.conversationContext.get(conversationId);
          context.messages.push(
            { role: "user", content: prompt },
            result.message,
          );
        }
      }

      this.emit("query-completed", { prompt, result });

      const responseTime = Date.now() - startTime;

      // ğŸ”¥ è®°å½• Token ä½¿ç”¨
      if (this.tokenTracker) {
        try {
          await this.tokenTracker.recordUsage({
            conversationId: options.conversationId,
            messageId: options.messageId,
            provider: this.provider,
            model: result.model || this.config.model || "unknown",
            inputTokens: result.usage?.prompt_tokens || 0,
            outputTokens: result.usage?.completion_tokens || 0,
            cachedTokens: result.usage?.cached_tokens || 0,
            wasCached: options.wasCached || false,
            wasCompressed: options.wasCompressed || false,
            compressionRatio: options.compressionRatio || 1.0,
            responseTime,
            endpoint: options.endpoint,
            userId: options.userId || "default",
          });
        } catch (trackError) {
          console.error("[LLMManager] Token è¿½è¸ªå¤±è´¥:", trackError);
          // ä¸é˜»å¡ä¸»æµç¨‹
        }
      }

      return {
        text: result.text || result.message?.content,
        model: result.model,
        tokens: result.tokens || result.usage?.total_tokens || 0,
        usage: result.usage,
        timestamp: Date.now(),
      };
    } catch (error) {
      console.error("[LLMManager] æŸ¥è¯¢å¤±è´¥:", error);
      this.emit("query-failed", { prompt, error });
      throw error;
    }
  }

  /**
   * å‘åå…¼å®¹ï¼šèŠå¤©å¯¹è¯ï¼ˆæ¶ˆæ¯æ•°ç»„ï¼‰
   * @param {Array} messages
   * @param {Object} options
   */
  async chat(messages, options = {}) {
    if (!Array.isArray(messages)) {
      throw new Error("messageså¿…é¡»æ˜¯æ•°ç»„");
    }

    const result = await this.chatWithMessages(messages, options);
    return {
      ...result,
      content: result.message?.content || result.text,
    };
  }

  /**
   * å‘åå…¼å®¹ï¼šèŠå¤©å¯¹è¯ï¼ˆæµå¼ï¼‰
   * @param {Array} messages
   * @param {Function} onChunk
   * @param {Object} options
   */
  async chatStream(messages, onChunk, options = {}) {
    if (!Array.isArray(messages)) {
      throw new Error("messageså¿…é¡»æ˜¯æ•°ç»„");
    }
    if (typeof onChunk !== "function") {
      throw new Error("onChunkå›è°ƒæ˜¯å¿…éœ€çš„");
    }

    const result = await this.chatWithMessagesStream(
      messages,
      onChunk,
      options,
    );
    return {
      ...result,
      content: result.message?.content || result.text,
    };
  }

  /**
   * èŠå¤©å¯¹è¯ï¼ˆæ”¯æŒå®Œæ•´messagesæ•°ç»„ï¼Œéæµå¼ï¼‰
   * @param {Array} messages - æ¶ˆæ¯æ•°ç»„ [{role: 'user'|'assistant'|'system', content: string}]
   * @param {Object} options - é€‰é¡¹
   */
  async chatWithMessages(messages, options = {}) {
    if (!this.isInitialized) {
      throw new Error("LLMæœåŠ¡æœªåˆå§‹åŒ–");
    }

    // ğŸ”¥ æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²æš‚åœï¼ˆé¢„ç®—è¶…é™ï¼‰
    if (this.paused) {
      throw new Error(
        "LLMæœåŠ¡å·²æš‚åœï¼šé¢„ç®—è¶…é™ã€‚è¯·å‰å¾€è®¾ç½®é¡µé¢è°ƒæ•´é¢„ç®—æˆ–æ¢å¤æœåŠ¡ã€‚",
      );
    }

    const startTime = Date.now();
    let wasCached = false;
    let wasCompressed = false;
    let compressionRatio = 1.0;
    let processedMessages = messages;

    try {
      // ğŸ”¥ æ­¥éª¤ 1: æ£€æŸ¥å“åº”ç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
      if (this.responseCache && !options.skipCache) {
        const cacheResult = await this.responseCache.get(
          this.provider,
          this.config.model,
          messages,
          options,
        );

        if (cacheResult.hit) {
          console.log("[LLMManager] ç¼“å­˜å‘½ä¸­ï¼Œè·³è¿‡ LLM è°ƒç”¨");
          wasCached = true;

          // ğŸ”¥ è®°å½• Token ä½¿ç”¨ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
          if (this.tokenTracker) {
            try {
              await this.tokenTracker.recordUsage({
                conversationId: options.conversationId,
                messageId: options.messageId,
                provider: this.provider,
                model: this.config.model || "unknown",
                inputTokens: 0,
                outputTokens: 0,
                cachedTokens: 0,
                wasCached: true,
                wasCompressed: false,
                compressionRatio: 1.0,
                responseTime: Date.now() - startTime,
                endpoint: options.endpoint,
                userId: options.userId || "default",
              });
            } catch (trackError) {
              console.error("[LLMManager] Token è¿½è¸ªå¤±è´¥:", trackError);
            }
          }

          return {
            text:
              cacheResult.response.text ||
              cacheResult.response.message?.content,
            message: cacheResult.response.message,
            model: cacheResult.response.model,
            tokens: cacheResult.response.tokens || 0,
            usage: cacheResult.response.usage,
            timestamp: Date.now(),
            wasCached: true,
            tokensSaved: cacheResult.tokensSaved || 0,
          };
        }
      }

      // ğŸ”¥ æ­¥éª¤ 2: Prompt å‹ç¼©ï¼ˆå¦‚æœå¯ç”¨ä¸”æœªç¦ç”¨ï¼‰
      if (
        this.promptCompressor &&
        !options.skipCompression &&
        messages.length > 5
      ) {
        console.log("[LLMManager] æ‰§è¡Œ Prompt å‹ç¼©...");
        const compressionResult = await this.promptCompressor.compress(
          messages,
          {
            preserveSystemMessage: true,
            preserveLastUserMessage: true,
          },
        );

        processedMessages = compressionResult.messages;
        wasCompressed = true;
        compressionRatio = compressionResult.compressionRatio;

        console.log(
          `[LLMManager] Prompt å·²å‹ç¼©: ${messages.length} â†’ ${processedMessages.length} æ¡æ¶ˆæ¯, ` +
            `å‹ç¼©ç‡: ${compressionRatio.toFixed(2)}, èŠ‚çœ ${compressionResult.tokensSaved} tokens`,
        );
      }

      // ğŸ”¥ æ­¥éª¤ 3: è°ƒç”¨ LLM API
      let result;

      if (this.provider === LLMProviders.OLLAMA) {
        result = await this.client.chat(processedMessages, options);
      } else {
        // OpenAIå…¼å®¹çš„API
        result = await this.client.chat(processedMessages, options);
      }

      this.emit("chat-completed", { messages: processedMessages, result });

      const responseTime = Date.now() - startTime;

      // ğŸ”¥ æ­¥éª¤ 4: å­˜å…¥å“åº”ç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
      if (this.responseCache && !options.skipCache && !wasCached) {
        try {
          await this.responseCache.set(
            this.provider,
            this.config.model,
            messages, // ä½¿ç”¨åŸå§‹ messages ä½œä¸ºç¼“å­˜é”®
            {
              text: result.message?.content || result.text,
              message: result.message,
              model: result.model,
              tokens: result.tokens || result.usage?.total_tokens || 0,
              usage: result.usage,
            },
            options,
          );
          console.log("[LLMManager] å“åº”å·²ç¼“å­˜");
        } catch (cacheError) {
          console.error("[LLMManager] ç¼“å­˜ä¿å­˜å¤±è´¥:", cacheError);
          // ä¸é˜»å¡ä¸»æµç¨‹
        }
      }

      // ğŸ”¥ æ­¥éª¤ 5: è®°å½• Token ä½¿ç”¨
      if (this.tokenTracker) {
        try {
          await this.tokenTracker.recordUsage({
            conversationId: options.conversationId,
            messageId: options.messageId,
            provider: this.provider,
            model: result.model || this.config.model || "unknown",
            inputTokens: result.usage?.prompt_tokens || 0,
            outputTokens: result.usage?.completion_tokens || 0,
            cachedTokens: result.usage?.cached_tokens || 0,
            wasCached,
            wasCompressed,
            compressionRatio,
            responseTime,
            endpoint: options.endpoint,
            userId: options.userId || "default",
          });
        } catch (trackError) {
          console.error("[LLMManager] Token è¿½è¸ªå¤±è´¥:", trackError);
          // ä¸é˜»å¡ä¸»æµç¨‹
        }
      }

      return {
        text: result.message?.content || result.text,
        message: result.message,
        model: result.model,
        tokens: result.tokens || result.usage?.total_tokens || 0,
        usage: result.usage,
        timestamp: Date.now(),
        wasCached,
        wasCompressed,
        compressionRatio,
      };
    } catch (error) {
      console.error("[LLMManager] èŠå¤©å¤±è´¥:", error);
      this.emit("chat-failed", { messages: processedMessages, error });
      throw error;
    }
  }

  /**
   * èŠå¤©å¯¹è¯ï¼ˆæ”¯æŒå®Œæ•´messagesæ•°ç»„ï¼Œæµå¼ï¼‰
   * @param {Array} messages - æ¶ˆæ¯æ•°ç»„
   * @param {Function} onChunk - å›è°ƒå‡½æ•°
   * @param {Object} options - é€‰é¡¹
   */
  async chatWithMessagesStream(messages, onChunk, options = {}) {
    if (!this.isInitialized) {
      throw new Error("LLMæœåŠ¡æœªåˆå§‹åŒ–");
    }

    // ğŸ”¥ æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²æš‚åœï¼ˆé¢„ç®—è¶…é™ï¼‰
    if (this.paused) {
      throw new Error(
        "LLMæœåŠ¡å·²æš‚åœï¼šé¢„ç®—è¶…é™ã€‚è¯·å‰å¾€è®¾ç½®é¡µé¢è°ƒæ•´é¢„ç®—æˆ–æ¢å¤æœåŠ¡ã€‚",
      );
    }

    const startTime = Date.now();
    let wasCompressed = false;
    let compressionRatio = 1.0;
    let processedMessages = messages;

    try {
      // ğŸ”¥ Prompt å‹ç¼©ï¼ˆæµå¼ä¸æ”¯æŒç¼“å­˜ï¼Œä½†æ”¯æŒå‹ç¼©ï¼‰
      if (
        this.promptCompressor &&
        !options.skipCompression &&
        messages.length > 5
      ) {
        console.log("[LLMManager] æ‰§è¡Œ Prompt å‹ç¼©ï¼ˆæµå¼ï¼‰...");
        const compressionResult = await this.promptCompressor.compress(
          messages,
          {
            preserveSystemMessage: true,
            preserveLastUserMessage: true,
          },
        );

        processedMessages = compressionResult.messages;
        wasCompressed = true;
        compressionRatio = compressionResult.compressionRatio;

        console.log(
          `[LLMManager] Prompt å·²å‹ç¼©ï¼ˆæµå¼ï¼‰: ${messages.length} â†’ ${processedMessages.length} æ¡æ¶ˆæ¯, ` +
            `å‹ç¼©ç‡: ${compressionRatio.toFixed(2)}, èŠ‚çœ ${compressionResult.tokensSaved} tokens`,
        );
      }

      let result;

      if (this.provider === LLMProviders.OLLAMA) {
        result = await this.client.chatStream(
          processedMessages,
          onChunk,
          options,
        );
      } else {
        // OpenAIå…¼å®¹çš„API
        result = await this.client.chatStream(
          processedMessages,
          onChunk,
          options,
        );
      }

      this.emit("chat-stream-completed", {
        messages: processedMessages,
        result,
      });

      const responseTime = Date.now() - startTime;

      // ğŸ”¥ è®°å½• Token ä½¿ç”¨
      if (this.tokenTracker) {
        try {
          await this.tokenTracker.recordUsage({
            conversationId: options.conversationId,
            messageId: options.messageId,
            provider: this.provider,
            model: result.model || this.config.model || "unknown",
            inputTokens: result.usage?.prompt_tokens || 0,
            outputTokens: result.usage?.completion_tokens || 0,
            cachedTokens: result.usage?.cached_tokens || 0,
            wasCached: false, // æµå¼ä¸æ”¯æŒç¼“å­˜
            wasCompressed,
            compressionRatio,
            responseTime,
            endpoint: options.endpoint,
            userId: options.userId || "default",
          });
        } catch (trackError) {
          console.error("[LLMManager] Token è¿½è¸ªå¤±è´¥:", trackError);
          // ä¸é˜»å¡ä¸»æµç¨‹
        }
      }

      return {
        text: result.message?.content || result.text,
        message: result.message,
        model: result.model,
        tokens: result.tokens || 0,
        usage: result.usage,
        timestamp: Date.now(),
        wasCompressed,
        compressionRatio,
      };
    } catch (error) {
      console.error("[LLMManager] æµå¼èŠå¤©å¤±è´¥:", error);
      this.emit("chat-stream-failed", { messages: processedMessages, error });
      throw error;
    }
  }

  /**
   * å‘é€æŸ¥è¯¢ï¼ˆæµå¼ï¼‰
   * @param {string} prompt - æç¤ºè¯
   * @param {Function} onChunk - å›è°ƒå‡½æ•°
   * @param {Object} options - é€‰é¡¹
   */
  async queryStream(prompt, onChunk, options = {}) {
    if (!this.isInitialized) {
      throw new Error("LLMæœåŠ¡æœªåˆå§‹åŒ–");
    }

    // ğŸ”¥ æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²æš‚åœï¼ˆé¢„ç®—è¶…é™ï¼‰
    if (this.paused) {
      throw new Error(
        "LLMæœåŠ¡å·²æš‚åœï¼šé¢„ç®—è¶…é™ã€‚è¯·å‰å¾€è®¾ç½®é¡µé¢è°ƒæ•´é¢„ç®—æˆ–æ¢å¤æœåŠ¡ã€‚",
      );
    }

    const startTime = Date.now();

    try {
      const conversationId = options.conversationId;
      let result;

      if (this.provider === LLMProviders.OLLAMA) {
        if (conversationId && this.conversationContext.has(conversationId)) {
          const context = this.conversationContext.get(conversationId);
          const messages = [
            ...context.messages,
            { role: "user", content: prompt },
          ];

          result = await this.client.chatStream(messages, onChunk, options);

          context.messages.push(
            { role: "user", content: prompt },
            result.message,
          );
        } else {
          result = await this.client.generateStream(prompt, onChunk, options);

          if (conversationId) {
            this.conversationContext.set(conversationId, {
              messages: [
                { role: "user", content: prompt },
                { role: "assistant", content: result.text },
              ],
              context: result.context,
            });
          }
        }
      } else {
        const messages = [];

        if (conversationId && this.conversationContext.has(conversationId)) {
          const context = this.conversationContext.get(conversationId);
          messages.push(...context.messages);
        }

        if (options.systemPrompt) {
          messages.unshift({ role: "system", content: options.systemPrompt });
        }

        messages.push({ role: "user", content: prompt });

        result = await this.client.chatStream(messages, onChunk, options);

        if (conversationId) {
          if (!this.conversationContext.has(conversationId)) {
            this.conversationContext.set(conversationId, { messages: [] });
          }
          const context = this.conversationContext.get(conversationId);
          context.messages.push(
            { role: "user", content: prompt },
            result.message,
          );
        }
      }

      this.emit("stream-completed", { prompt, result });

      const responseTime = Date.now() - startTime;

      // ğŸ”¥ è®°å½• Token ä½¿ç”¨
      if (this.tokenTracker) {
        try {
          await this.tokenTracker.recordUsage({
            conversationId: options.conversationId,
            messageId: options.messageId,
            provider: this.provider,
            model: result.model || this.config.model || "unknown",
            inputTokens: result.usage?.prompt_tokens || 0,
            outputTokens: result.usage?.completion_tokens || 0,
            cachedTokens: result.usage?.cached_tokens || 0,
            wasCached: options.wasCached || false,
            wasCompressed: options.wasCompressed || false,
            compressionRatio: options.compressionRatio || 1.0,
            responseTime,
            endpoint: options.endpoint,
            userId: options.userId || "default",
          });
        } catch (trackError) {
          console.error("[LLMManager] Token è¿½è¸ªå¤±è´¥:", trackError);
          // ä¸é˜»å¡ä¸»æµç¨‹
        }
      }

      return {
        text: result.text || result.message?.content,
        model: result.model,
        tokens: result.tokens || 0,
        usage: result.usage,
        timestamp: Date.now(),
      };
    } catch (error) {
      console.error("[LLMManager] æµå¼æŸ¥è¯¢å¤±è´¥:", error);
      this.emit("stream-failed", { prompt, error });
      throw error;
    }
  }

  /**
   * æ¸…é™¤ä¼šè¯ä¸Šä¸‹æ–‡
   * @param {string} conversationId - ä¼šè¯ID
   */
  clearContext(conversationId) {
    if (conversationId) {
      this.conversationContext.delete(conversationId);
    } else {
      this.conversationContext.clear();
    }
  }

  /**
   * è·å–ä¼šè¯ä¸Šä¸‹æ–‡
   * @param {string} conversationId - ä¼šè¯ID
   */
  getContext(conversationId) {
    return this.conversationContext.get(conversationId);
  }

  /**
   * ç”ŸæˆåµŒå…¥å‘é‡
   * @param {string} text - æ–‡æœ¬
   */
  async embeddings(text) {
    if (!this.isInitialized) {
      throw new Error("LLMæœåŠ¡æœªåˆå§‹åŒ–");
    }

    try {
      return await this.client.embeddings(text);
    } catch (error) {
      console.error("[LLMManager] ç”ŸæˆåµŒå…¥å¤±è´¥:", error);
      throw error;
    }
  }

  /**
   * åˆ—å‡ºå¯ç”¨æ¨¡å‹
   */
  async listModels() {
    if (!this.client) {
      return [];
    }

    try {
      const status = await this.client.checkStatus();
      return status.models || [];
    } catch (error) {
      console.error("[LLMManager] åˆ—å‡ºæ¨¡å‹å¤±è´¥:", error);
      return [];
    }
  }

  /**
   * æ™ºèƒ½é€‰æ‹©æ¨¡å‹ï¼ˆä»…é™ç«å±±å¼•æ“ï¼‰
   * @param {Object} scenario - åœºæ™¯æè¿°
   * @returns {Object} æ¨èçš„æ¨¡å‹é…ç½®
   */
  selectVolcengineModel(scenario = {}) {
    if (this.provider !== LLMProviders.VOLCENGINE) {
      console.warn(
        "[LLMManager] æ™ºèƒ½é€‰æ‹©å™¨ä»…æ”¯æŒç«å±±å¼•æ“ï¼Œå½“å‰æä¾›å•†:",
        this.provider,
      );
      return null;
    }

    const selector = getModelSelector();
    const model = selector.selectByScenario(scenario);

    console.log("[LLMManager] æ™ºèƒ½é€‰æ‹©æ¨¡å‹:", model.name);
    console.log("[LLMManager] æ¨¡å‹ID:", model.id);
    console.log("[LLMManager] èƒ½åŠ›:", model.capabilities);
    console.log("[LLMManager] ä»·æ ¼:", model.pricing);

    return {
      modelId: model.id,
      modelName: model.name,
      capabilities: model.capabilities,
      pricing: model.pricing,
      description: model.description,
      contextLength: model.contextLength,
      maxOutputTokens: model.maxOutputTokens,
    };
  }

  /**
   * æ ¹æ®ä»»åŠ¡ç±»å‹æ™ºèƒ½é€‰æ‹©æ¨¡å‹
   * @param {string} taskType - ä»»åŠ¡ç±»å‹ï¼ˆæ¥è‡ª TaskTypesï¼‰
   * @param {Object} options - é€‰é¡¹
   * @returns {Object} æ¨èçš„æ¨¡å‹é…ç½®
   */
  selectModelByTask(taskType, options = {}) {
    if (this.provider !== LLMProviders.VOLCENGINE) {
      console.warn(
        "[LLMManager] æ™ºèƒ½é€‰æ‹©å™¨ä»…æ”¯æŒç«å±±å¼•æ“ï¼Œå½“å‰æä¾›å•†:",
        this.provider,
      );
      return null;
    }

    const selector = getModelSelector();
    const model = selector.selectModel(taskType, options);

    console.log("[LLMManager] ä¸ºä»»åŠ¡", taskType, "é€‰æ‹©æ¨¡å‹:", model.name);

    return {
      modelId: model.id,
      modelName: model.name,
      capabilities: model.capabilities,
      pricing: model.pricing,
      description: model.description,
    };
  }

  /**
   * ä¼°ç®—æˆæœ¬ï¼ˆä»…é™ç«å±±å¼•æ“ï¼‰
   * @param {string} modelId - æ¨¡å‹ID
   * @param {number} inputTokens - è¾“å…¥tokens
   * @param {number} outputTokens - è¾“å‡ºtokens
   * @param {number} imageCount - å›¾ç‰‡æ•°é‡
   * @returns {number} é¢„ä¼°æˆæœ¬ï¼ˆäººæ°‘å¸ï¼‰
   */
  estimateCost(modelId, inputTokens = 0, outputTokens = 0, imageCount = 0) {
    if (this.provider !== LLMProviders.VOLCENGINE) {
      console.warn(
        "[LLMManager] æˆæœ¬ä¼°ç®—ä»…æ”¯æŒç«å±±å¼•æ“ï¼Œå½“å‰æä¾›å•†:",
        this.provider,
      );
      return 0;
    }

    const selector = getModelSelector();
    const cost = selector.estimateCost(
      modelId,
      inputTokens,
      outputTokens,
      imageCount,
    );

    console.log("[LLMManager] æˆæœ¬ä¼°ç®—:");
    console.log("  æ¨¡å‹:", modelId);
    console.log("  è¾“å…¥tokens:", inputTokens);
    console.log("  è¾“å‡ºtokens:", outputTokens);
    console.log("  å›¾ç‰‡æ•°é‡:", imageCount);
    console.log("  é¢„ä¼°æˆæœ¬: Â¥", cost.toFixed(4));

    return cost;
  }

  /**
   * åˆ—å‡ºç«å±±å¼•æ“æ‰€æœ‰å¯ç”¨æ¨¡å‹
   * @param {Object} filters - è¿‡æ»¤æ¡ä»¶
   * @returns {Array} æ¨¡å‹åˆ—è¡¨
   */
  listVolcengineModels(filters = {}) {
    if (this.provider !== LLMProviders.VOLCENGINE) {
      console.warn(
        "[LLMManager] æ¨¡å‹åˆ—è¡¨ä»…æ”¯æŒç«å±±å¼•æ“ï¼Œå½“å‰æä¾›å•†:",
        this.provider,
      );
      return [];
    }

    const selector = getModelSelector();
    return selector.listModels(filters);
  }

  // ========================================
  // ğŸ”¥ ç«å±±å¼•æ“å·¥å…·è°ƒç”¨åŠŸèƒ½
  // ========================================

  /**
   * å¯ç”¨è”ç½‘æœç´¢çš„å¯¹è¯
   * @param {Array} messages - æ¶ˆæ¯æ•°ç»„
   * @param {Object} options - é€‰é¡¹
   * @returns {Promise<Object>} APIå“åº”
   */
  async chatWithWebSearch(messages, options = {}) {
    if (this.provider !== LLMProviders.VOLCENGINE) {
      throw new Error("è”ç½‘æœç´¢ä»…æ”¯æŒç«å±±å¼•æ“");
    }

    if (!this.toolsClient) {
      throw new Error("ç«å±±å¼•æ“å·¥å…·è°ƒç”¨å®¢æˆ·ç«¯æœªåˆå§‹åŒ–");
    }

    console.log("[LLMManager] ä½¿ç”¨è”ç½‘æœç´¢å¯¹è¯");
    return await this.toolsClient.chatWithWebSearch(messages, options);
  }

  /**
   * å¯ç”¨å›¾åƒå¤„ç†çš„å¯¹è¯
   * @param {Array} messages - æ¶ˆæ¯æ•°ç»„ï¼ˆéœ€åŒ…å«å›¾åƒURLï¼‰
   * @param {Object} options - é€‰é¡¹
   * @returns {Promise<Object>} APIå“åº”
   */
  async chatWithImageProcess(messages, options = {}) {
    if (this.provider !== LLMProviders.VOLCENGINE) {
      throw new Error("å›¾åƒå¤„ç†ä»…æ”¯æŒç«å±±å¼•æ“");
    }

    if (!this.toolsClient) {
      throw new Error("ç«å±±å¼•æ“å·¥å…·è°ƒç”¨å®¢æˆ·ç«¯æœªåˆå§‹åŒ–");
    }

    console.log("[LLMManager] ä½¿ç”¨å›¾åƒå¤„ç†å¯¹è¯");
    return await this.toolsClient.chatWithImageProcess(messages, options);
  }

  /**
   * ä½¿ç”¨çŸ¥è¯†åº“å¢å¼ºçš„å¯¹è¯
   * @param {Array} messages - æ¶ˆæ¯æ•°ç»„
   * @param {string} knowledgeBaseId - çŸ¥è¯†åº“ID
   * @param {Object} options - é€‰é¡¹
   * @returns {Promise<Object>} APIå“åº”
   */
  async chatWithKnowledgeBase(messages, knowledgeBaseId, options = {}) {
    if (this.provider !== LLMProviders.VOLCENGINE) {
      throw new Error("çŸ¥è¯†åº“æœç´¢ä»…æ”¯æŒç«å±±å¼•æ“");
    }

    if (!this.toolsClient) {
      throw new Error("ç«å±±å¼•æ“å·¥å…·è°ƒç”¨å®¢æˆ·ç«¯æœªåˆå§‹åŒ–");
    }

    console.log("[LLMManager] ä½¿ç”¨çŸ¥è¯†åº“æœç´¢å¯¹è¯");
    return await this.toolsClient.chatWithKnowledgeBase(
      messages,
      knowledgeBaseId,
      options,
    );
  }

  /**
   * Function Calling å¯¹è¯
   * @param {Array} messages - æ¶ˆæ¯æ•°ç»„
   * @param {Array} functions - å¯ç”¨å‡½æ•°åˆ—è¡¨
   * @param {Object} options - é€‰é¡¹
   * @returns {Promise<Object>} APIå“åº”
   */
  async chatWithFunctionCalling(messages, functions, options = {}) {
    if (this.provider !== LLMProviders.VOLCENGINE) {
      throw new Error("å‡½æ•°è°ƒç”¨ä»…æ”¯æŒç«å±±å¼•æ“");
    }

    if (!this.toolsClient) {
      throw new Error("ç«å±±å¼•æ“å·¥å…·è°ƒç”¨å®¢æˆ·ç«¯æœªåˆå§‹åŒ–");
    }

    console.log("[LLMManager] ä½¿ç”¨å‡½æ•°è°ƒç”¨å¯¹è¯");
    return await this.toolsClient.chatWithFunctionCalling(
      messages,
      functions,
      options,
    );
  }

  /**
   * æ··åˆå¤šç§å·¥å…·çš„å¯¹è¯ï¼ˆæ™ºèƒ½ç»„åˆï¼‰
   * @param {Array} messages - æ¶ˆæ¯æ•°ç»„
   * @param {Object} toolConfig - å·¥å…·é…ç½®
   * @returns {Promise<Object>} APIå“åº”
   */
  async chatWithMultipleTools(messages, toolConfig = {}) {
    if (this.provider !== LLMProviders.VOLCENGINE) {
      throw new Error("å·¥å…·è°ƒç”¨ä»…æ”¯æŒç«å±±å¼•æ“");
    }

    if (!this.toolsClient) {
      throw new Error("ç«å±±å¼•æ“å·¥å…·è°ƒç”¨å®¢æˆ·ç«¯æœªåˆå§‹åŒ–");
    }

    console.log("[LLMManager] ä½¿ç”¨å¤šç§å·¥å…·å¯¹è¯");
    return await this.toolsClient.chatWithMultipleTools(messages, toolConfig);
  }

  // ========================================
  // ğŸ”¥ Token è¿½è¸ªå’Œé¢„ç®—ç®¡ç† API
  // ========================================

  /**
   * å¤„ç†é¢„ç®—å‘Šè­¦äº‹ä»¶ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
   * @private
   * @param {Object} alert - å‘Šè­¦è¯¦æƒ…
   */
  async _handleBudgetAlert(alert) {
    const { level, period, usage, spent, limit } = alert;

    console.warn(
      `[LLMManager] ğŸš¨ é¢„ç®—å‘Šè­¦: ${period} ä½¿ç”¨ç‡ ${(usage * 100).toFixed(1)}% ($${spent.toFixed(2)}/$${limit})`,
    );

    // å‘é€å‘Šè­¦äº‹ä»¶ç»™å¤–éƒ¨ç›‘å¬å™¨
    this.emit("budget-alert", alert);

    // å¦‚æœæ˜¯ critical çº§åˆ«ä¸”å¯ç”¨äº†è‡ªåŠ¨æš‚åœ
    if (level === "critical" && this.budgetConfig?.auto_pause_on_limit) {
      console.error("[LLMManager] â›” é¢„ç®—è¶…é™ï¼Œè‡ªåŠ¨æš‚åœ LLM æœåŠ¡");
      this.paused = true;
      this.emit("service-paused", { reason: "budget-exceeded", alert });
    }

    // å¦‚æœå¯ç”¨äº†è‡ªåŠ¨åˆ‡æ¢åˆ°æ›´ä¾¿å®œçš„æ¨¡å‹
    if (
      level === "warning" &&
      this.budgetConfig?.auto_switch_to_cheaper_model
    ) {
      console.warn("[LLMManager] ğŸ’¡ å°è¯•åˆ‡æ¢åˆ°æ›´ä¾¿å®œçš„æ¨¡å‹");
      await this._switchToCheaperModel();
    }
  }

  /**
   * åˆ‡æ¢åˆ°æ›´ä¾¿å®œçš„æ¨¡å‹ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
   * @private
   */
  async _switchToCheaperModel() {
    // æ¨¡å‹æˆæœ¬æ˜ å°„ï¼ˆä»ä½åˆ°é«˜ï¼‰
    const cheaperModels = {
      openai: ["gpt-3.5-turbo", "gpt-4o-mini"],
      anthropic: ["claude-3-haiku-20240307", "claude-3-5-haiku-20241022"],
      deepseek: ["deepseek-chat"],
      volcengine: ["doubao-lite-32k", "doubao-pro-32k"],
    };

    const currentProvider = this.provider;
    const currentModel = this.config.model;

    if (cheaperModels[currentProvider]) {
      const options = cheaperModels[currentProvider];
      const currentIndex = options.indexOf(currentModel);

      // å¦‚æœå½“å‰ä¸æ˜¯æœ€ä¾¿å®œçš„æ¨¡å‹ï¼Œåˆ‡æ¢åˆ°æ›´ä¾¿å®œçš„
      if (currentIndex > 0) {
        const newModel = options[currentIndex - 1];
        console.log(`[LLMManager] åˆ‡æ¢æ¨¡å‹: ${currentModel} â†’ ${newModel}`);

        this.config.model = newModel;
        await this.initialize();

        this.emit("model-switched", {
          from: currentModel,
          to: newModel,
          reason: "budget-optimization",
        });
      } else {
        console.warn("[LLMManager] å·²ç»åœ¨ä½¿ç”¨æœ€ä¾¿å®œçš„æ¨¡å‹ï¼Œæ— æ³•ç»§ç»­é™çº§");
      }
    }
  }

  /**
   * æ¢å¤è¢«æš‚åœçš„æœåŠ¡
   * @param {string} userId - ç”¨æˆ· ID
   */
  async resumeService(userId = "default") {
    if (!this.paused) {
      console.warn("[LLMManager] æœåŠ¡æœªæš‚åœï¼Œæ— éœ€æ¢å¤");
      return { success: false, message: "æœåŠ¡æœªæš‚åœ" };
    }

    console.log("[LLMManager] æ¢å¤ LLM æœåŠ¡");
    this.paused = false;
    this.emit("service-resumed", { userId });

    return { success: true, message: "æœåŠ¡å·²æ¢å¤" };
  }

  /**
   * æ‰‹åŠ¨æš‚åœæœåŠ¡
   */
  async pauseService() {
    if (this.paused) {
      console.warn("[LLMManager] æœåŠ¡å·²ç»æš‚åœ");
      return { success: false, message: "æœåŠ¡å·²æš‚åœ" };
    }

    console.log("[LLMManager] æ‰‹åŠ¨æš‚åœ LLM æœåŠ¡");
    this.paused = true;
    this.emit("service-paused", { reason: "manual" });

    return { success: true, message: "æœåŠ¡å·²æš‚åœ" };
  }

  /**
   * è·å–é¢„ç®—é…ç½®
   * @param {string} userId - ç”¨æˆ· ID
   * @returns {Promise<Object>}
   */
  async getBudgetConfig(userId = "default") {
    if (!this.tokenTracker) {
      throw new Error("Token è¿½è¸ªæœªå¯ç”¨");
    }

    const config = await this.tokenTracker.getBudgetConfig(userId);
    this.budgetConfig = config; // ç¼“å­˜é…ç½®
    return config;
  }

  /**
   * ä¿å­˜é¢„ç®—é…ç½®
   * @param {string} userId - ç”¨æˆ· ID
   * @param {Object} config - é¢„ç®—é…ç½®
   * @returns {Promise<Object>}
   */
  async saveBudgetConfig(userId = "default", config) {
    if (!this.tokenTracker) {
      throw new Error("Token è¿½è¸ªæœªå¯ç”¨");
    }

    const result = await this.tokenTracker.saveBudgetConfig(userId, config);

    // æ›´æ–°ç¼“å­˜
    this.budgetConfig = await this.tokenTracker.getBudgetConfig(userId);

    return result;
  }

  /**
   * è·å–ä½¿ç”¨ç»Ÿè®¡
   * @param {Object} options - æŸ¥è¯¢é€‰é¡¹
   * @returns {Promise<Object>}
   */
  async getUsageStats(options = {}) {
    if (!this.tokenTracker) {
      throw new Error("Token è¿½è¸ªæœªå¯ç”¨");
    }

    return await this.tokenTracker.getUsageStats(options);
  }

  /**
   * è·å–æ—¶é—´åºåˆ—æ•°æ®ï¼ˆç”¨äºå›¾è¡¨ï¼‰
   * @param {Object} options - æŸ¥è¯¢é€‰é¡¹
   * @returns {Promise<Array>}
   */
  async getTimeSeriesData(options = {}) {
    if (!this.tokenTracker) {
      throw new Error("Token è¿½è¸ªæœªå¯ç”¨");
    }

    return await this.tokenTracker.getTimeSeriesData(options);
  }

  /**
   * è·å–æˆæœ¬åˆ†è§£ï¼ˆæŒ‰æä¾›å•†/æ¨¡å‹ï¼‰
   * @param {Object} options - æŸ¥è¯¢é€‰é¡¹
   * @returns {Promise<Object>}
   */
  async getCostBreakdown(options = {}) {
    if (!this.tokenTracker) {
      throw new Error("Token è¿½è¸ªæœªå¯ç”¨");
    }

    return await this.tokenTracker.getCostBreakdown(options);
  }

  /**
   * å¯¼å‡ºæˆæœ¬æŠ¥å‘Š
   * @param {Object} options - å¯¼å‡ºé€‰é¡¹
   * @returns {Promise<string>} CSV æ–‡ä»¶è·¯å¾„
   */
  async exportCostReport(options = {}) {
    if (!this.tokenTracker) {
      throw new Error("Token è¿½è¸ªæœªå¯ç”¨");
    }

    return await this.tokenTracker.exportCostReport(options);
  }

  /**
   * è®¡ç®—æˆæœ¬ä¼°ç®—ï¼ˆæ”¯æŒå¤šæä¾›å•†ï¼‰
   * @param {string} provider - æä¾›å•†
   * @param {string} model - æ¨¡å‹åç§°
   * @param {number} inputTokens - è¾“å…¥ tokens
   * @param {number} outputTokens - è¾“å‡º tokens
   * @param {number} cachedTokens - ç¼“å­˜ tokens
   * @returns {Object} æˆæœ¬ä¼°ç®—ç»“æœ
   */
  calculateCostEstimate(
    provider,
    model,
    inputTokens,
    outputTokens,
    cachedTokens = 0,
  ) {
    if (!this.tokenTracker) {
      return { costUsd: 0, costCny: 0, pricing: null };
    }

    return this.tokenTracker.calculateCost(
      provider,
      model,
      inputTokens,
      outputTokens,
      cachedTokens,
    );
  }

  /**
   * æ£€æŸ¥æ˜¯å¦å¯ä»¥æ‰§è¡Œæ“ä½œï¼ˆé¢„ç®—æ£€æŸ¥ï¼‰
   * @param {number} estimatedTokens - é¢„ä¼° token æ•°é‡
   * @returns {Promise<Object>} { allowed: boolean, reason?: string }
   */
  async canPerformOperation(estimatedTokens = 0) {
    if (this.paused) {
      return {
        allowed: false,
        reason: "æœåŠ¡å·²æš‚åœï¼šé¢„ç®—è¶…é™ã€‚è¯·å‰å¾€è®¾ç½®é¡µé¢è°ƒæ•´é¢„ç®—æˆ–æ¢å¤æœåŠ¡ã€‚",
      };
    }

    if (!this.tokenTracker) {
      return { allowed: true };
    }

    // ä¼°ç®—æˆæœ¬
    const estimate = this.calculateCostEstimate(
      this.provider,
      this.config.model,
      estimatedTokens,
      estimatedTokens,
    );

    // è·å–å½“å‰é¢„ç®—çŠ¶æ€
    const budgetConfig = await this.getBudgetConfig();
    if (!budgetConfig) {
      return { allowed: true };
    }

    // æ£€æŸ¥æ˜¯å¦ä¼šè¶…å‡ºé¢„ç®—
    const dailyRemaining =
      (budgetConfig.daily_limit_usd || Infinity) -
      (budgetConfig.current_daily_spend || 0);
    const monthlyRemaining =
      (budgetConfig.monthly_limit_usd || Infinity) -
      (budgetConfig.current_monthly_spend || 0);

    if (estimate.costUsd > dailyRemaining) {
      return {
        allowed: false,
        reason: `æ“ä½œé¢„ä¼°æˆæœ¬ $${estimate.costUsd.toFixed(4)} è¶…å‡ºæ¯æ—¥å‰©ä½™é¢„ç®— $${dailyRemaining.toFixed(4)}`,
      };
    }

    if (estimate.costUsd > monthlyRemaining) {
      return {
        allowed: false,
        reason: `æ“ä½œé¢„ä¼°æˆæœ¬ $${estimate.costUsd.toFixed(4)} è¶…å‡ºæ¯æœˆå‰©ä½™é¢„ç®— $${monthlyRemaining.toFixed(4)}`,
      };
    }

    return { allowed: true };
  }

  /**
   * å…³é—­ç®¡ç†å™¨
   */
  async close() {
    console.log("[LLMManager] å…³é—­LLMç®¡ç†å™¨");

    // ç§»é™¤ TokenTracker ç›‘å¬å™¨
    if (this.tokenTracker) {
      this.tokenTracker.removeAllListeners("budget-alert");
    }

    this.conversationContext.clear();
    this.isInitialized = false;
    this.client = null;
    this.emit("closed");
  }
}

// å•ä¾‹å®ä¾‹
let llmManagerInstance = null;

/**
 * è·å–LLMç®¡ç†å™¨å•ä¾‹
 * @param {Object} config - é…ç½®å¯¹è±¡ï¼ˆä»…é¦–æ¬¡è°ƒç”¨æ—¶ç”Ÿæ•ˆï¼‰
 * @returns {LLMManager}
 */
function getLLMManager(config = {}) {
  if (!llmManagerInstance) {
    llmManagerInstance = new LLMManager(config);
  }
  return llmManagerInstance;
}

/**
 * ä¸ºLLMManageræ·»åŠ AIæ ‡ç­¾ç”Ÿæˆå’Œæ‘˜è¦ç”ŸæˆåŠŸèƒ½
 */
LLMManager.prototype.generateTags = async function ({ title, content, url }) {
  if (!this.isInitialized) {
    console.warn("[LLMManager] LLMæœåŠ¡æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨fallback");
    // Fallback: ç®€å•çš„å…³é”®è¯æå–
    return this.generateTagsFallback({ title, content, url });
  }

  try {
    // é™åˆ¶å†…å®¹é•¿åº¦
    const limitedContent = content.substring(0, 500);

    const prompt = `åˆ†æä»¥ä¸‹ç½‘é¡µå†…å®¹ï¼Œç”Ÿæˆ3-5ä¸ªæœ€ç›¸å…³çš„æ ‡ç­¾ï¼ˆä¸­æ–‡æˆ–è‹±æ–‡ï¼‰ã€‚
åªè¿”å›æ ‡ç­¾åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚

æ ‡é¢˜: ${title}
URL: ${url}
å†…å®¹: ${limitedContent}

æ ‡ç­¾:`;

    const result = await this.query(prompt, {
      temperature: 0.3,
      max_tokens: 50,
    });

    // è§£ææ ‡ç­¾
    const responseText = result.text || result.message?.content || "";
    const tags = responseText
      .split(/[,ï¼Œã€]/)
      .map((t) => t.trim())
      .filter((t) => t.length > 0 && t.length < 20)
      .slice(0, 5);

    console.log("[LLMManager] AIç”Ÿæˆæ ‡ç­¾:", tags);
    return tags;
  } catch (error) {
    console.error("[LLMManager] æ ‡ç­¾ç”Ÿæˆå¤±è´¥:", error);
    // Fallback
    return this.generateTagsFallback({ title, content, url });
  }
};

/**
 * Fallbackæ ‡ç­¾ç”Ÿæˆï¼ˆç®€å•å…³é”®è¯æå–ï¼‰
 */
LLMManager.prototype.generateTagsFallback = function ({ title, content, url }) {
  const tags = [];

  // ä»URLæå–åŸŸå
  if (url) {
    try {
      const urlObj = new URL(url);
      const domain = urlObj.hostname.split(".").slice(-2, -1)[0];
      if (domain) {
        tags.push(domain);
      }
    } catch (e) {
      // å¿½ç•¥
    }
  }

  // ä»æ ‡é¢˜æå–å…³é”®è¯
  if (title) {
    const keywords = [
      "æ•™ç¨‹",
      "æŒ‡å—",
      "æ–‡æ¡£",
      "åšå®¢",
      "æ–°é—»",
      "æŠ€æœ¯",
      "å¼€å‘",
      "Tutorial",
      "Guide",
      "Documentation",
      "Blog",
    ];
    for (const keyword of keywords) {
      if (title.toLowerCase().includes(keyword.toLowerCase())) {
        tags.push(keyword);
        if (tags.length >= 3) break;
      }
    }
  }

  return tags.slice(0, 3);
};

/**
 * ç”Ÿæˆå†…å®¹æ‘˜è¦
 */
LLMManager.prototype.generateSummary = async function ({ title, content }) {
  if (!this.isInitialized) {
    console.warn("[LLMManager] LLMæœåŠ¡æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨fallback");
    // Fallback: ç®€å•æˆªå–
    return this.generateSummaryFallback({ content });
  }

  try {
    // é™åˆ¶å†…å®¹é•¿åº¦
    const limitedContent = content.substring(0, 3000);

    const prompt = `è¯·ä¸ºä»¥ä¸‹æ–‡ç« ç”Ÿæˆä¸€æ®µç®€æ´çš„æ‘˜è¦ï¼ˆ100-200å­—ï¼‰ã€‚
åªè¿”å›æ‘˜è¦å†…å®¹ï¼Œä¸è¦å…¶ä»–è¯´æ˜ã€‚

æ ‡é¢˜: ${title}
å†…å®¹: ${limitedContent}

æ‘˜è¦:`;

    const result = await this.query(prompt, {
      temperature: 0.5,
      max_tokens: 300,
    });

    const summary = (result.text || result.message?.content || "").trim();

    console.log("[LLMManager] AIç”Ÿæˆæ‘˜è¦:", summary.substring(0, 50) + "...");
    return summary;
  } catch (error) {
    console.error("[LLMManager] æ‘˜è¦ç”Ÿæˆå¤±è´¥:", error);
    // Fallback
    return this.generateSummaryFallback({ content });
  }
};

/**
 * Fallbackæ‘˜è¦ç”Ÿæˆï¼ˆç®€å•æˆªå–ï¼‰
 */
LLMManager.prototype.generateSummaryFallback = function ({ content }) {
  // æå–çº¯æ–‡æœ¬ï¼ˆå»é™¤HTMLï¼‰
  const textContent = content.replace(/<[^>]*>/g, "").trim();

  // å–å‰200å­—
  const summary = textContent.substring(0, 200);

  return summary + (textContent.length > 200 ? "..." : "");
};

// ==========================================
// ğŸ”¥ Manus ä¼˜åŒ– API
// ==========================================

/**
 * æ„å»ºä¼˜åŒ–åçš„ Promptï¼ˆKV-Cache å‹å¥½ï¼‰
 *
 * @param {Object} options - æ„å»ºé€‰é¡¹
 * @param {string} options.systemPrompt - ç³»ç»Ÿæç¤ºè¯
 * @param {Array} options.messages - å¯¹è¯å†å²
 * @param {Array} options.tools - å·¥å…·å®šä¹‰ï¼ˆå¯é€‰ï¼‰
 * @returns {Object} ä¼˜åŒ–åçš„æ¶ˆæ¯å’Œå…ƒæ•°æ®
 */
LLMManager.prototype.buildOptimizedPrompt = function (options) {
  if (!this.manusOptimizations) {
    // ä¸ä¼˜åŒ–ï¼Œè¿”å›åŸºç¡€æ¶ˆæ¯
    const messages = [];
    if (options.systemPrompt) {
      messages.push({ role: "system", content: options.systemPrompt });
    }
    if (options.messages) {
      messages.push(...options.messages);
    }
    return { messages, metadata: { optimized: false } };
  }

  return this.manusOptimizations.buildOptimizedPrompt(options);
};

/**
 * ä½¿ç”¨ä¼˜åŒ–åçš„ Prompt è¿›è¡Œå¯¹è¯
 *
 * @param {Array} messages - æ¶ˆæ¯æ•°ç»„
 * @param {Object} options - é€‰é¡¹
 * @param {string} options.systemPrompt - ç³»ç»Ÿæç¤ºè¯
 * @param {Array} options.tools - å·¥å…·å®šä¹‰
 * @returns {Promise<Object>} å¯¹è¯ç»“æœ
 */
LLMManager.prototype.chatWithOptimizedPrompt = async function (messages, options = {}) {
  // æ„å»ºä¼˜åŒ– Prompt
  const optimized = this.buildOptimizedPrompt({
    systemPrompt: options.systemPrompt,
    messages,
    tools: options.tools,
  });

  // ä½¿ç”¨ä¼˜åŒ–åçš„æ¶ˆæ¯è¿›è¡Œå¯¹è¯
  const result = await this.chatWithMessages(optimized.messages, {
    ...options,
    skipCompression: true, // å·²ç»ä¼˜åŒ–è¿‡ï¼Œè·³è¿‡é¢å¤–å‹ç¼©
  });

  return {
    ...result,
    promptOptimization: optimized.metadata,
  };
};

/**
 * å¼€å§‹ä»»åŠ¡è¿½è¸ªï¼ˆManus todo.md æœºåˆ¶ï¼‰
 *
 * @param {Object} task - ä»»åŠ¡ä¿¡æ¯
 * @param {string} task.objective - ä»»åŠ¡ç›®æ ‡
 * @param {Array} task.steps - ä»»åŠ¡æ­¥éª¤
 * @returns {Object} ä»»åŠ¡ä¿¡æ¯
 */
LLMManager.prototype.startTask = function (task) {
  if (!this.manusOptimizations) {
    console.warn("[LLMManager] Manus ä¼˜åŒ–æœªå¯ç”¨ï¼Œæ— æ³•è¿½è¸ªä»»åŠ¡");
    return null;
  }
  return this.manusOptimizations.startTask(task);
};

/**
 * æ›´æ–°ä»»åŠ¡è¿›åº¦
 *
 * @param {number} stepIndex - å½“å‰æ­¥éª¤ç´¢å¼•
 * @param {string} status - çŠ¶æ€
 */
LLMManager.prototype.updateTaskProgress = function (stepIndex, status) {
  if (!this.manusOptimizations) return;
  this.manusOptimizations.updateTaskProgress(stepIndex, status);
};

/**
 * å®Œæˆå½“å‰æ­¥éª¤
 */
LLMManager.prototype.completeCurrentStep = function () {
  if (!this.manusOptimizations) return;
  this.manusOptimizations.completeCurrentStep();
};

/**
 * å®Œæˆä»»åŠ¡
 */
LLMManager.prototype.completeTask = function () {
  if (!this.manusOptimizations) return;
  this.manusOptimizations.completeTask();
};

/**
 * å–æ¶ˆä»»åŠ¡
 */
LLMManager.prototype.cancelTask = function () {
  if (!this.manusOptimizations) return;
  this.manusOptimizations.cancelTask();
};

/**
 * è·å–å½“å‰ä»»åŠ¡
 * @returns {Object|null} å½“å‰ä»»åŠ¡
 */
LLMManager.prototype.getCurrentTask = function () {
  if (!this.manusOptimizations) return null;
  return this.manusOptimizations.getCurrentTask();
};

/**
 * è®°å½•é”™è¯¯ï¼ˆä¾›æ¨¡å‹å­¦ä¹ ï¼‰
 * @param {Object} error - é”™è¯¯ä¿¡æ¯
 */
LLMManager.prototype.recordError = function (error) {
  if (!this.manusOptimizations) return;
  this.manusOptimizations.recordError(error);
};

/**
 * è®¾ç½®å·¥å…·å¯ç”¨æ€§
 * @param {string} toolName - å·¥å…·åç§°
 * @param {boolean} available - æ˜¯å¦å¯ç”¨
 */
LLMManager.prototype.setToolAvailable = function (toolName, available) {
  if (!this.manusOptimizations) return;
  this.manusOptimizations.setToolAvailable(toolName, available);
};

/**
 * æŒ‰å‰ç¼€è®¾ç½®å·¥å…·å¯ç”¨æ€§
 * @param {string} prefix - å·¥å…·å‰ç¼€
 * @param {boolean} available - æ˜¯å¦å¯ç”¨
 */
LLMManager.prototype.setToolsByPrefix = function (prefix, available) {
  if (!this.manusOptimizations) return;
  this.manusOptimizations.setToolsByPrefix(prefix, available);
};

/**
 * éªŒè¯å·¥å…·è°ƒç”¨
 * @param {string} toolName - å·¥å…·åç§°
 * @returns {Object} éªŒè¯ç»“æœ
 */
LLMManager.prototype.validateToolCall = function (toolName) {
  if (!this.manusOptimizations) {
    return { allowed: true };
  }
  return this.manusOptimizations.validateToolCall(toolName);
};

/**
 * é…ç½®ä»»åŠ¡é˜¶æ®µçŠ¶æ€æœº
 * @param {Object} config - çŠ¶æ€æœºé…ç½®ï¼ˆå¯é€‰ï¼‰
 */
LLMManager.prototype.configureTaskPhases = function (config) {
  if (!this.manusOptimizations) return;
  this.manusOptimizations.configureTaskPhases(config);
};

/**
 * åˆ‡æ¢åˆ°æŒ‡å®šé˜¶æ®µ
 * @param {string} phase - é˜¶æ®µåç§°
 * @returns {boolean} æ˜¯å¦æˆåŠŸ
 */
LLMManager.prototype.transitionToPhase = function (phase) {
  if (!this.manusOptimizations) return false;
  return this.manusOptimizations.transitionToPhase(phase);
};

/**
 * è·å– Manus ä¼˜åŒ–ç»Ÿè®¡
 * @returns {Object} ç»Ÿè®¡æ•°æ®
 */
LLMManager.prototype.getManusStats = function () {
  if (!this.manusOptimizations) {
    return { enabled: false };
  }
  return {
    enabled: true,
    ...this.manusOptimizations.getStats(),
  };
};

/**
 * å‹ç¼©å†…å®¹ï¼ˆå¯æ¢å¤å‹ç¼©ï¼‰
 * @param {any} content - åŸå§‹å†…å®¹
 * @param {string} type - å†…å®¹ç±»å‹
 * @returns {Object} å‹ç¼©åçš„å¼•ç”¨
 */
LLMManager.prototype.compressContent = function (content, type) {
  if (!this.manusOptimizations) return content;
  return this.manusOptimizations.compress(content, type);
};

module.exports = {
  LLMManager,
  LLMProviders,
  getLLMManager,
  TaskTypes, // å¯¼å‡ºä»»åŠ¡ç±»å‹æšä¸¾ï¼Œæ–¹ä¾¿å¤–éƒ¨ä½¿ç”¨
};
