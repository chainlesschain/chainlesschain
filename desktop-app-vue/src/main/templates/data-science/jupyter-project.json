{
  "id": "tpl_data_jupyter_004",
  "name": "jupyter_notebook_project_template",
  "display_name": "Jupyter Notebooké¡¹ç›®",
  "description": "åˆ›å»ºç»“æ„åŒ–çš„Jupyter Notebookæ•°æ®åˆ†æé¡¹ç›®ï¼ŒåŒ…å«æ¨¡æ¿notebookå’Œæœ€ä½³å®è·µ",
  "icon": "ğŸ““",
  "category": "data-science",
  "subcategory": "notebook",
  "tags": [
    "Jupyter",
    "Notebook",
    "æ•°æ®åˆ†æ",
    "Python"
  ],
  "project_type": "app",
  "prompt_template": "è¯·å¸®æˆ‘ç”ŸæˆJupyter Notebooké¡¹ç›®æ¡†æ¶ï¼Œè¦æ±‚:\n\n**é¡¹ç›®ä¿¡æ¯ï¼š**\n- é¡¹ç›®åç§°ï¼š{{projectName}}\n- åˆ†æç±»å‹ï¼š{{analysisType}}\n- æ•°æ®æºï¼š{{dataSource}}\n\n**é¡¹ç›®ç»“æ„ï¼š**\n\n```\n{{projectName}}/\nâ”œâ”€â”€ notebooks/\nâ”‚   â”œâ”€â”€ 00_README.md\nâ”‚   â”œâ”€â”€ 01_Data_Loading.ipynb\nâ”‚   â”œâ”€â”€ 02_EDA.ipynb\nâ”‚   â”œâ”€â”€ 03_Data_Cleaning.ipynb\nâ”‚   â”œâ”€â”€ 04_Feature_Engineering.ipynb\nâ”‚   â”œâ”€â”€ 05_Modeling.ipynb\nâ”‚   â”œâ”€â”€ 06_Results_Visualization.ipynb\nâ”‚   â””â”€â”€ 07_Report.ipynb\nâ”‚\nâ”œâ”€â”€ data/\nâ”‚   â”œâ”€â”€ raw/              # åŸå§‹æ•°æ®ï¼ˆä¸ä¿®æ”¹ï¼‰\nâ”‚   â”œâ”€â”€ interim/          # ä¸­é—´å¤„ç†æ•°æ®\nâ”‚   â”œâ”€â”€ processed/        # æœ€ç»ˆæ•°æ®\nâ”‚   â””â”€â”€ external/         # å¤–éƒ¨å‚è€ƒæ•°æ®\nâ”‚\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”œâ”€â”€ data/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â””â”€â”€ data_utils.py\nâ”‚   â”œâ”€â”€ features/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â””â”€â”€ feature_engineering.py\nâ”‚   â””â”€â”€ visualization/\nâ”‚       â”œâ”€â”€ __init__.py\nâ”‚       â””â”€â”€ plot_utils.py\nâ”‚\nâ”œâ”€â”€ outputs/\nâ”‚   â”œâ”€â”€ figures/          # ç”Ÿæˆçš„å›¾è¡¨\nâ”‚   â”œâ”€â”€ models/           # ä¿å­˜çš„æ¨¡å‹\nâ”‚   â””â”€â”€ reports/          # è¾“å‡ºæŠ¥å‘Š\nâ”‚\nâ”œâ”€â”€ requirements.txt\nâ”œâ”€â”€ environment.yml       # Condaç¯å¢ƒ\nâ”œâ”€â”€ .gitignore\nâ””â”€â”€ README.md\n```\n\n**requirements.txtï¼š**\n\n```\n# Jupyter\njupyter==1.0.0\njupyterlab==4.0.9\nipywidgets==8.1.1\n\n# æ•°æ®å¤„ç†\npandas==2.1.3\nnumpy==1.26.2\nscipy==1.11.4\n\n# å¯è§†åŒ–\nmatplotlib==3.8.2\nseaborn==0.13.0\nplotly==5.18.0\n\n{{#eq analysisType \"æœºå™¨å­¦ä¹ \"}}\n# æœºå™¨å­¦ä¹ \nscikit-learn==1.3.2\nxgboost==2.0.2\n{{/eq}}\n\n{{#eq analysisType \"æ·±åº¦å­¦ä¹ \"}}\n# æ·±åº¦å­¦ä¹ \ntensorflow==2.15.0\ntorch==2.1.0\n{{/eq}}\n\n# æ•°æ®åº“\nsqlalchemy==2.0.23\n\n# å·¥å…·\ntqdm==4.66.1\njoblib==1.3.2\n```\n\n**notebooks/01_Data_Loading.ipynbç¤ºä¾‹ï¼š**\n\n```markdown\n# æ•°æ®åŠ è½½\n\n**ç›®æ ‡**ï¼šåŠ è½½å’Œåˆæ­¥æ£€æŸ¥æ•°æ®\n\n**ä½œè€…**ï¼š{{analyst}}\n**æ—¥æœŸ**ï¼š{{date}}\n\n## 1. å¯¼å…¥åº“\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# è®¾ç½®æ˜¾ç¤ºé€‰é¡¹\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\n# è®¾ç½®å¯è§†åŒ–æ ·å¼\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.rcParams['font.sans-serif'] = ['SimHei']  # ä¸­æ–‡æ˜¾ç¤º\nplt.rcParams['axes.unicode_minus'] = False\n\nprint('âœ… åº“å¯¼å…¥æˆåŠŸ')\n```\n\n## 2. åŠ è½½æ•°æ®\n```python\n# è¯»å–æ•°æ®\ndf = pd.read_csv('../data/raw/{{dataFile}}')\n\nprint(f'æ•°æ®å½¢çŠ¶: {df.shape}')\nprint(f'è¡Œæ•°: {df.shape[0]:,}')\nprint(f'åˆ—æ•°: {df.shape[1]}')\n```\n\n## 3. æ•°æ®æ¦‚è§ˆ\n```python\n# å‰å‡ è¡Œ\ndf.head()\n```\n\n```python\n# æ•°æ®ä¿¡æ¯\ndf.info()\n```\n\n```python\n# æè¿°æ€§ç»Ÿè®¡\ndf.describe()\n```\n\n```python\n# æ•°æ®ç±»å‹åˆ†å¸ƒ\nprint('æ•°å€¼å‹åˆ—:', df.select_dtypes(include=[np.number]).columns.tolist())\nprint('ç±»åˆ«å‹åˆ—:', df.select_dtypes(include=['object']).columns.tolist())\nprint('æ—¥æœŸå‹åˆ—:', df.select_dtypes(include=['datetime']).columns.tolist())\n```\n\n## 4. åˆæ­¥æ£€æŸ¥\n```python\n# ç¼ºå¤±å€¼æ£€æŸ¥\nmissing = df.isnull().sum()\nmissing_pct = 100 * missing / len(df)\n\nmissing_df = pd.DataFrame({\n    'ç¼ºå¤±æ•°é‡': missing,\n    'ç¼ºå¤±æ¯”ä¾‹(%)': missing_pct\n})\n\nmissing_df = missing_df[missing_df['ç¼ºå¤±æ•°é‡'] > 0].sort_values('ç¼ºå¤±æ•°é‡', ascending=False)\n\nif len(missing_df) > 0:\n    print('âš ï¸  å­˜åœ¨ç¼ºå¤±å€¼ï¼š')\n    display(missing_df)\nelse:\n    print('âœ… æ— ç¼ºå¤±å€¼')\n```\n\n```python\n# é‡å¤å€¼æ£€æŸ¥\nduplicates = df.duplicated().sum()\nprint(f'é‡å¤è¡Œæ•°: {duplicates} ({100*duplicates/len(df):.2f}%)')\n```\n\n## 5. ä¿å­˜åˆ°ä¸­é—´æ•°æ®\n```python\ndf.to_csv('../data/interim/data_loaded.csv', index=False)\nprint('âœ… æ•°æ®å·²ä¿å­˜åˆ° data/interim/data_loaded.csv')\n```\n\n## 6. å°ç»“\n\n- æ•°æ®è¡Œæ•°ï¼š{df.shape[0]:,}\n- æ•°æ®åˆ—æ•°ï¼š{df.shape[1]}\n- ç¼ºå¤±å€¼æƒ…å†µï¼š[æ€»ç»“]\n- é‡å¤å€¼æƒ…å†µï¼š[æ€»ç»“]\n- **ä¸‹ä¸€æ­¥**ï¼šè¿›è¡Œæ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰\n```\n\n**notebooks/02_EDA.ipynbç¤ºä¾‹å¤§çº²ï¼š**\n\n```markdown\n# æ¢ç´¢æ€§æ•°æ®åˆ†æ(EDA)\n\n## 1. å•å˜é‡åˆ†æ\n- æ•°å€¼å˜é‡åˆ†å¸ƒ\n- ç±»åˆ«å˜é‡é¢‘æ•°\n- å¼‚å¸¸å€¼æ£€æµ‹\n\n## 2. åŒå˜é‡åˆ†æ\n- ç›¸å…³æ€§åˆ†æ\n- æ•£ç‚¹å›¾çŸ©é˜µ\n- åˆ†ç»„ç»Ÿè®¡\n\n## 3. å¤šå˜é‡åˆ†æ\n- PCAé™ç»´\n- èšç±»åˆ†æ\n\n## 4. å…³é”®å‘ç°\n- æ´å¯Ÿ1\n- æ´å¯Ÿ2\n- æ´å¯Ÿ3\n```\n\n**src/data/data_utils.pyï¼ˆå·¥å…·å‡½æ•°ï¼‰ï¼š**\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndef load_data(file_path, **kwargs):\n    \"\"\"\n    åŠ è½½æ•°æ®\n    \n    Parameters:\n    -----------\n    file_path : str\n        æ•°æ®æ–‡ä»¶è·¯å¾„\n    **kwargs : dict\n        pd.read_csvçš„å…¶ä»–å‚æ•°\n    \n    Returns:\n    --------\n    df : DataFrame\n    \"\"\"\n    try:\n        df = pd.read_csv(file_path, **kwargs)\n        print(f'âœ… æˆåŠŸåŠ è½½æ•°æ®: {df.shape}')\n        return df\n    except Exception as e:\n        print(f'âŒ åŠ è½½å¤±è´¥: {e}')\n        return None\n\ndef check_missing(df):\n    \"\"\"\n    æ£€æŸ¥ç¼ºå¤±å€¼\n    \"\"\"\n    missing = df.isnull().sum()\n    missing_pct = 100 * missing / len(df)\n    \n    missing_df = pd.DataFrame({\n        'ç¼ºå¤±æ•°é‡': missing,\n        'ç¼ºå¤±æ¯”ä¾‹(%)': missing_pct\n    })\n    \n    return missing_df[missing_df['ç¼ºå¤±æ•°é‡'] > 0].sort_values('ç¼ºå¤±æ•°é‡', ascending=False)\n\ndef check_duplicates(df):\n    \"\"\"\n    æ£€æŸ¥é‡å¤å€¼\n    \"\"\"\n    duplicates = df.duplicated().sum()\n    return {\n        'count': duplicates,\n        'percentage': 100 * duplicates / len(df)\n    }\n\ndef detect_outliers(df, column, method='iqr'):\n    \"\"\"\n    æ£€æµ‹å¼‚å¸¸å€¼\n    \n    Parameters:\n    -----------\n    df : DataFrame\n    column : str\n        åˆ—å\n    method : str\n        'iqr' æˆ– 'zscore'\n    \n    Returns:\n    --------\n    outliers : Series\n        å¼‚å¸¸å€¼çš„å¸ƒå°”ç´¢å¼•\n    \"\"\"\n    if method == 'iqr':\n        Q1 = df[column].quantile(0.25)\n        Q3 = df[column].quantile(0.75)\n        IQR = Q3 - Q1\n        \n        lower_bound = Q1 - 1.5 * IQR\n        upper_bound = Q3 + 1.5 * IQR\n        \n        outliers = (df[column] < lower_bound) | (df[column] > upper_bound)\n        \n    elif method == 'zscore':\n        from scipy import stats\n        z_scores = np.abs(stats.zscore(df[column].dropna()))\n        outliers = z_scores > 3\n    \n    return outliers\n```\n\n**src/visualization/plot_utils.pyï¼š**\n\n```python\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\ndef plot_distribution(df, column, figsize=(10, 6)):\n    \"\"\"\n    ç»˜åˆ¶åˆ†å¸ƒå›¾\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=figsize)\n    \n    # ç›´æ–¹å›¾\n    axes[0].hist(df[column].dropna(), bins=30, edgecolor='black')\n    axes[0].set_title(f'{column} åˆ†å¸ƒ')\n    axes[0].set_xlabel(column)\n    axes[0].set_ylabel('é¢‘æ•°')\n    \n    # ç®±çº¿å›¾\n    axes[1].boxplot(df[column].dropna())\n    axes[1].set_title(f'{column} ç®±çº¿å›¾')\n    axes[1].set_ylabel(column)\n    \n    plt.tight_layout()\n    return fig\n\ndef plot_correlation_matrix(df, figsize=(12, 10)):\n    \"\"\"\n    ç»˜åˆ¶ç›¸å…³æ€§çŸ©é˜µ\n    \"\"\"\n    numeric_df = df.select_dtypes(include=[np.number])\n    corr = numeric_df.corr()\n    \n    plt.figure(figsize=figsize)\n    sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', \n                center=0, square=True, linewidths=1)\n    plt.title('ç›¸å…³æ€§çŸ©é˜µ')\n    plt.tight_layout()\n    return plt.gcf()\n\ndef plot_categorical(df, column, top_n=10, figsize=(10, 6)):\n    \"\"\"\n    ç»˜åˆ¶ç±»åˆ«å˜é‡æ¡å½¢å›¾\n    \"\"\"\n    value_counts = df[column].value_counts().head(top_n)\n    \n    plt.figure(figsize=figsize)\n    value_counts.plot(kind='barh')\n    plt.title(f'{column} Top {top_n}')\n    plt.xlabel('æ•°é‡')\n    plt.tight_layout()\n    return plt.gcf()\n```\n\n**Jupyter Notebookæœ€ä½³å®è·µï¼š**\n\n### 1. ä»£ç ç»„ç»‡\n\n**å•å…ƒæ ¼ç»“æ„**ï¼š\n```markdown\n## å¤§æ ‡é¢˜\næè¿°è¿™éƒ¨åˆ†çš„ç›®æ ‡\n\n### å­æ ‡é¢˜\nå…·ä½“åˆ†ææ­¥éª¤\n```\n\n**ä»£ç +æ³¨é‡Š**ï¼š\n```python\n# 1. åŠ è½½æ•°æ®\ndf = pd.read_csv('data.csv')\n\n# 2. æ£€æŸ¥æ•°æ®\nprint(df.shape)  # (1000, 10)\n\n# 3. å¯è§†åŒ–\ndf.hist(figsize=(12, 8))\n```\n\n### 2. Markdownä½¿ç”¨\n\n**æ ‡é¢˜å±‚çº§**ï¼š\n```markdown\n# H1 - Notebookæ ‡é¢˜\n## H2 - ä¸»è¦ç« èŠ‚\n### H3 - å­ç« èŠ‚\n#### H4 - è¯¦ç»†å†…å®¹\n```\n\n**æ ¼å¼åŒ–**ï¼š\n```markdown\n**ç²—ä½“**\n*æ–œä½“*\n`ä»£ç `\n- åˆ—è¡¨é¡¹\n1. ç¼–å·åˆ—è¡¨\n```\n\n**æ•°å­¦å…¬å¼**ï¼š\n```markdown\nè¡Œå†…å…¬å¼ï¼š$y = wx + b$\n\nç‹¬ç«‹å…¬å¼ï¼š\n$$\nf(x) = \\frac{1}{1 + e^{-x}}\n$$\n```\n\n### 3. ä»£ç é£æ ¼\n\n**å¯¼å…¥è§„èŒƒ**ï¼š\n```python\n# æ ‡å‡†åº“\nimport os\nimport sys\n\n# ç¬¬ä¸‰æ–¹åº“\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# è‡ªå®šä¹‰æ¨¡å—\nfrom src.data import data_utils\n```\n\n**é­”æ³•å‘½ä»¤**ï¼š\n```python\n# è‡ªåŠ¨é‡è½½æ¨¡å—\n%load_ext autoreload\n%autoreload 2\n\n# å†…è”æ˜¾ç¤ºå›¾è¡¨\n%matplotlib inline\n\n# è®¡æ—¶\n%time operation()\n%timeit operation()\n\n# è°ƒè¯•\n%debug\n```\n\n### 4. è¾“å‡ºç®¡ç†\n\n**æ§åˆ¶è¾“å‡º**ï¼š\n```python\n# æŠ‘åˆ¶è¾“å‡º\n_ = df.hist()\n\n# é™åˆ¶è¡Œæ•°\npd.set_option('display.max_rows', 20)\n\n# æ˜¾ç¤ºå…¨éƒ¨åˆ—\npd.set_option('display.max_columns', None)\n```\n\n**ä¿å­˜è¾“å‡º**ï¼š\n```python\n# ä¿å­˜å›¾è¡¨\nplt.savefig('outputs/figures/plot.png', dpi=300, bbox_inches='tight')\n\n# ä¿å­˜æ•°æ®\ndf.to_csv('outputs/processed_data.csv', index=False)\n```\n\n### 5. ç‰ˆæœ¬æ§åˆ¶\n\n**.gitignoreï¼š**\n```\n# Jupyter\n.ipynb_checkpoints/\n*.ipynb_checkpoints\n\n# æ•°æ®\ndata/raw/*.csv\ndata/interim/*.csv\ndata/processed/*.csv\n\n# è¾“å‡º\noutputs/figures/*.png\noutputs/models/*.pkl\n\n# Python\n__pycache__/\n*.pyc\n```\n\n**æ¸…é™¤è¾“å‡ºåæäº¤**ï¼š\n```bash\n# å®‰è£…nbstripout\npip install nbstripout\n\n# é…ç½®è‡ªåŠ¨æ¸…é™¤\nnbstripout --install\n```\n\n### 6. åä½œæŠ€å·§\n\n**å‘½åè§„èŒƒ**ï¼š\n- ä½¿ç”¨ç¼–å·ï¼š01_ã€02_ã€03_\n- æè¿°æ€§åç§°ï¼šEDAã€Modeling\n- é¿å…ç©ºæ ¼ï¼šç”¨ä¸‹åˆ’çº¿_\n\n**æ–‡æ¡£åŒ–**ï¼š\n- æ¯ä¸ªnotebookå¼€å¤´è¯´æ˜ç›®æ ‡\n- è®°å½•å…³é”®å‘ç°\n- æ ‡æ³¨å¾…åŠäº‹é¡¹ï¼ˆTODOï¼‰\n\n**æ¨¡å—åŒ–**ï¼š\n- é€šç”¨å‡½æ•°æ”¾src/\n- Notebookåªä¿ç•™åˆ†æé€»è¾‘\n- é¿å…é‡å¤ä»£ç \n\n**å¯¼å‡ºæŠ¥å‘Š**ï¼š\n```bash\n# è½¬æ¢ä¸ºHTML\njupyter nbconvert --to html notebook.ipynb\n\n# è½¬æ¢ä¸ºPDF\njupyter nbconvert --to pdf notebook.ipynb\n\n# è½¬æ¢ä¸ºPythonè„šæœ¬\njupyter nbconvert --to script notebook.ipynb\n```",
  "variables_schema": [
    {
      "name": "projectName",
      "label": "é¡¹ç›®åç§°",
      "type": "string",
      "required": true,
      "placeholder": "ä¾‹å¦‚ï¼šsales-analysis"
    },
    {
      "name": "analysisType",
      "label": "åˆ†æç±»å‹",
      "type": "select",
      "required": false,
      "default": "æ•°æ®åˆ†æ",
      "options": [
        {
          "value": "æ•°æ®åˆ†æ",
          "label": "æ•°æ®åˆ†æ"
        },
        {
          "value": "æœºå™¨å­¦ä¹ ",
          "label": "æœºå™¨å­¦ä¹ "
        },
        {
          "value": "æ·±åº¦å­¦ä¹ ",
          "label": "æ·±åº¦å­¦ä¹ "
        },
        {
          "value": "ç»Ÿè®¡åˆ†æ",
          "label": "ç»Ÿè®¡åˆ†æ"
        }
      ]
    },
    {
      "name": "dataSource",
      "label": "æ•°æ®æ¥æº",
      "type": "string",
      "required": false,
      "default": "CSVæ–‡ä»¶",
      "placeholder": "ä¾‹å¦‚ï¼šCSVã€æ•°æ®åº“ã€API"
    },
    {
      "name": "analyst",
      "label": "åˆ†æå¸ˆå§“å",
      "type": "string",
      "required": false,
      "default": "æ•°æ®åˆ†æå¸ˆ",
      "placeholder": "æ‚¨çš„å§“å"
    }
  ],
  "file_structure": {
    "root": "{{projectName}}",
    "files": [
      {
        "path": "README.md",
        "type": "markdown"
      },
      {
        "path": "requirements.txt",
        "type": "document"
      },
      {
        "path": "environment.yml",
        "type": "document"
      },
      {
        "path": ".gitignore",
        "type": "document"
      }
    ]
  },
  "default_files": [],
  "is_builtin": true,
  "author": "ChainlessChain Team",
  "version": "1.0.0",
  "usage_count": 0,
  "rating": 0,
  "rating_count": 0,
  "required_skills": [
    "skill_data_science",
    "skill_data_analysis",
    "skill_code_development"
  ],
  "required_tools": [
    "tool_data_preprocessor",
    "tool_chart_generator",
    "tool_python_project_setup"
  ],
  "execution_engine": "ml"
}