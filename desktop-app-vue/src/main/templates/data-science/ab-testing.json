{
  "id": "tpl_ds_abtest_008",
  "name": "ab_testing",
  "display_name": "A/Bæµ‹è¯•åˆ†æ",
  "description": "åœ¨çº¿å®éªŒè®¾è®¡ä¸ç»Ÿè®¡åˆ†æï¼ŒåŒ…å«æ ·æœ¬é‡è®¡ç®—ã€å‡è®¾æ£€éªŒã€å¤šè‡‚è€è™æœºç­‰æ–¹æ³•",
  "icon": "ğŸ§ª",
  "category": "data-science",
  "subcategory": "experiment",
  "tags": [
    "A/Bæµ‹è¯•",
    "å‡è®¾æ£€éªŒ",
    "å®éªŒè®¾è®¡",
    "è½¬åŒ–ç‡ä¼˜åŒ–",
    "ç»Ÿè®¡æ¨æ–­"
  ],
  "project_type": "code",
  "prompt_template": "A/Bæµ‹è¯•åˆ†æé¡¹ç›®\n\n**å®éªŒä¿¡æ¯ï¼š**\n- å®éªŒåç§°ï¼š{{experimentName}}\n- æµ‹è¯•æŒ‡æ ‡ï¼š{{primaryMetric}}\n- å®éªŒç±»å‹ï¼š{{testType}}\n- æ˜¾è‘—æ€§æ°´å¹³ï¼š{{significanceLevel}}\n\n# A/Bæµ‹è¯•å®Œæ•´æµç¨‹\n\n## 1. é¡¹ç›®è®¾ç½®\n\n### 1.1 ç¯å¢ƒé…ç½®\n\n```python\n# requirements.txt\npandas>=2.0.0\nnumpy>=1.24.0\nscipy>=1.10.0\nmatplotlib>=3.7.0\nseaborn>=0.12.0\nstatsmodels>=0.14.0\nscikit-learn>=1.3.0\nplotly>=5.14.0\n```\n\n```bash\npip install -r requirements.txt\n```\n\n### 1.2 å¯¼å…¥åº“\n\n```python\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm, chi2_contingency, mannwhitneyu\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ç»Ÿè®¡æ£€éªŒ\nfrom statsmodels.stats.power import zt_ind_solve_power\nfrom statsmodels.stats.proportion import proportions_ztest, proportion_confint\nfrom statsmodels.stats.weightstats import ttest_ind\n\n# å¯è§†åŒ–\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\n\n# è®¾ç½®æ ·å¼\nplt.style.use('seaborn-v0_8')\nsns.set_palette(\"Set2\")\n```\n\n---\n\n## 2. å®éªŒè®¾è®¡\n\n### 2.1 å®éªŒå‚æ•°è®¾å®š\n\n```python\n# å®éªŒé…ç½®\nEXPERIMENT_CONFIG = {\n    'name': '{{experimentName}}',\n    'primary_metric': '{{primaryMetric}}',\n    'test_type': '{{testType}}',  # 'proportion' æˆ– 'mean'\n    'significance_level': {{significanceLevel}},  # Î±, é€šå¸¸ 0.05\n    'statistical_power': {{statisticalPower}},  # 1-Î², é€šå¸¸ 0.8\n    'mde': {{minimumDetectableEffect}},  # æœ€å°å¯æ£€æµ‹æ•ˆåº” (Minimum Detectable Effect)\n    'baseline_rate': {{baselineRate}},  # åŸºçº¿è½¬åŒ–ç‡\n    'traffic_split': [0.5, 0.5],  # æµé‡åˆ†é…æ¯”ä¾‹ [å¯¹ç…§ç»„, å®éªŒç»„]\n}\n\nprint(\"å®éªŒé…ç½®:\")\nfor key, value in EXPERIMENT_CONFIG.items():\n    print(f\"  {key}: {value}\")\n```\n\n### 2.2 æ ·æœ¬é‡è®¡ç®—\n\n{{#eq testType \"proportion\"}}\n```python\ndef calculate_sample_size_proportion(p1, p2, alpha=0.05, power=0.8):\n    \"\"\"\n    è®¡ç®—æ¯”ä¾‹æ£€éªŒæ‰€éœ€æ ·æœ¬é‡\n    \n    å‚æ•°:\n        p1: å¯¹ç…§ç»„è½¬åŒ–ç‡\n        p2: å®éªŒç»„è½¬åŒ–ç‡\n        alpha: æ˜¾è‘—æ€§æ°´å¹³\n        power: ç»Ÿè®¡åŠŸæ•ˆ\n    \n    è¿”å›:\n        æ¯ç»„æ‰€éœ€æ ·æœ¬é‡\n    \"\"\"\n    # æ•ˆåº”é‡\n    effect_size = abs(p2 - p1) / np.sqrt(p1 * (1 - p1))\n    \n    # ä½¿ç”¨åŠŸæ•ˆåˆ†æ\n    sample_size = zt_ind_solve_power(\n        effect_size=effect_size,\n        alpha=alpha,\n        power=power,\n        ratio=1.0,\n        alternative='two-sided'\n    )\n    \n    return int(np.ceil(sample_size))\n\n# è®¡ç®—æ ·æœ¬é‡\nbaseline = EXPERIMENT_CONFIG['baseline_rate']\nmde = EXPERIMENT_CONFIG['mde']\nexpected_rate = baseline * (1 + mde)  # æœŸæœ›æå‡åçš„è½¬åŒ–ç‡\n\nsample_size_per_group = calculate_sample_size_proportion(\n    baseline, \n    expected_rate,\n    alpha=EXPERIMENT_CONFIG['significance_level'],\n    power=EXPERIMENT_CONFIG['statistical_power']\n)\n\ntotal_sample_size = sample_size_per_group * 2\n\nprint(\"\\næ ·æœ¬é‡è®¡ç®—:\")\nprint(\"=\"*60)\nprint(f\"åŸºçº¿è½¬åŒ–ç‡: {baseline:.2%}\")\nprint(f\"æœŸæœ›è½¬åŒ–ç‡: {expected_rate:.2%}\")\nprint(f\"ç›¸å¯¹æå‡: {mde:.2%}\")\nprint(f\"ç»å¯¹æå‡: {(expected_rate - baseline):.4f}\")\nprint(f\"\\næ¯ç»„æ‰€éœ€æ ·æœ¬é‡: {sample_size_per_group:,}\")\nprint(f\"æ€»æ ·æœ¬é‡: {total_sample_size:,}\")\n```\n{{/eq}}\n\n{{#eq testType \"mean\"}}\n```python\ndef calculate_sample_size_mean(mean1, std, mde, alpha=0.05, power=0.8):\n    \"\"\"\n    è®¡ç®—å‡å€¼æ£€éªŒæ‰€éœ€æ ·æœ¬é‡\n    \n    å‚æ•°:\n        mean1: å¯¹ç…§ç»„å‡å€¼\n        std: æ ‡å‡†å·®\n        mde: æœ€å°å¯æ£€æµ‹å·®å¼‚\n        alpha: æ˜¾è‘—æ€§æ°´å¹³\n        power: ç»Ÿè®¡åŠŸæ•ˆ\n    \n    è¿”å›:\n        æ¯ç»„æ‰€éœ€æ ·æœ¬é‡\n    \"\"\"\n    # Cohen's d æ•ˆåº”é‡\n    effect_size = mde / std\n    \n    sample_size = zt_ind_solve_power(\n        effect_size=effect_size,\n        alpha=alpha,\n        power=power,\n        ratio=1.0,\n        alternative='two-sided'\n    )\n    \n    return int(np.ceil(sample_size))\n\n# è®¡ç®—æ ·æœ¬é‡\nbaseline_mean = {{baselineMean}}\nstd_dev = {{standardDeviation}}\nmde_value = {{mdeValue}}\n\nsample_size_per_group = calculate_sample_size_mean(\n    baseline_mean,\n    std_dev,\n    mde_value,\n    alpha=EXPERIMENT_CONFIG['significance_level'],\n    power=EXPERIMENT_CONFIG['statistical_power']\n)\n\ntotal_sample_size = sample_size_per_group * 2\n\nprint(\"\\næ ·æœ¬é‡è®¡ç®—:\")\nprint(\"=\"*60)\nprint(f\"åŸºçº¿å‡å€¼: {baseline_mean:.2f}\")\nprint(f\"æ ‡å‡†å·®: {std_dev:.2f}\")\nprint(f\"æœ€å°å¯æ£€æµ‹å·®å¼‚: {mde_value:.2f}\")\nprint(f\"\\næ¯ç»„æ‰€éœ€æ ·æœ¬é‡: {sample_size_per_group:,}\")\nprint(f\"æ€»æ ·æœ¬é‡: {total_sample_size:,}\")\n```\n{{/eq}}\n\n### 2.3 å®éªŒæ—¶é•¿ä¼°ç®—\n\n```python\ndaily_traffic = {{dailyTraffic}}  # æ¯æ—¥æµé‡\ntraffic_to_experiment = {{trafficAllocation}}  # åˆ†é…ç»™å®éªŒçš„æµé‡æ¯”ä¾‹\n\ndaily_experimental_users = daily_traffic * traffic_to_experiment\ndays_needed = np.ceil(total_sample_size / daily_experimental_users)\n\nprint(f\"\\nå®éªŒæ—¶é•¿ä¼°ç®—:\")\nprint(f\"æ¯æ—¥æ€»æµé‡: {daily_traffic:,}\")\nprint(f\"æ¯æ—¥å®éªŒæµé‡: {daily_experimental_users:,.0f}\")\nprint(f\"é¢„è®¡å®éªŒå¤©æ•°: {days_needed:.0f}å¤©\")\nprint(f\"é¢„è®¡ç»“æŸæ—¥æœŸ: {pd.Timestamp.now() + pd.Timedelta(days=days_needed)}\")\n```\n\n---\n\n## 3. æ•°æ®é‡‡é›†ä¸é¢„å¤„ç†\n\n### 3.1 æ•°æ®åŠ è½½\n\n```python\n# è¯»å–å®éªŒæ•°æ®\ndf = pd.read_csv('{{experimentDataFile}}')\n\nprint(f\"æ•°æ®å½¢çŠ¶: {df.shape}\")\nprint(f\"\\næ•°æ®é¢„è§ˆ:\")\nprint(df.head())\n\nprint(f\"\\næ•°æ®ä¿¡æ¯:\")\nprint(df.info())\n```\n\n### 3.2 æ•°æ®è´¨é‡æ£€æŸ¥\n\n```python\n# æ£€æŸ¥ç¼ºå¤±å€¼\nprint(\"\\nç¼ºå¤±å€¼ç»Ÿè®¡:\")\nprint(df.isnull().sum())\n\n# æ£€æŸ¥é‡å¤å€¼\nprint(f\"\\né‡å¤è®°å½•æ•°: {df.duplicated().sum()}\")\n\n# æ£€æŸ¥åˆ†ç»„åˆ†å¸ƒ\nprint(\"\\nåˆ†ç»„åˆ†å¸ƒ:\")\nprint(df['{{groupColumn}}'].value_counts())\n\n# æ ·æœ¬é‡ä¸å¹³è¡¡æ£€éªŒ (Chi-square goodness of fit)\ngroup_counts = df['{{groupColumn}}'].value_counts()\nexpected = [len(df) * 0.5, len(df) * 0.5]  # æœŸæœ›50/50åˆ†é…\nchi2, p_value = stats.chisquare(group_counts, expected)\n\nprint(f\"\\næ ·æœ¬é‡å¹³è¡¡æ£€éªŒ:\")\nprint(f\"å¡æ–¹ç»Ÿè®¡é‡: {chi2:.4f}\")\nprint(f\"på€¼: {p_value:.4f}\")\nif p_value > 0.05:\n    print(\"ç»“è®º: æ ·æœ¬é‡åˆ†é…å‡è¡¡ âœ“\")\nelse:\n    print(\"è­¦å‘Š: æ ·æœ¬é‡åˆ†é…ä¸å‡ âš ï¸\")\n```\n\n### 3.3 æ•°æ®æ¸…æ´—\n\n```python\n# ç§»é™¤ç¼ºå¤±å€¼\ndf_clean = df.dropna(subset=['{{groupColumn}}', '{{metricColumn}}'])\n\n# ç§»é™¤é‡å¤è®°å½•\ndf_clean = df_clean.drop_duplicates(subset=['{{userIdColumn}}'])\n\n# ç§»é™¤å¼‚å¸¸å€¼ï¼ˆå¦‚æœæ˜¯è¿ç»­æŒ‡æ ‡ï¼‰\n{{#eq testType \"mean\"}}\nQ1 = df_clean['{{metricColumn}}'].quantile(0.25)\nQ3 = df_clean['{{metricColumn}}'].quantile(0.75)\nIQR = Q3 - Q1\nlower_bound = Q1 - 3 * IQR\nupper_bound = Q3 + 3 * IQR\n\noutliers = df_clean[\n    (df_clean['{{metricColumn}}'] < lower_bound) | \n    (df_clean['{{metricColumn}}'] > upper_bound)\n]\n\nprint(f\"\\nå¼‚å¸¸å€¼æ•°é‡: {len(outliers)}\")\nprint(f\"å¼‚å¸¸å€¼æ¯”ä¾‹: {len(outliers) / len(df_clean) * 100:.2f}%\")\n\ndf_clean = df_clean[\n    (df_clean['{{metricColumn}}'] >= lower_bound) & \n    (df_clean['{{metricColumn}}'] <= upper_bound)\n]\n{{/eq}}\n\nprint(f\"\\næ¸…æ´—åæ•°æ®é‡: {len(df_clean)}\")\n```\n\n---\n\n## 4. æ¢ç´¢æ€§æ•°æ®åˆ†æ (EDA)\n\n### 4.1 æè¿°æ€§ç»Ÿè®¡\n\n```python\n# åˆ†ç»„ç»Ÿè®¡\nsummary = df_clean.groupby('{{groupColumn}}')['{{metricColumn}}'].agg([\n    ('æ ·æœ¬é‡', 'count'),\n    ('å‡å€¼', 'mean'),\n    ('æ ‡å‡†å·®', 'std'),\n    ('ä¸­ä½æ•°', 'median'),\n    ('æœ€å°å€¼', 'min'),\n    ('æœ€å¤§å€¼', 'max')\n])\n\nprint(\"\\nåˆ†ç»„ç»Ÿè®¡:\")\nprint(\"=\"*60)\nprint(summary)\n\n{{#eq testType \"proportion\"}}\n# è½¬åŒ–ç‡è®¡ç®—\nconversion_rates = df_clean.groupby('{{groupColumn}}')['{{metricColumn}}'].agg([\n    ('æ€»æ•°', 'count'),\n    ('è½¬åŒ–æ•°', 'sum'),\n    ('è½¬åŒ–ç‡', 'mean')\n])\n\nconversion_rates['è½¬åŒ–ç‡'] = conversion_rates['è½¬åŒ–ç‡'].apply(lambda x: f\"{x:.2%}\")\n\nprint(\"\\nè½¬åŒ–ç‡ç»Ÿè®¡:\")\nprint(conversion_rates)\n{{/eq}}\n```\n\n### 4.2 æ•°æ®å¯è§†åŒ–\n\n{{#eq testType \"proportion\"}}\n```python\n# è½¬åŒ–ç‡å¯¹æ¯”\ncontrol_rate = df_clean[df_clean['{{groupColumn}}'] == 'å¯¹ç…§ç»„']['{{metricColumn}}'].mean()\ntreatment_rate = df_clean[df_clean['{{groupColumn}}'] == 'å®éªŒç»„']['{{metricColumn}}'].mean()\n\nfig = go.Figure()\n\nfig.add_trace(go.Bar(\n    x=['å¯¹ç…§ç»„', 'å®éªŒç»„'],\n    y=[control_rate, treatment_rate],\n    text=[f'{control_rate:.2%}', f'{treatment_rate:.2%}'],\n    textposition='auto',\n    marker=dict(color=['#3498db', '#e74c3c'])\n))\n\nfig.update_layout(\n    title='è½¬åŒ–ç‡å¯¹æ¯”',\n    xaxis_title='ç»„åˆ«',\n    yaxis_title='è½¬åŒ–ç‡',\n    yaxis_tickformat='.2%',\n    height=500\n)\n\nfig.show()\n```\n{{/eq}}\n\n{{#eq testType \"mean\"}}\n```python\n# åˆ†å¸ƒå¯¹æ¯”\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\n# ç®±çº¿å›¾\ndf_clean.boxplot(column='{{metricColumn}}', by='{{groupColumn}}', ax=axes[0])\naxes[0].set_title('åˆ†å¸ƒå¯¹æ¯” (ç®±çº¿å›¾)')\naxes[0].set_xlabel('ç»„åˆ«')\naxes[0].set_ylabel('{{metricColumn}}')\nplt.sca(axes[0])\nplt.xticks(rotation=0)\n\n# ç›´æ–¹å›¾\ncontrol_data = df_clean[df_clean['{{groupColumn}}'] == 'å¯¹ç…§ç»„']['{{metricColumn}}']\ntreatment_data = df_clean[df_clean['{{groupColumn}}'] == 'å®éªŒç»„']['{{metricColumn}}']\n\naxes[1].hist(control_data, alpha=0.5, label='å¯¹ç…§ç»„', bins=30, edgecolor='black')\naxes[1].hist(treatment_data, alpha=0.5, label='å®éªŒç»„', bins=30, edgecolor='black')\naxes[1].set_title('åˆ†å¸ƒå¯¹æ¯” (ç›´æ–¹å›¾)')\naxes[1].set_xlabel('{{metricColumn}}')\naxes[1].set_ylabel('é¢‘æ•°')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n```\n{{/eq}}\n\n---\n\n## 5. å‡è®¾æ£€éªŒ\n\n### 5.1 å‡è®¾è®¾å®š\n\n```markdown\n**åŸå‡è®¾ (Hâ‚€)**: å®éªŒç»„ä¸å¯¹ç…§ç»„çš„{{primaryMetric}}æ— æ˜¾è‘—å·®å¼‚\n**å¤‡æ‹©å‡è®¾ (Hâ‚)**: å®éªŒç»„ä¸å¯¹ç…§ç»„çš„{{primaryMetric}}å­˜åœ¨æ˜¾è‘—å·®å¼‚\n\n**æ˜¾è‘—æ€§æ°´å¹³ (Î±)**: {{significanceLevel}}\n**æ£€éªŒç±»å‹**: åŒä¾§æ£€éªŒ\n```\n\n{{#eq testType \"proportion\"}}\n### 5.2 æ¯”ä¾‹æ£€éªŒ (Z-test)\n\n```python\ndef proportion_z_test(control_converted, control_total, \n                       treatment_converted, treatment_total, \n                       alpha=0.05):\n    \"\"\"\n    ä¸¤æ ·æœ¬æ¯”ä¾‹Zæ£€éªŒ\n    \"\"\"\n    # è®¡ç®—è½¬åŒ–ç‡\n    p_control = control_converted / control_total\n    p_treatment = treatment_converted / treatment_total\n    \n    # åˆå¹¶æ¯”ä¾‹\n    p_pooled = (control_converted + treatment_converted) / (control_total + treatment_total)\n    \n    # æ ‡å‡†è¯¯å·®\n    se = np.sqrt(p_pooled * (1 - p_pooled) * (1/control_total + 1/treatment_total))\n    \n    # Zç»Ÿè®¡é‡\n    z_stat = (p_treatment - p_control) / se\n    \n    # på€¼ (åŒä¾§)\n    p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n    \n    # ç½®ä¿¡åŒºé—´\n    z_critical = norm.ppf(1 - alpha/2)\n    ci_lower = (p_treatment - p_control) - z_critical * se\n    ci_upper = (p_treatment - p_control) + z_critical * se\n    \n    return {\n        'control_rate': p_control,\n        'treatment_rate': p_treatment,\n        'absolute_lift': p_treatment - p_control,\n        'relative_lift': (p_treatment - p_control) / p_control,\n        'z_statistic': z_stat,\n        'p_value': p_value,\n        'ci_lower': ci_lower,\n        'ci_upper': ci_upper,\n        'significant': p_value < alpha\n    }\n\n# è·å–æ•°æ®\ncontrol = df_clean[df_clean['{{groupColumn}}'] == 'å¯¹ç…§ç»„']\ntreatment = df_clean[df_clean['{{groupColumn}}'] == 'å®éªŒç»„']\n\ncontrol_converted = control['{{metricColumn}}'].sum()\ncontrol_total = len(control)\ntreatment_converted = treatment['{{metricColumn}}'].sum()\ntreatment_total = len(treatment)\n\n# æ‰§è¡Œæ£€éªŒ\nresult = proportion_z_test(\n    control_converted, control_total,\n    treatment_converted, treatment_total,\n    alpha=EXPERIMENT_CONFIG['significance_level']\n)\n\n# è¾“å‡ºç»“æœ\nprint(\"\\næ¯”ä¾‹æ£€éªŒç»“æœ:\")\nprint(\"=\"*60)\nprint(f\"å¯¹ç…§ç»„è½¬åŒ–ç‡: {result['control_rate']:.4f} ({result['control_rate']:.2%})\")\nprint(f\"å®éªŒç»„è½¬åŒ–ç‡: {result['treatment_rate']:.4f} ({result['treatment_rate']:.2%})\")\nprint(f\"\\nç»å¯¹æå‡: {result['absolute_lift']:.4f} ({result['absolute_lift']:.2%})\")\nprint(f\"ç›¸å¯¹æå‡: {result['relative_lift']:.2%}\")\nprint(f\"\\nZç»Ÿè®¡é‡: {result['z_statistic']:.4f}\")\nprint(f\"på€¼: {result['p_value']:.6f}\")\nprint(f\"95%ç½®ä¿¡åŒºé—´: [{result['ci_lower']:.4f}, {result['ci_upper']:.4f}]\")\nprint(f\"\\nç»Ÿè®¡æ˜¾è‘—æ€§: {'æ˜¯ âœ“' if result['significant'] else 'å¦ âœ—'}\")\n\nif result['significant']:\n    print(f\"\\nç»“è®º: åœ¨{EXPERIMENT_CONFIG['significance_level']}çš„æ˜¾è‘—æ€§æ°´å¹³ä¸‹ï¼Œ\")\n    print(f\"å®éªŒç»„çš„è½¬åŒ–ç‡æ˜¾è‘—{'é«˜äº' if result['absolute_lift'] > 0 else 'ä½äº'}å¯¹ç…§ç»„ã€‚\")\nelse:\n    print(f\"\\nç»“è®º: åœ¨{EXPERIMENT_CONFIG['significance_level']}çš„æ˜¾è‘—æ€§æ°´å¹³ä¸‹ï¼Œ\")\n    print(\"æœªè§‚å¯Ÿåˆ°ç»Ÿè®¡æ˜¾è‘—å·®å¼‚ã€‚\")\n```\n{{/eq}}\n\n{{#eq testType \"mean\"}}\n### 5.2 å‡å€¼æ£€éªŒ (T-test)\n\n```python\ndef independent_t_test(control_data, treatment_data, alpha=0.05):\n    \"\"\"\n    ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ\n    \"\"\"\n    # Welch's t-test (ä¸å‡è®¾æ–¹å·®é½æ€§)\n    t_stat, p_value = stats.ttest_ind(treatment_data, control_data, equal_var=False)\n    \n    # æ•ˆåº”é‡ (Cohen's d)\n    pooled_std = np.sqrt(\n        ((len(control_data) - 1) * control_data.std()**2 + \n         (len(treatment_data) - 1) * treatment_data.std()**2) / \n        (len(control_data) + len(treatment_data) - 2)\n    )\n    cohens_d = (treatment_data.mean() - control_data.mean()) / pooled_std\n    \n    # ç½®ä¿¡åŒºé—´\n    mean_diff = treatment_data.mean() - control_data.mean()\n    se_diff = np.sqrt(control_data.var()/len(control_data) + \n                      treatment_data.var()/len(treatment_data))\n    \n    df = len(control_data) + len(treatment_data) - 2\n    t_critical = stats.t.ppf(1 - alpha/2, df)\n    ci_lower = mean_diff - t_critical * se_diff\n    ci_upper = mean_diff + t_critical * se_diff\n    \n    return {\n        'control_mean': control_data.mean(),\n        'treatment_mean': treatment_data.mean(),\n        'mean_diff': mean_diff,\n        'relative_lift': mean_diff / control_data.mean(),\n        't_statistic': t_stat,\n        'p_value': p_value,\n        'cohens_d': cohens_d,\n        'ci_lower': ci_lower,\n        'ci_upper': ci_upper,\n        'significant': p_value < alpha\n    }\n\n# è·å–æ•°æ®\ncontrol_data = df_clean[df_clean['{{groupColumn}}'] == 'å¯¹ç…§ç»„']['{{metricColumn}}']\ntreatment_data = df_clean[df_clean['{{groupColumn}}'] == 'å®éªŒç»„']['{{metricColumn}}']\n\n# æ‰§è¡Œæ£€éªŒ\nresult = independent_t_test(control_data, treatment_data, \n                            alpha=EXPERIMENT_CONFIG['significance_level'])\n\n# è¾“å‡ºç»“æœ\nprint(\"\\nTæ£€éªŒç»“æœ:\")\nprint(\"=\"*60)\nprint(f\"å¯¹ç…§ç»„å‡å€¼: {result['control_mean']:.4f}\")\nprint(f\"å®éªŒç»„å‡å€¼: {result['treatment_mean']:.4f}\")\nprint(f\"\\nå‡å€¼å·®å¼‚: {result['mean_diff']:.4f}\")\nprint(f\"ç›¸å¯¹æå‡: {result['relative_lift']:.2%}\")\nprint(f\"æ•ˆåº”é‡ (Cohen's d): {result['cohens_d']:.4f}\")\nprint(f\"\\ntç»Ÿè®¡é‡: {result['t_statistic']:.4f}\")\nprint(f\"på€¼: {result['p_value']:.6f}\")\nprint(f\"95%ç½®ä¿¡åŒºé—´: [{result['ci_lower']:.4f}, {result['ci_upper']:.4f}]\")\nprint(f\"\\nç»Ÿè®¡æ˜¾è‘—æ€§: {'æ˜¯ âœ“' if result['significant'] else 'å¦ âœ—'}\")\n```\n{{/eq}}\n\n### 5.3 åŠŸæ•ˆåˆ†æ\n\n```python\n# å®é™…åŠŸæ•ˆè®¡ç®—\nobserved_effect_size = abs(result['{{effectSizeKey}}')\nalpha = EXPERIMENT_CONFIG['significance_level']\n\n# è®¡ç®—å®é™…åŠŸæ•ˆ\nactual_power = zt_ind_solve_power(\n    effect_size=observed_effect_size,\n    nobs1=len(control),\n    alpha=alpha,\n    ratio=len(treatment)/len(control),\n    alternative='two-sided'\n)\n\nprint(f\"\\nåŠŸæ•ˆåˆ†æ:\")\nprint(f\"è§‚å¯Ÿåˆ°çš„æ•ˆåº”é‡: {observed_effect_size:.4f}\")\nprint(f\"å®é™…ç»Ÿè®¡åŠŸæ•ˆ: {actual_power:.4f}\")\nprint(f\"é¢„è®¾ç»Ÿè®¡åŠŸæ•ˆ: {EXPERIMENT_CONFIG['statistical_power']}\")\n\nif actual_power < EXPERIMENT_CONFIG['statistical_power']:\n    print(\"\\nè­¦å‘Š: å®é™…åŠŸæ•ˆä½äºé¢„è®¾å€¼ï¼Œå¯èƒ½éœ€è¦æ›´å¤šæ ·æœ¬ âš ï¸\")\n```\n\n---\n\n## 6. æ¬¡è¦æŒ‡æ ‡åˆ†æ\n\n```python\n# æ¬¡è¦æŒ‡æ ‡åˆ—è¡¨\nsecondary_metrics = {{secondaryMetrics}}  # ä¾‹å¦‚: ['é¡µé¢åœç•™æ—¶é—´', 'è·³å‡ºç‡', 'ç‚¹å‡»æ¬¡æ•°']\n\nprint(\"\\næ¬¡è¦æŒ‡æ ‡åˆ†æ:\")\nprint(\"=\"*60)\n\nfor metric in secondary_metrics:\n    print(f\"\\næŒ‡æ ‡: {metric}\")\n    print(\"-\" * 40)\n    \n    control_metric = df_clean[df_clean['{{groupColumn}}'] == 'å¯¹ç…§ç»„'][metric]\n    treatment_metric = df_clean[df_clean['{{groupColumn}}'] == 'å®éªŒç»„'][metric]\n    \n    # æ‰§è¡Œtæ£€éªŒ\n    t_stat, p_val = stats.ttest_ind(treatment_metric, control_metric, equal_var=False)\n    \n    print(f\"å¯¹ç…§ç»„å‡å€¼: {control_metric.mean():.4f}\")\n    print(f\"å®éªŒç»„å‡å€¼: {treatment_metric.mean():.4f}\")\n    print(f\"på€¼: {p_val:.4f}\")\n    print(f\"æ˜¾è‘—: {'æ˜¯ âœ“' if p_val < 0.05 else 'å¦ âœ—'}\")\n```\n\n---\n\n## 7. åˆ†å±‚åˆ†æ (Segmentation)\n\n```python\n# æŒ‰ç”¨æˆ·ç»†åˆ†åˆ†æ\nsegments = {{segmentColumns}}  # ä¾‹å¦‚: ['è®¾å¤‡ç±»å‹', 'åœ°åŒº', 'æ–°è€ç”¨æˆ·']\n\nfor segment in segments:\n    print(f\"\\n{'='*60}\")\n    print(f\"ç»†åˆ†ç»´åº¦: {segment}\")\n    print(f\"{'='*60}\")\n    \n    segment_results = []\n    \n    for seg_value in df_clean[segment].unique():\n        seg_data = df_clean[df_clean[segment] == seg_value]\n        \n        control_seg = seg_data[seg_data['{{groupColumn}}'] == 'å¯¹ç…§ç»„']['{{metricColumn}}']\n        treatment_seg = seg_data[seg_data['{{groupColumn}}'] == 'å®éªŒç»„']['{{metricColumn}}']\n        \n        if len(control_seg) > 30 and len(treatment_seg) > 30:  # ç¡®ä¿æ ·æœ¬é‡è¶³å¤Ÿ\n            t_stat, p_val = stats.ttest_ind(treatment_seg, control_seg, equal_var=False)\n            \n            segment_results.append({\n                'ç»†åˆ†': seg_value,\n                'å¯¹ç…§ç»„æ ·æœ¬': len(control_seg),\n                'å®éªŒç»„æ ·æœ¬': len(treatment_seg),\n                'å¯¹ç…§ç»„å‡å€¼': control_seg.mean(),\n                'å®éªŒç»„å‡å€¼': treatment_seg.mean(),\n                'æå‡': (treatment_seg.mean() - control_seg.mean()) / control_seg.mean(),\n                'på€¼': p_val,\n                'æ˜¾è‘—': p_val < 0.05\n            })\n    \n    seg_df = pd.DataFrame(segment_results)\n    print(seg_df.to_string(index=False))\n```\n\n---\n\n## 8. ç½®ä¿¡åŒºé—´å¯è§†åŒ–\n\n```python\nfig = go.Figure()\n\n# å¯¹ç…§ç»„\nfig.add_trace(go.Scatter(\n    x=[result['control_{{metricKey}}']],\n    y=['å¯¹ç…§ç»„'],\n    mode='markers',\n    marker=dict(size=12, color='blue'),\n    name='å¯¹ç…§ç»„',\n    error_x=dict(\n        type='data',\n        array=[0],  # å¯¹ç…§ç»„ä½œä¸ºåŸºå‡†\n        visible=True\n    )\n))\n\n# å®éªŒç»„\nfig.add_trace(go.Scatter(\n    x=[result['treatment_{{metricKey}}']],\n    y=['å®éªŒç»„'],\n    mode='markers',\n    marker=dict(size=12, color='red'),\n    name='å®éªŒç»„',\n    error_x=dict(\n        type='data',\n        symmetric=False,\n        arrayminus=[result['treatment_{{metricKey}}'] - result['ci_lower']],\n        array=[result['ci_upper'] - result['treatment_{{metricKey}}']],\n        visible=True\n    )\n))\n\nfig.update_layout(\n    title='å®éªŒç»“æœ - 95%ç½®ä¿¡åŒºé—´',\n    xaxis_title='{{primaryMetric}}',\n    yaxis_title='',\n    height=400,\n    showlegend=True\n)\n\nfig.show()\n```\n\n---\n\n## 9. å®éªŒç»“è®ºä¸å»ºè®®\n\n```python\nconclusion = f\"\"\"\nA/Bæµ‹è¯•å®éªŒæŠ¥å‘Š\n{'='*80}\n\nå®éªŒåç§°: {{experimentName}}\nå®éªŒæ—¶é—´: {df_clean['{{dateColumn}}'].min()} è‡³ {df_clean['{{dateColumn}}'].max()}\nä¸»è¦æŒ‡æ ‡: {{primaryMetric}}\n\næ ·æœ¬é‡:\n- å¯¹ç…§ç»„: {len(control):,} ({len(control)/(len(control)+len(treatment)):.1%})\n- å®éªŒç»„: {len(treatment):,} ({len(treatment)/(len(control)+len(treatment)):.1%})\n- æ€»è®¡: {len(df_clean):,}\n\nå®éªŒç»“æœ:\n- å¯¹ç…§ç»„ {{primaryMetric}}: {result['control_{{metricKey}}']:.4f}\n- å®éªŒç»„ {{primaryMetric}}: {result['treatment_{{metricKey}}']:.4f}\n- ç»å¯¹æå‡: {result['{{liftKey}}']:.4f}\n- ç›¸å¯¹æå‡: {result['relative_lift']:.2%}\n\nç»Ÿè®¡æ£€éªŒ:\n- æ£€éªŒæ–¹æ³•: {{testMethod}}\n- ç»Ÿè®¡é‡: {result['{{statKey}}']:.4f}\n- på€¼: {result['p_value']:.6f}\n- æ˜¾è‘—æ€§æ°´å¹³: {EXPERIMENT_CONFIG['significance_level']}\n- 95%ç½®ä¿¡åŒºé—´: [{result['ci_lower']:.4f}, {result['ci_upper']:.4f}]\n\nç»Ÿè®¡æ˜¾è‘—æ€§: {'æ˜¯' if result['significant'] else 'å¦'}\n\nç»“è®º:\n{'='*80}\n\"\"\"\n\nif result['significant']:\n    if result['{{liftKey}}'] > 0:\n        conclusion += f\"\"\"\nå®éªŒç»„åœ¨ {{primaryMetric}} ä¸Šè¡¨ç°æ˜¾è‘—ä¼˜äºå¯¹ç…§ç»„ã€‚\nç›¸å¯¹æå‡ä¸º {result['relative_lift']:.2%}ï¼Œä¸”è¯¥æå‡åœ¨ç»Ÿè®¡ä¸Šæ˜¾è‘— (p={result['p_value']:.4f})ã€‚\n\nå»ºè®®: æ¨èå…¨é‡ä¸Šçº¿å®éªŒç‰ˆæœ¬ã€‚\n        \"\"\"\n    else:\n        conclusion += f\"\"\"\nå®éªŒç»„åœ¨ {{primaryMetric}} ä¸Šè¡¨ç°æ˜¾è‘—å·®äºå¯¹ç…§ç»„ã€‚\nç›¸å¯¹ä¸‹é™ä¸º {abs(result['relative_lift']):.2%}ï¼Œä¸”è¯¥å·®å¼‚åœ¨ç»Ÿè®¡ä¸Šæ˜¾è‘— (p={result['p_value']:.4f})ã€‚\n\nå»ºè®®: ä¸æ¨èä¸Šçº¿å®éªŒç‰ˆæœ¬ï¼Œéœ€è¦é‡æ–°è®¾è®¡ã€‚\n        \"\"\"\nelse:\n    conclusion += f\"\"\"\nå®éªŒç»„ä¸å¯¹ç…§ç»„åœ¨ {{primaryMetric}} ä¸Šæ— æ˜¾è‘—å·®å¼‚ (p={result['p_value']:.4f})ã€‚\nå¯èƒ½åŸå› :\n1. å®éªŒå˜æ›´å¯¹æŒ‡æ ‡å½±å“ä¸å¤§\n2. æ ·æœ¬é‡ä¸è¶³ï¼Œç»Ÿè®¡åŠŸæ•ˆä¸å¤Ÿ\n3. å®éªŒå‘¨æœŸå¤ªçŸ­ï¼Œæœªæ•æ‰å®Œæ•´æ•ˆåº”\n\nå»ºè®®: \n- å¦‚æœä¸šåŠ¡åˆ¤æ–­è¯¥å˜æ›´é‡è¦ï¼Œè€ƒè™‘å»¶é•¿å®éªŒæ—¶é—´å¢åŠ æ ·æœ¬é‡\n- è¯„ä¼°æ˜¯å¦æœ‰å…¶ä»–æ¬¡è¦æŒ‡æ ‡æ˜¾ç¤ºç§¯ææ•ˆæœ\n- åˆ†å±‚åˆ†ææ˜¯å¦æŸäº›ç”¨æˆ·ç¾¤ä½“æœ‰æ˜¾è‘—æ•ˆæœ\n    \"\"\"\n\nprint(conclusion)\n\n# ä¿å­˜æŠ¥å‘Š\nwith open('ab_test_report.txt', 'w', encoding='utf-8') as f:\n    f.write(conclusion)\n\nprint(\"\\næŠ¥å‘Šå·²ä¿å­˜è‡³ ab_test_report.txt\")\n```\n\n---\n\n## 10. é«˜çº§è¯é¢˜\n\n### 10.1 å¤šé‡æ¯”è¾ƒæ ¡æ­£ (Bonferroni)\n\n```python\n# å¦‚æœåŒæ—¶æµ‹è¯•å¤šä¸ªæŒ‡æ ‡ï¼Œéœ€è¦æ ¡æ­£æ˜¾è‘—æ€§æ°´å¹³\nnum_tests = {{numTests}}  # æµ‹è¯•æ•°é‡\nbonferroni_alpha = EXPERIMENT_CONFIG['significance_level'] / num_tests\n\nprint(f\"åŸå§‹Î±: {EXPERIMENT_CONFIG['significance_level']}\")\nprint(f\"Bonferroniæ ¡æ­£åÎ±: {bonferroni_alpha:.6f}\")\nprint(f\"\\nåœ¨æ ¡æ­£åçš„æ˜¾è‘—æ€§æ°´å¹³ä¸‹ï¼Œç»“æœ{'æ˜¾è‘—' if result['p_value'] < bonferroni_alpha else 'ä¸æ˜¾è‘—'}\")\n```\n\n### 10.2 è´å¶æ–¯A/Bæµ‹è¯•\n\n```python\nfrom scipy.stats import beta\n\n# å…ˆéªŒåˆ†å¸ƒ (Betaåˆ†å¸ƒ)\nalpha_prior = 1\nbeta_prior = 1\n\n# åéªŒåˆ†å¸ƒ\nalpha_control = alpha_prior + control_converted\nbeta_control = beta_prior + (control_total - control_converted)\n\nalpha_treatment = alpha_prior + treatment_converted\nbeta_treatment = beta_prior + (treatment_total - treatment_converted)\n\n# ç”Ÿæˆåˆ†å¸ƒ\nx = np.linspace(0, 1, 1000)\ncontrol_dist = beta.pdf(x, alpha_control, beta_control)\ntreatment_dist = beta.pdf(x, alpha_treatment, beta_treatment)\n\n# å¯è§†åŒ–åéªŒåˆ†å¸ƒ\nplt.figure(figsize=(12, 6))\nplt.plot(x, control_dist, label='å¯¹ç…§ç»„åéªŒåˆ†å¸ƒ', color='blue')\nplt.plot(x, treatment_dist, label='å®éªŒç»„åéªŒåˆ†å¸ƒ', color='red')\nplt.fill_between(x, control_dist, alpha=0.3, color='blue')\nplt.fill_between(x, treatment_dist, alpha=0.3, color='red')\nplt.xlabel('è½¬åŒ–ç‡')\nplt.ylabel('æ¦‚ç‡å¯†åº¦')\nplt.title('è´å¶æ–¯åéªŒåˆ†å¸ƒ')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\n# è®¡ç®—å®éªŒç»„ä¼˜äºå¯¹ç…§ç»„çš„æ¦‚ç‡\nsamples = 100000\ncontrol_samples = np.random.beta(alpha_control, beta_control, samples)\ntreatment_samples = np.random.beta(alpha_treatment, beta_treatment, samples)\nprob_treatment_better = (treatment_samples > control_samples).mean()\n\nprint(f\"\\nè´å¶æ–¯åˆ†æ:\")\nprint(f\"å®éªŒç»„ä¼˜äºå¯¹ç…§ç»„çš„æ¦‚ç‡: {prob_treatment_better:.2%}\")\n```\n\n---\n\n## é™„å½•\n\n### A. æ£€éªŒåŠ›ä¸æ ·æœ¬é‡å…³ç³»\n\n```python\n# ç»˜åˆ¶æ ·æœ¬é‡-åŠŸæ•ˆæ›²çº¿\nsample_sizes = np.arange(100, 10000, 100)\npowers = []\n\nfor n in sample_sizes:\n    power = zt_ind_solve_power(\n        effect_size=EXPERIMENT_CONFIG['mde'],\n        nobs1=n,\n        alpha=EXPERIMENT_CONFIG['significance_level'],\n        ratio=1.0,\n        alternative='two-sided'\n    )\n    powers.append(power)\n\nplt.figure(figsize=(10, 6))\nplt.plot(sample_sizes, powers, linewidth=2)\nplt.axhline(y=0.8, color='r', linestyle='--', label='ç›®æ ‡åŠŸæ•ˆ 0.8')\nplt.axvline(x=sample_size_per_group, color='g', linestyle='--', \n            label=f'æ‰€éœ€æ ·æœ¬é‡ {sample_size_per_group}')\nplt.xlabel('æ¯ç»„æ ·æœ¬é‡')\nplt.ylabel('ç»Ÿè®¡åŠŸæ•ˆ')\nplt.title('æ ·æœ¬é‡-åŠŸæ•ˆæ›²çº¿')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n```\n\n### B. å¸¸ç”¨æ£€éªŒæ–¹æ³•é€‰æ‹©\n\n| æ•°æ®ç±»å‹ | æ ·æœ¬é‡ | æ­£æ€æ€§ | æ¨èæ£€éªŒ |\n|----------|--------|--------|----------|\n| æ¯”ä¾‹/è½¬åŒ–ç‡ | å¤§ (>30) | - | Z-test |\n| æ¯”ä¾‹/è½¬åŒ–ç‡ | å° (<30) | - | Fisherç²¾ç¡®æ£€éªŒ |\n| è¿ç»­å˜é‡ | å¤§ (>30) | æ˜¯ | T-test |\n| è¿ç»­å˜é‡ | å¤§ (>30) | å¦ | Mann-Whitney U |\n| è¿ç»­å˜é‡ | å° (<30) | æ˜¯ | T-test |\n| è¿ç»­å˜é‡ | å° (<30) | å¦ | Mann-Whitney U |\n\n### C. æ•ˆåº”é‡è§£é‡Š (Cohen's d)\n\n- å°æ•ˆåº”: d = 0.2\n- ä¸­æ•ˆåº”: d = 0.5\n- å¤§æ•ˆåº”: d = 0.8\n",
  "variables_schema": [
    {
      "name": "experimentName",
      "label": "å®éªŒåç§°",
      "type": "string",
      "required": true
    },
    {
      "name": "primaryMetric",
      "label": "ä¸»è¦æŒ‡æ ‡",
      "type": "string",
      "required": true
    },
    {
      "name": "testType",
      "label": "å®éªŒç±»å‹",
      "type": "select",
      "required": true,
      "options": [
        {"value": "proportion", "label": "æ¯”ä¾‹/è½¬åŒ–ç‡æµ‹è¯•"},
        {"value": "mean", "label": "å‡å€¼æµ‹è¯•"}
      ]
    },
    {
      "name": "significanceLevel",
      "label": "æ˜¾è‘—æ€§æ°´å¹³",
      "type": "number",
      "required": false
    }
  ],
  "file_structure": {
    "root": "{{experimentName}}-ABæµ‹è¯•",
    "files": [
      {"path": "ab_test_analysis.ipynb", "type": "notebook"},
      {"path": "data/", "type": "folder"},
      {"path": "reports/", "type": "folder"},
      {"path": "å®éªŒè®¾è®¡æ–‡æ¡£.md", "type": "document"}
    ]
  },
  "default_files": [],
  "is_builtin": true,
  "author": "ChainlessChain Team",
  "version": "1.0.0"
}
