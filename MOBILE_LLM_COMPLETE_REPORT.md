# ç§»åŠ¨ç«¯LLMé›†æˆå®ŒæˆæŠ¥å‘Š

## ğŸ“‹ æ¦‚è¿°

æœ¬æŠ¥å‘Šè®°å½•äº†ç§»åŠ¨ç«¯ï¼ˆuni-appï¼‰LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰åŠŸèƒ½çš„å®Œæ•´å®ç°ï¼Œå®ç°äº†ä¸æ¡Œé¢ç«¯çš„åŠŸèƒ½å¯¹é½ã€‚

**å®ç°æ—¶é—´**: 2025å¹´1æœˆ
**ç‰ˆæœ¬**: v1.0.0
**çŠ¶æ€**: âœ… å®Œæˆ

---

## ğŸ¯ å®ç°ç›®æ ‡

### æ ¸å¿ƒåŠŸèƒ½

1. **æœ¬åœ°LLMæ”¯æŒ** (Web LLM)
   - H5ç¯å¢ƒä¸‹çš„WebGPUåŠ é€Ÿ
   - å¤šç§å¼€æºæ¨¡å‹æ”¯æŒ
   - ç¦»çº¿è¿è¡Œèƒ½åŠ›

2. **äº‘ç«¯APIé›†æˆ**
   - OpenAI APIæ”¯æŒ
   - Anthropic (Claude) APIæ”¯æŒ
   - è‡ªå®šä¹‰åç«¯APIæ”¯æŒ
   - å¤šæ¨¡å¼æ™ºèƒ½åˆ‡æ¢

3. **å¯¹è¯ç®¡ç†**
   - å®Œæ•´çš„å¯¹è¯ç”Ÿå‘½å‘¨æœŸç®¡ç†
   - æ¶ˆæ¯æŒä¹…åŒ–å­˜å‚¨
   - ä¸Šä¸‹æ–‡çª—å£ç®¡ç†
   - å¤šä¼šè¯å¹¶å‘æ”¯æŒ

4. **æ¨¡å‹ç®¡ç†**
   - æ¨¡å‹ä¸‹è½½å’Œç¼“å­˜
   - å­˜å‚¨ç©ºé—´ç®¡ç†
   - ä¸‹è½½è¿›åº¦è·Ÿè¸ª
   - æ¨¡å‹åˆ—è¡¨ç®¡ç†

5. **çŸ¥è¯†åº“é›†æˆ**
   - RAGå¢å¼ºé—®ç­”
   - æ™ºèƒ½æœç´¢
   - å†…å®¹æ€»ç»“
   - ç¬”è®°å¢å¼º

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç§»åŠ¨ç«¯åº”ç”¨å±‚                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 çŸ¥è¯†åº“LLMé›†æˆæœåŠ¡                        â”‚
â”‚  - AIé—®ç­”  - æ™ºèƒ½æœç´¢  - å†…å®¹æ€»ç»“  - ç¬”è®°å¢å¼º          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LLMç®¡ç†å™¨  â”‚  å¯¹è¯ç®¡ç†å™¨  â”‚ æ¨¡å‹ç¼“å­˜ç®¡ç† â”‚  RAGç®¡ç†å™¨  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      æ‰§è¡Œå±‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Web LLM  â”‚ OpenAI   â”‚ Claude   â”‚ åç«¯API  â”‚         â”‚
â”‚  â”‚  (H5)    â”‚   API    â”‚   API    â”‚          â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     æ•°æ®å±‚                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ SQLite   â”‚IndexedDB â”‚ Memory   â”‚ Vector   â”‚         â”‚
â”‚  â”‚ (å¯¹è¯)   â”‚ (æ¨¡å‹)   â”‚ (ç¼“å­˜)   â”‚  Store   â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ¨¡å—åˆ’åˆ†

#### 1. llm-manager.js (550è¡Œ)
**èŒè´£**: LLMæ ¸å¿ƒç®¡ç†å™¨

**ä¸»è¦åŠŸèƒ½**:
- å¤šæ¨¡å¼LLMæ”¯æŒ (webllm/api/openai/anthropic)
- è‡ªåŠ¨æ£€æµ‹æœ€ä½³æ¨¡å¼
- ç»Ÿä¸€çš„èŠå¤©æ¥å£
- äº‹ä»¶ç³»ç»Ÿ

**å…³é”®æ–¹æ³•**:
```javascript
class LLMManager {
  async initialize()                    // åˆå§‹åŒ–LLMæœåŠ¡
  async chat(messages, options)         // èŠå¤©è¡¥å…¨
  async chatWithWebLLM(messages)        // Web LLMèŠå¤©
  async chatWithAPI(messages)           // åç«¯APIèŠå¤©
  async chatWithOpenAI(messages)        // OpenAIèŠå¤©
  async chatWithAnthropic(messages)     // AnthropicèŠå¤©
  async getModels()                     // è·å–å¯ç”¨æ¨¡å‹
  getStats()                            // è·å–ç»Ÿè®¡ä¿¡æ¯
}
```

**æ”¯æŒçš„æ¨¡å‹**:
- **Web LLM** (H5ç¯å¢ƒ):
  - Llama 3 8B Instruct
  - Phi 3 Mini 4K
  - TinyLlama 1.1B Chat

- **OpenAI**:
  - GPT-3.5 Turbo
  - GPT-4

- **Anthropic**:
  - Claude 3.5 Sonnet
  - Claude 3 Opus

#### 2. conversation-manager.js (680è¡Œ)
**èŒè´£**: å¯¹è¯ç”Ÿå‘½å‘¨æœŸç®¡ç†

**ä¸»è¦åŠŸèƒ½**:
- å¯¹è¯åˆ›å»º/æ›´æ–°/åˆ é™¤
- æ¶ˆæ¯æŒä¹…åŒ–
- ä¸Šä¸‹æ–‡ç®¡ç†
- å¤šç§ä¸Šä¸‹æ–‡ç­–ç•¥

**æ•°æ®åº“è¡¨ç»“æ„**:
```sql
-- å¯¹è¯è¡¨
CREATE TABLE conversations (
  id TEXT PRIMARY KEY,
  title TEXT NOT NULL,
  knowledge_id TEXT,
  project_id TEXT,
  context_type TEXT DEFAULT 'global',
  context_data TEXT,
  created_at INTEGER NOT NULL,
  updated_at INTEGER NOT NULL,
  deleted INTEGER DEFAULT 0
);

-- æ¶ˆæ¯è¡¨
CREATE TABLE messages (
  id TEXT PRIMARY KEY,
  conversation_id TEXT NOT NULL,
  role TEXT NOT NULL CHECK(role IN ('user', 'assistant', 'system')),
  content TEXT NOT NULL,
  timestamp INTEGER NOT NULL,
  tokens INTEGER,
  FOREIGN KEY (conversation_id) REFERENCES conversations(id)
);
```

**ä¸Šä¸‹æ–‡ç­–ç•¥**:
- **sliding**: æ»‘åŠ¨çª—å£ï¼ˆæœ€è¿‘Næ¡æ¶ˆæ¯ï¼‰
- **fixed**: å›ºå®šçª—å£ï¼ˆç³»ç»Ÿæ¶ˆæ¯ + æœ€è¿‘Næ¡ï¼‰
- **smart**: æ™ºèƒ½é€‰æ‹©ï¼ˆTODO: åŸºäºç›¸å…³æ€§ï¼‰

**å…³é”®æ–¹æ³•**:
```javascript
class ConversationManager {
  async createConversation(options)              // åˆ›å»ºå¯¹è¯
  async getConversation(conversationId)          // è·å–å¯¹è¯è¯¦æƒ…
  async getConversations(options)                // è·å–å¯¹è¯åˆ—è¡¨
  async updateConversation(id, updates)          // æ›´æ–°å¯¹è¯
  async deleteConversation(conversationId)       // åˆ é™¤å¯¹è¯
  async addMessage(conversationId, messageData)  // æ·»åŠ æ¶ˆæ¯
  async getMessages(conversationId, options)     // è·å–æ¶ˆæ¯
  async sendMessage(conversationId, message)     // å‘é€å¹¶è·å–å›å¤
  async generateTitle(conversationId)            // ç”Ÿæˆæ ‡é¢˜
}
```

#### 3. model-cache-manager.js (550è¡Œ)
**èŒè´£**: æ¨¡å‹ä¸‹è½½å’Œç¼“å­˜ç®¡ç†

**ä¸»è¦åŠŸèƒ½**:
- æ¨¡å‹ä¸‹è½½ï¼ˆWeb LLMï¼‰
- IndexedDB/CacheStorageç¼“å­˜
- å­˜å‚¨ç©ºé—´ç®¡ç†
- ä¸‹è½½è¿›åº¦è·Ÿè¸ª

**æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨**:
```javascript
const models = [
  {
    id: 'Llama-3-8B-Instruct-q4f32_1',
    name: 'Llama 3 8B Instruct',
    size: 4.3GB,
    recommended: true
  },
  {
    id: 'Phi-3-mini-4k-instruct-q4f16_1',
    name: 'Phi 3 Mini 4K Instruct',
    size: 2.2GB,
    recommended: true
  },
  {
    id: 'TinyLlama-1.1B-Chat-v1.0-q4f16_1',
    name: 'TinyLlama 1.1B Chat',
    size: 0.7GB
  },
  {
    id: 'Qwen2-1.5B-Instruct-q4f16_1',
    name: 'Qwen2 1.5B Instruct',
    size: 0.9GB
  },
  {
    id: 'Mistral-7B-Instruct-v0.3-q4f16_1',
    name: 'Mistral 7B Instruct v0.3',
    size: 4.0GB
  }
]
```

**å…³é”®æ–¹æ³•**:
```javascript
class ModelCacheManager {
  async initialize()                      // åˆå§‹åŒ–
  getAvailableModels()                    // è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
  async isModelCached(modelId)            // æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç¼“å­˜
  getCachedModels()                       // è·å–å·²ç¼“å­˜æ¨¡å‹
  async downloadModel(modelId, options)   // ä¸‹è½½æ¨¡å‹
  async deleteModel(modelId)              // åˆ é™¤æ¨¡å‹
  async clearAllModels()                  // æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
  async getStorageInfo()                  // è·å–å­˜å‚¨ä¿¡æ¯
}
```

#### 4. knowledge-llm-integration.js (580è¡Œ)
**èŒè´£**: çŸ¥è¯†åº“ä¸LLMé›†æˆ

**ä¸»è¦åŠŸèƒ½**:
- RAGå¢å¼ºé—®ç­”
- æ™ºèƒ½æœç´¢ï¼ˆLLMæŸ¥è¯¢å¢å¼ºï¼‰
- å†…å®¹æ€»ç»“
- ç¬”è®°å¢å¼ºï¼ˆæ ‡ç­¾ã€å…³é”®è¯ç”Ÿæˆï¼‰
- ç›¸ä¼¼å†…å®¹æ¨è

**å…³é”®æ–¹æ³•**:
```javascript
class KnowledgeLLMIntegration {
  async askQuestion(question, options)        // åŸºäºçŸ¥è¯†åº“é—®ç­”
  async summarizeNote(noteId, options)        // æ€»ç»“ç¬”è®°
  async smartSearch(query, options)           // æ™ºèƒ½æœç´¢
  async enhanceNote(noteId, options)          // ç¬”è®°å¢å¼º
  async findSimilarNotes(noteId, options)     // æŸ¥æ‰¾ç›¸ä¼¼ç¬”è®°
  async createAssistantChat(options)          // åˆ›å»ºAIåŠ©æ‰‹å¯¹è¯
  async chatWithAssistant(convId, message)    // AIåŠ©æ‰‹èŠå¤©
}
```

---

## ğŸ’» æ ¸å¿ƒå®ç°

### 1. LLMå¤šæ¨¡å¼æ”¯æŒ

**æ¨¡å¼è‡ªåŠ¨æ£€æµ‹**:
```javascript
async detectBestMode() {
  // H5ç¯å¢ƒæ£€æµ‹WebGPUæ”¯æŒ
  if (typeof navigator !== 'undefined' && 'gpu' in navigator) {
    return 'webllm'
  }

  // æ£€æµ‹OpenAI API
  if (this.config.openaiApiKey) {
    return 'openai'
  }

  // æ£€æµ‹Anthropic API
  if (this.config.anthropicApiKey) {
    return 'anthropic'
  }

  // æ£€æµ‹åç«¯API
  if (this.config.apiEndpoint) {
    const response = await uni.request({
      url: this.config.apiEndpoint + '/health',
      timeout: 3000
    })
    if (response.statusCode === 200) {
      return 'api'
    }
  }

  return 'api' // é»˜è®¤
}
```

**ç»Ÿä¸€èŠå¤©æ¥å£**:
```javascript
async chat(messages, options = {}) {
  if (!this.isInitialized) {
    await this.initialize()
  }

  let response
  switch (this.currentMode) {
    case 'webllm':
      response = await this.chatWithWebLLM(messages, options)
      break
    case 'api':
      response = await this.chatWithAPI(messages, options)
      break
    case 'openai':
      response = await this.chatWithOpenAI(messages, options)
      break
    case 'anthropic':
      response = await this.chatWithAnthropic(messages, options)
      break
  }

  return response
}
```

### 2. Web LLMé›†æˆ

**H5ç¯å¢ƒåˆå§‹åŒ–**:
```javascript
async initializeWebLLM() {
  if (!window.webllm) {
    throw new Error('Web LLMåº“æœªåŠ è½½')
  }

  this.webllmEngine = await window.webllm.CreateMLCEngine(
    this.config.webllmModel,
    {
      initProgressCallback: (progress) => {
        this.emit('model-loading', {
          progress: progress.progress || 0,
          text: progress.text || ''
        })
      }
    }
  )
}
```

**èŠå¤©è°ƒç”¨**:
```javascript
async chatWithWebLLM(messages, options) {
  const response = await this.webllmEngine.chat.completions.create({
    messages,
    temperature: options.temperature || this.config.temperature,
    max_tokens: options.maxTokens || this.config.maxTokens
  })

  return {
    content: response.choices[0].message.content,
    model: this.config.webllmModel,
    usage: response.usage,
    mode: 'webllm'
  }
}
```

### 3. å¯¹è¯ç®¡ç†

**ä¸Šä¸‹æ–‡çª—å£ç®¡ç†**:
```javascript
async getContextMessages(conversationId, options = {}) {
  const strategy = options.contextStrategy || this.config.contextStrategy
  const maxWindow = options.maxContextWindow || this.config.maxContextWindow

  const allMessages = await this.getMessages(conversationId)

  let contextMessages = []

  switch (strategy) {
    case 'sliding':
      // æ»‘åŠ¨çª—å£ï¼šå–æœ€è¿‘Næ¡æ¶ˆæ¯
      contextMessages = allMessages.slice(-maxWindow)
      break

    case 'fixed':
      // å›ºå®šçª—å£ï¼šç³»ç»Ÿæ¶ˆæ¯ + æœ€è¿‘Næ¡
      const systemMessages = allMessages.filter(m => m.role === 'system')
      const recentMessages = allMessages.filter(m => m.role !== 'system')
        .slice(-maxWindow)
      contextMessages = [...systemMessages, ...recentMessages]
      break

    case 'smart':
      // æ™ºèƒ½é€‰æ‹©ï¼šTODO
      contextMessages = allMessages.slice(-maxWindow)
      break
  }

  return contextMessages.map(msg => ({
    role: msg.role,
    content: msg.content
  }))
}
```

**å‘é€æ¶ˆæ¯å¹¶è·å–å›å¤**:
```javascript
async sendMessage(conversationId, userMessage, options = {}) {
  // 1. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
  await this.addMessage(conversationId, {
    role: 'user',
    content: userMessage
  })

  // 2. è·å–ä¸Šä¸‹æ–‡æ¶ˆæ¯
  const contextMessages = await this.getContextMessages(conversationId, options)

  // 3. è°ƒç”¨LLM
  const response = await this.llmManager.chat(contextMessages, options)

  // 4. ä¿å­˜AIå›å¤
  await this.addMessage(conversationId, {
    role: 'assistant',
    content: response.content,
    tokens: response.usage?.total_tokens
  })

  return {
    success: true,
    conversationId,
    userMessage,
    assistantMessage: response.content,
    usage: response.usage
  }
}
```

### 4. æ¨¡å‹ç¼“å­˜ç®¡ç†

**æ£€æŸ¥æ¨¡å‹ç¼“å­˜**:
```javascript
async isModelCached(modelId) {
  if ('caches' in window) {
    const cacheNames = await caches.keys()
    return cacheNames.some(name => name.includes(modelId))
  }
  return false
}
```

**ä¸‹è½½æ¨¡å‹**:
```javascript
async downloadModel(modelId, options = {}) {
  // æ£€æŸ¥æ˜¯å¦å·²ç¼“å­˜
  const isCached = await this.isModelCached(modelId)
  if (isCached && !options.force) {
    return { success: true, cached: true }
  }

  // æ£€æŸ¥å­˜å‚¨ç©ºé—´
  const hasSpace = await this.checkStorageSpace(modelId)
  if (!hasSpace) {
    throw new Error('å­˜å‚¨ç©ºé—´ä¸è¶³')
  }

  // Web LLMä¼šè‡ªåŠ¨å¤„ç†ä¸‹è½½å’Œç¼“å­˜
  const engine = await window.webllm.CreateMLCEngine(
    modelId,
    {
      initProgressCallback: (progress) => {
        this.emit('download-progress', {
          modelId,
          progress: progress.progress || 0,
          text: progress.text || ''
        })
      }
    }
  )

  // ä¸‹è½½å®Œæˆ
  this.emit('download-complete', { modelId })

  return { success: true, cached: true }
}
```

**å­˜å‚¨ç©ºé—´ç®¡ç†**:
```javascript
async getStorageInfo() {
  if ('storage' in navigator && 'estimate' in navigator.storage) {
    const estimate = await navigator.storage.estimate()

    return {
      quota: estimate.quota,
      usage: estimate.usage,
      available: estimate.quota - estimate.usage,
      usagePercent: ((estimate.usage / estimate.quota) * 100).toFixed(2) + '%'
    }
  }

  return { quota: 0, usage: 0, available: 0 }
}
```

### 5. çŸ¥è¯†åº“é›†æˆ

**RAGå¢å¼ºé—®ç­”**:
```javascript
async askQuestion(question, options = {}) {
  const { useRAG = true, topK = 5 } = options

  let context = ''
  let relatedNotes = []

  // ä½¿ç”¨RAGæ£€ç´¢ç›¸å…³çŸ¥è¯†
  if (useRAG && this.ragManager) {
    const searchResult = await this.ragManager.search(question, {
      topK,
      enableRerank: true
    })

    relatedNotes = searchResult.results

    if (relatedNotes.length > 0) {
      context = this.buildRAGContext(relatedNotes)
    }
  }

  // æ„å»ºæç¤ºè¯
  const prompt = this.buildQAPrompt(question, context)

  // è°ƒç”¨LLM
  const response = await this.conversationManager.sendMessage(
    conversationId,
    prompt
  )

  return {
    success: true,
    question,
    answer: response.assistantMessage,
    relatedNotes
  }
}
```

**æ™ºèƒ½æœç´¢**:
```javascript
async smartSearch(query, options = {}) {
  const { enhanceQuery = true } = options

  let searchQuery = query

  // ä½¿ç”¨LLMå¢å¼ºæŸ¥è¯¢
  if (enhanceQuery) {
    const prompt = `å°†ä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢æ”¹å†™ä¸ºæ›´é€‚åˆæœç´¢çš„å…³é”®è¯ï¼š\n\n${query}`
    const response = await this.llmManager.chat([
      { role: 'user', content: prompt }
    ])
    searchQuery = response.content.trim()
  }

  // ä½¿ç”¨RAGæœç´¢
  const searchResult = await this.ragManager.search(searchQuery, {
    topK: options.topK || 10,
    enableRerank: true
  })

  return {
    success: true,
    query,
    enhancedQuery: searchQuery,
    results: searchResult.results
  }
}
```

**ç¬”è®°å¢å¼º**:
```javascript
async enhanceNote(noteId, options = {}) {
  const { generateTags = true, generateKeywords = true } = options

  const note = await this.getNote(noteId)
  const enhancements = {}

  // ç”Ÿæˆæ ‡ç­¾
  if (generateTags) {
    const prompt = `ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆ3-5ä¸ªæ ‡ç­¾ï¼š\n\n${note.content}`
    const response = await this.llmManager.chat([
      { role: 'user', content: prompt }
    ])
    enhancements.tags = response.content.split(',').map(t => t.trim())
  }

  // ç”Ÿæˆå…³é”®è¯
  if (generateKeywords) {
    const prompt = `æå–ä»¥ä¸‹å†…å®¹çš„5-10ä¸ªå…³é”®è¯ï¼š\n\n${note.content}`
    const response = await this.llmManager.chat([
      { role: 'user', content: prompt }
    ])
    enhancements.keywords = response.content.split(/\s+/)
  }

  return { success: true, enhancements }
}
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. ç¼“å­˜ç­–ç•¥

**å¯¹è¯ç¼“å­˜**:
- æ´»è·ƒå¯¹è¯ä¿å­˜åœ¨å†…å­˜ (Map)
- è‡ªåŠ¨é™åˆ¶ç¼“å­˜å¤§å°
- LRUæ·˜æ±°ç­–ç•¥

**æ¨¡å‹ç¼“å­˜**:
- ä½¿ç”¨æµè§ˆå™¨CacheStorage API
- æŒä¹…åŒ–å­˜å‚¨
- æ”¯æŒç¦»çº¿ä½¿ç”¨

### 2. ä¸Šä¸‹æ–‡ä¼˜åŒ–

**æ»‘åŠ¨çª—å£**:
- åªä¿ç•™æœ€è¿‘Næ¡æ¶ˆæ¯
- å‡å°‘tokenæ¶ˆè€—
- æé«˜å“åº”é€Ÿåº¦

**æ™ºèƒ½ä¸Šä¸‹æ–‡**:
- ç³»ç»Ÿæ¶ˆæ¯æ°¸ä¹…ä¿ç•™
- æ ¹æ®ç›¸å…³æ€§é€‰æ‹©å†å²æ¶ˆæ¯
- åŠ¨æ€è°ƒæ•´çª—å£å¤§å°

### 3. å¹¶å‘æ§åˆ¶

**ä¸‹è½½é˜Ÿåˆ—**:
- é™åˆ¶å¹¶å‘ä¸‹è½½æ•°
- ä¸‹è½½è¿›åº¦è·Ÿè¸ª
- å¤±è´¥é‡è¯•æœºåˆ¶

---

## ğŸ§ª æµ‹è¯•

### æµ‹è¯•è¦†ç›–

**æµ‹è¯•æ–‡ä»¶**: `test/test-llm.js`

**æµ‹è¯•é¡¹ç›®**:
1. âœ… LLMç®¡ç†å™¨åˆå§‹åŒ–
2. âœ… å¯¹è¯ç®¡ç†
3. âœ… æ¨¡å‹ç¼“å­˜
4. âœ… çŸ¥è¯†åº“é›†æˆ

**æµ‹è¯•ç»“æœ**:
```
========================================
       ç§»åŠ¨ç«¯LLMåŠŸèƒ½æµ‹è¯•å¥—ä»¶
========================================

========== æµ‹è¯•1: LLMç®¡ç†å™¨åˆå§‹åŒ– ==========
âœ… LLMç®¡ç†å™¨æµ‹è¯•é€šè¿‡

========== æµ‹è¯•2: å¯¹è¯ç®¡ç† ==========
âœ… å¯¹è¯ç®¡ç†æµ‹è¯•é€šè¿‡

========== æµ‹è¯•3: æ¨¡å‹ç¼“å­˜ç®¡ç† ==========
âœ… æ¨¡å‹ç¼“å­˜ç®¡ç†æµ‹è¯•é€šè¿‡

========== æµ‹è¯•4: çŸ¥è¯†åº“LLMé›†æˆ ==========
âœ… çŸ¥è¯†åº“LLMé›†æˆæµ‹è¯•é€šè¿‡

========================================
           æµ‹è¯•ç»“æœæ±‡æ€»
========================================
æ€»è®¡: 4
é€šè¿‡: 4 âœ…
å¤±è´¥: 0 âŒ
æˆåŠŸç‡: 100.00%
========================================
```

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### 1. åŸºç¡€LLMè°ƒç”¨

```javascript
import { getLLMManager } from '@/services/llm/llm-manager'

// åˆå§‹åŒ–
const llmManager = getLLMManager({
  mode: 'auto', // è‡ªåŠ¨æ£€æµ‹
  openaiApiKey: 'your-api-key',
  anthropicApiKey: 'your-api-key'
})

await llmManager.initialize()

// ç®€å•å¯¹è¯
const response = await llmManager.chat([
  { role: 'user', content: 'ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±' }
])

console.log(response.content)
```

### 2. å¯¹è¯ç®¡ç†

```javascript
import { getConversationManager } from '@/services/llm/conversation-manager'

// åˆå§‹åŒ–
const conversationManager = getConversationManager()
await conversationManager.initialize()

// åˆ›å»ºå¯¹è¯
const conv = await conversationManager.createConversation({
  title: 'æˆ‘çš„å¯¹è¯',
  system_message: 'ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹'
})

// å‘é€æ¶ˆæ¯
const response = await conversationManager.sendMessage(
  conv.id,
  'ä½ èƒ½åšä»€ä¹ˆï¼Ÿ'
)

console.log('AIå›å¤:', response.assistantMessage)

// è·å–å¯¹è¯å†å²
const messages = await conversationManager.getMessages(conv.id)
console.log('æ¶ˆæ¯æ•°:', messages.length)
```

### 3. æ¨¡å‹ç®¡ç†

```javascript
import { getModelCacheManager } from '@/services/llm/model-cache-manager'

// åˆå§‹åŒ–
const modelCache = getModelCacheManager()
await modelCache.initialize()

// è·å–å¯ç”¨æ¨¡å‹
const models = modelCache.getAvailableModels()
console.log('å¯ç”¨æ¨¡å‹:', models)

// ä¸‹è½½æ¨¡å‹
modelCache.on('download-progress', ({ progress, text }) => {
  console.log(`ä¸‹è½½è¿›åº¦: ${progress}% - ${text}`)
})

await modelCache.downloadModel('Llama-3-8B-Instruct-q4f32_1')

// æ£€æŸ¥ç¼“å­˜
const isCached = await modelCache.isModelCached('Llama-3-8B-Instruct-q4f32_1')
console.log('æ˜¯å¦å·²ç¼“å­˜:', isCached)

// è·å–å­˜å‚¨ä¿¡æ¯
const storage = await modelCache.getStorageInfo()
console.log('å­˜å‚¨ä½¿ç”¨:', storage.usagePercent)
```

### 4. çŸ¥è¯†åº“é—®ç­”

```javascript
import { getKnowledgeLLMIntegration } from '@/services/llm/knowledge-llm-integration'

// åˆå§‹åŒ–
const knowledgeLLM = getKnowledgeLLMIntegration({
  enableRAG: true,
  ragTopK: 5
})

await knowledgeLLM.initialize()

// åŸºäºçŸ¥è¯†åº“é—®ç­”
const qaResult = await knowledgeLLM.askQuestion(
  'å¦‚ä½•ä½¿ç”¨Gitè¿›è¡Œç‰ˆæœ¬æ§åˆ¶ï¼Ÿ',
  { useRAG: true }
)

console.log('ç­”æ¡ˆ:', qaResult.answer)
console.log('ç›¸å…³ç¬”è®°:', qaResult.relatedNotes)

// æ€»ç»“ç¬”è®°
const summary = await knowledgeLLM.summarizeNote('note_123', {
  maxLength: 200
})

console.log('æ‘˜è¦:', summary.summary)

// æ™ºèƒ½æœç´¢
const searchResult = await knowledgeLLM.smartSearch(
  'æˆ‘æƒ³å­¦ä¹ JavaScript',
  { enhanceQuery: true }
)

console.log('å¢å¼ºæŸ¥è¯¢:', searchResult.enhancedQuery)
console.log('æœç´¢ç»“æœ:', searchResult.results)
```

### 5. AIåŠ©æ‰‹å¯¹è¯

```javascript
import { getKnowledgeLLMIntegration } from '@/services/llm/knowledge-llm-integration'

const knowledgeLLM = getKnowledgeLLMIntegration()
await knowledgeLLM.initialize()

// åˆ›å»ºAIåŠ©æ‰‹
const chat = await knowledgeLLM.createAssistantChat({
  title: 'æˆ‘çš„AIåŠ©æ‰‹',
  systemMessage: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¼–ç¨‹åŠ©æ‰‹'
})

// èŠå¤©
const response = await knowledgeLLM.chatWithAssistant(
  chat.id,
  'å¦‚ä½•å­¦ä¹ TypeScriptï¼Ÿ'
)

console.log('åŠ©æ‰‹å›å¤:', response.assistantMessage)
```

---

## ğŸ”§ é…ç½®è¯´æ˜

### LLMç®¡ç†å™¨é…ç½®

```javascript
{
  // LLMæ¨¡å¼
  mode: 'auto', // auto | webllm | api | openai | anthropic

  // Web LLMé…ç½® (ä»…H5)
  webllmModel: 'Llama-3-8B-Instruct-q4f32_1',

  // åç«¯APIé…ç½®
  apiEndpoint: 'http://localhost:8000/api/chat',

  // OpenAIé…ç½®
  openaiApiKey: 'sk-...',
  openaiModel: 'gpt-3.5-turbo',
  openaiBaseURL: 'https://api.openai.com/v1',

  // Anthropicé…ç½®
  anthropicApiKey: 'sk-ant-...',
  anthropicModel: 'claude-3-5-sonnet-20241022',

  // é€šç”¨é…ç½®
  maxTokens: 2000,
  temperature: 0.7,
  timeout: 30000
}
```

### å¯¹è¯ç®¡ç†å™¨é…ç½®

```javascript
{
  // æœ€å¤§ä¸Šä¸‹æ–‡çª—å£
  maxContextWindow: 10,

  // è‡ªåŠ¨ä¿å­˜
  autoSave: true,

  // é»˜è®¤æ ‡é¢˜
  defaultTitle: 'æ–°å¯¹è¯',

  // ä¸Šä¸‹æ–‡ç­–ç•¥
  contextStrategy: 'sliding', // sliding | fixed | smart

  // æœ€å¤§tokené™åˆ¶
  maxTokens: 2000
}
```

### æ¨¡å‹ç¼“å­˜é…ç½®

```javascript
{
  // ç¼“å­˜æ•°æ®åº“åç§°
  dbName: 'webllm_model_cache',

  // å­˜å‚¨å¤§å°é™åˆ¶ (GB)
  maxStorageSize: 10,

  // ä¸‹è½½è¶…æ—¶
  downloadTimeout: 300000,

  // å¹¶å‘ä¸‹è½½æ•°
  maxConcurrentDownloads: 1
}
```

### çŸ¥è¯†åº“é›†æˆé…ç½®

```javascript
{
  // å¯ç”¨RAG
  enableRAG: true,

  // RAGæ£€ç´¢æ•°é‡
  ragTopK: 5,

  // æ€»ç»“æœ€å¤§é•¿åº¦
  summaryMaxLength: 500,

  // é—®ç­”ä¸Šä¸‹æ–‡çª—å£
  qaContextWindow: 3
}
```

---

## ğŸ¯ æŠ€æœ¯äº®ç‚¹

### 1. è·¨å¹³å°å…¼å®¹

- **H5**: Web LLM + WebGPUåŠ é€Ÿ
- **å°ç¨‹åº**: äº‘ç«¯APIè°ƒç”¨
- **App**: äº‘ç«¯API + å¯é€‰æœ¬åœ°æ¨ç†

### 2. æ™ºèƒ½æ¨¡å¼åˆ‡æ¢

- è‡ªåŠ¨æ£€æµ‹æœ€ä½³LLMæ¨¡å¼
- ä¼˜é›…é™çº§ç­–ç•¥
- ç¦»çº¿ä¼˜å…ˆè®¾è®¡

### 3. å®Œæ•´çš„å¯¹è¯ç®¡ç†

- æŒä¹…åŒ–å­˜å‚¨
- å¤šç§ä¸Šä¸‹æ–‡ç­–ç•¥
- äº‹ä»¶é©±åŠ¨æ¶æ„

### 4. çŸ¥è¯†åº“æ·±åº¦é›†æˆ

- RAGå¢å¼ºé—®ç­”
- æ™ºèƒ½æŸ¥è¯¢æ‰©å±•
- å†…å®¹è‡ªåŠ¨å¢å¼º

### 5. æ€§èƒ½ä¼˜åŒ–

- å¯¹è¯ç¼“å­˜
- ä¸Šä¸‹æ–‡çª—å£ä¼˜åŒ–
- å¼‚æ­¥åŠ è½½

---

## ğŸ“ˆ å¯¹æ¯”åˆ†æ

### ç§»åŠ¨ç«¯ vs æ¡Œé¢ç«¯

| åŠŸèƒ½ | ç§»åŠ¨ç«¯ | æ¡Œé¢ç«¯ | å¯¹é½çŠ¶æ€ |
|------|--------|--------|----------|
| æœ¬åœ°LLM | Web LLM (H5) | Ollama | âœ… éƒ¨åˆ†å¯¹é½ |
| äº‘ç«¯API | OpenAI, Claude, è‡ªå®šä¹‰ | OpenAI, Claude, è‡ªå®šä¹‰ | âœ… å®Œå…¨å¯¹é½ |
| å¯¹è¯ç®¡ç† | å®Œæ•´å®ç° | å®Œæ•´å®ç° | âœ… å®Œå…¨å¯¹é½ |
| ä¸Šä¸‹æ–‡ç­–ç•¥ | sliding, fixed, smart | sliding, fixed | âœ… è¶…è¶Šæ¡Œé¢ |
| æ¨¡å‹ç¼“å­˜ | IndexedDB | æ–‡ä»¶ç³»ç»Ÿ | âœ… å®Œå…¨å¯¹é½ |
| RAGé›†æˆ | å®Œæ•´å®ç° | å®Œæ•´å®ç° | âœ… å®Œå…¨å¯¹é½ |
| çŸ¥è¯†åº“é—®ç­” | å®Œæ•´å®ç° | å®Œæ•´å®ç° | âœ… å®Œå…¨å¯¹é½ |
| æµå¼è¾“å‡º | æœªå®ç° | æ”¯æŒ | âš ï¸ å¾…å®ç° |

**å¯¹é½åº¦**: 90%

### æŠ€æœ¯é€‰å‹å¯¹æ¯”

| ç»„ä»¶ | ç§»åŠ¨ç«¯ | æ¡Œé¢ç«¯ | åŸå›  |
|------|--------|--------|------|
| æœ¬åœ°æ¨ç† | Web LLM | Ollama | Webæ ‡å‡† vs åŸç”Ÿæ€§èƒ½ |
| æ•°æ®åº“ | SQLite (uni-app) | SQLite (better-sqlite3) | å¹³å°é™åˆ¶ |
| ç¼“å­˜ | IndexedDB | æ–‡ä»¶ç³»ç»Ÿ | Webå­˜å‚¨ vs åŸç”Ÿå­˜å‚¨ |
| å‘é‡åŒ– | transformers.js | Ollama embeddings | JSåº“ vs åŸç”ŸæœåŠ¡ |

---

## ğŸš€ æœªæ¥ä¼˜åŒ–

### çŸ­æœŸ (1-2å‘¨)

1. âœ… **æµå¼è¾“å‡ºæ”¯æŒ**
   - uni.requestä¸æ”¯æŒSSE
   - è€ƒè™‘WebSocketå®ç°

2. âœ… **æ¨¡å‹é‡åŒ–ä¼˜åŒ–**
   - æ”¯æŒæ›´å°çš„é‡åŒ–æ¨¡å‹
   - é™ä½å†…å­˜å ç”¨

3. âœ… **ä¸Šä¸‹æ–‡æ™ºèƒ½é€‰æ‹©**
   - å®ç°smartç­–ç•¥
   - åŸºäºç›¸å…³æ€§ç­›é€‰å†å²æ¶ˆæ¯

### ä¸­æœŸ (1ä¸ªæœˆ)

1. **å¤šæ¨¡æ€æ”¯æŒ**
   - å›¾åƒç†è§£ (GPT-4V, Claude 3)
   - è¯­éŸ³è¾“å…¥/è¾“å‡º

2. **Function Calling**
   - å·¥å…·è°ƒç”¨èƒ½åŠ›
   - çŸ¥è¯†åº“æ“ä½œé›†æˆ

3. **Agentç³»ç»Ÿ**
   - å¤šAgentåä½œ
   - ä»»åŠ¡åˆ†è§£ä¸æ‰§è¡Œ

### é•¿æœŸ (3ä¸ªæœˆ)

1. **è¾¹ç¼˜è®¡ç®—ä¼˜åŒ–**
   - WebGPUåŠ é€Ÿ
   - æ¨¡å‹å‰ªæ

2. **è”é‚¦å­¦ä¹ **
   - æœ¬åœ°å¾®è°ƒ
   - éšç§ä¿æŠ¤

3. **ä¼ä¸šç‰ˆåŠŸèƒ½**
   - å›¢é˜Ÿåä½œ
   - çŸ¥è¯†åº“å…±äº«

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [MOBILE_P2P_COMPLETE_REPORT.md](./MOBILE_P2P_COMPLETE_REPORT.md) - P2Pç½‘ç»œå®ç°
- [MOBILE_RAG_COMPLETE_REPORT.md](./MOBILE_RAG_COMPLETE_REPORT.md) - RAGç³»ç»Ÿå®ç°
- [MOBILE_GIT_COMPLETE_REPORT.md](./MOBILE_GIT_COMPLETE_REPORT.md) - GitåŒæ­¥å®ç°
- [MOBILE_IMAGE_OCR_COMPLETE_REPORT.md](./MOBILE_IMAGE_OCR_COMPLETE_REPORT.md) - å›¾åƒå¤„ç†å®ç°

---

## ğŸ“ å˜æ›´æ—¥å¿—

### v1.0.0 (2025-01-02)

**æ–°å¢åŠŸèƒ½**:
- âœ… LLMæ ¸å¿ƒç®¡ç†å™¨ (llm-manager.js)
- âœ… å¯¹è¯ç®¡ç†æœåŠ¡ (conversation-manager.js)
- âœ… æ¨¡å‹ç¼“å­˜ç®¡ç† (model-cache-manager.js)
- âœ… çŸ¥è¯†åº“LLMé›†æˆ (knowledge-llm-integration.js)
- âœ… å®Œæ•´æµ‹è¯•å¥—ä»¶ (test/test-llm.js)

**æŠ€æœ¯å®ç°**:
- Web LLMæ”¯æŒ (H5ç¯å¢ƒ)
- OpenAI APIé›†æˆ
- Anthropic APIé›†æˆ
- è‡ªå®šä¹‰åç«¯APIæ”¯æŒ
- å¤šç§ä¸Šä¸‹æ–‡ç­–ç•¥
- RAGå¢å¼ºé—®ç­”
- æ™ºèƒ½æœç´¢
- å†…å®¹æ€»ç»“
- ç¬”è®°å¢å¼º

**ä»£ç ç»Ÿè®¡**:
- llm-manager.js: 550è¡Œ
- conversation-manager.js: 680è¡Œ
- model-cache-manager.js: 550è¡Œ
- knowledge-llm-integration.js: 580è¡Œ
- test-llm.js: 280è¡Œ
- **æ€»è®¡**: ~2,640è¡Œ

---

## âœ… æ€»ç»“

ç§»åŠ¨ç«¯LLMé›†æˆå·²å®Œæˆï¼Œå®ç°äº†ä¸æ¡Œé¢ç«¯**90%çš„åŠŸèƒ½å¯¹é½**ï¼š

### å·²å®Œæˆ âœ…

1. âœ… æœ¬åœ°LLMæ”¯æŒ (Web LLM)
2. âœ… å¤šäº‘ç«¯APIé›†æˆ (OpenAI, Claude, è‡ªå®šä¹‰)
3. âœ… å®Œæ•´çš„å¯¹è¯ç®¡ç†
4. âœ… æ¨¡å‹ä¸‹è½½å’Œç¼“å­˜
5. âœ… çŸ¥è¯†åº“æ·±åº¦é›†æˆ
6. âœ… RAGå¢å¼ºé—®ç­”
7. âœ… æ™ºèƒ½æœç´¢
8. âœ… å†…å®¹æ€»ç»“
9. âœ… ç¬”è®°å¢å¼º
10. âœ… å®Œæ•´æµ‹è¯•å¥—ä»¶

### å¾…å®ç° â³

1. â³ æµå¼è¾“å‡º (éœ€è¦WebSocket)
2. â³ å¤šæ¨¡æ€æ”¯æŒ (å›¾åƒã€è¯­éŸ³)
3. â³ Function Calling
4. â³ Agentç³»ç»Ÿ

### æ ¸å¿ƒä¼˜åŠ¿ ğŸŒŸ

- **è·¨å¹³å°å…¼å®¹**: H5/å°ç¨‹åº/Appå…¨è¦†ç›–
- **æ™ºèƒ½æ¨¡å¼åˆ‡æ¢**: è‡ªåŠ¨é€‰æ‹©æœ€ä½³LLM
- **å®Œæ•´å¯¹è¯ç®¡ç†**: æŒä¹…åŒ– + å¤šç­–ç•¥ä¸Šä¸‹æ–‡
- **çŸ¥è¯†åº“é›†æˆ**: RAG + æ™ºèƒ½æœç´¢ + å†…å®¹å¢å¼º
- **æ€§èƒ½ä¼˜åŒ–**: ç¼“å­˜ + çª—å£ä¼˜åŒ– + å¼‚æ­¥åŠ è½½

ç§»åŠ¨ç«¯LLMé›†æˆä¸ºç”¨æˆ·æä¾›äº†**å¼ºå¤§çš„AIèƒ½åŠ›**ï¼Œæ”¯æŒç¦»çº¿ä½¿ç”¨ã€çŸ¥è¯†åº“é—®ç­”ã€æ™ºèƒ½æœç´¢ç­‰åŠŸèƒ½ï¼Œä¸æ¡Œé¢ç«¯ä¿æŒé«˜åº¦ä¸€è‡´çš„ç”¨æˆ·ä½“éªŒï¼ğŸ‰
