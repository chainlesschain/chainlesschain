import Foundation
import NaturalLanguage
import CoreML

// MARK: - AI/ML Tools (12 tools)
// NLP: 6 tools | Text Analysis: 4 tools | ML: 2 tools

public class AIMLTools {

    // MARK: - NLP Tools (6 tools)

    /// Tool: tool.nlp.language - è¯­è¨€è¯†åˆ«
    public static let languageDetectionTool = Tool(
        id: "tool.nlp.language",
        name: "è¯­è¨€è¯†åˆ«",
        description: "è‡ªåŠ¨è¯†åˆ«æ–‡æœ¬çš„è¯­è¨€",
        category: .ai,
        parameters: [
            ToolParameter(name: "text", type: .string, description: "å¾…è¯†åˆ«çš„æ–‡æœ¬", required: true)
        ],
        executor: languageDetectionExecutor
    )

    private static let languageDetectionExecutor: ToolExecutor = { input in
        guard let text = input.getString("text") else {
            return .failure(error: "ç¼ºå°‘æ–‡æœ¬å†…å®¹")
        }

        let recognizer = NLLanguageRecognizer()
        recognizer.processString(text)

        guard let language = recognizer.dominantLanguage else {
            return .failure(error: "æ— æ³•è¯†åˆ«è¯­è¨€")
        }

        var languageHypotheses: [[String: Any]] = []
        for (lang, confidence) in recognizer.languageHypotheses(withMaximum: 3) {
            languageHypotheses.append([
                "language": lang.rawValue,
                "confidence": confidence
            ])
        }

        return .success(data: [
            "language": language.rawValue,
            "languageName": Locale.current.localizedString(forLanguageCode: language.rawValue) ?? language.rawValue,
            "hypotheses": languageHypotheses
        ])
    }

    /// Tool: tool.nlp.tokenize - æ–‡æœ¬åˆ†è¯
    public static let tokenizeTool = Tool(
        id: "tool.nlp.tokenize",
        name: "æ–‡æœ¬åˆ†è¯",
        description: "å°†æ–‡æœ¬åˆ†å‰²ä¸ºè¯è¯­ã€å¥å­æˆ–æ®µè½",
        category: .ai,
        parameters: [
            ToolParameter(name: "text", type: .string, description: "å¾…åˆ†è¯çš„æ–‡æœ¬", required: true),
            ToolParameter(name: "unit", type: .string, description: "åˆ†è¯å•ä½ï¼ˆword/sentence/paragraphï¼Œé»˜è®¤wordï¼‰", required: false)
        ],
        executor: tokenizeExecutor
    )

    private static let tokenizeExecutor: ToolExecutor = { input in
        guard let text = input.getString("text") else {
            return .failure(error: "ç¼ºå°‘æ–‡æœ¬å†…å®¹")
        }

        let unitString = input.getString("unit") ?? "word"
        var unit: NLTokenUnit

        switch unitString.lowercased() {
        case "word":
            unit = .word
        case "sentence":
            unit = .sentence
        case "paragraph":
            unit = .paragraph
        default:
            return .failure(error: "ä¸æ”¯æŒçš„åˆ†è¯å•ä½: \(unitString)")
        }

        let tokenizer = NLTokenizer(unit: unit)
        tokenizer.string = text

        var tokens: [String] = []
        tokenizer.enumerateTokens(in: text.startIndex..<text.endIndex) { range, _ in
            tokens.append(String(text[range]))
            return true
        }

        return .success(data: [
            "tokens": tokens,
            "count": tokens.count,
            "unit": unitString
        ])
    }

    /// Tool: tool.nlp.ner - å‘½åå®ä½“è¯†åˆ«
    public static let nerTool = Tool(
        id: "tool.nlp.ner",
        name: "å‘½åå®ä½“è¯†åˆ«",
        description: "è¯†åˆ«æ–‡æœ¬ä¸­çš„äººåã€åœ°åã€ç»„ç»‡ç­‰å®ä½“",
        category: .ai,
        parameters: [
            ToolParameter(name: "text", type: .string, description: "å¾…è¯†åˆ«çš„æ–‡æœ¬", required: true)
        ],
        executor: nerExecutor
    )

    private static let nerExecutor: ToolExecutor = { input in
        guard let text = input.getString("text") else {
            return .failure(error: "ç¼ºå°‘æ–‡æœ¬å†…å®¹")
        }

        let tagger = NLTagger(tagSchemes: [.nameType])
        tagger.string = text

        var entities: [[String: Any]] = []

        tagger.enumerateTags(in: text.startIndex..<text.endIndex, unit: .word, scheme: .nameType) { tag, range in
            if let tag = tag {
                let entity = String(text[range])
                var type = ""

                switch tag {
                case .personalName:
                    type = "person"
                case .placeName:
                    type = "place"
                case .organizationName:
                    type = "organization"
                default:
                    type = tag.rawValue
                }

                entities.append([
                    "text": entity,
                    "type": type,
                    "range": [text.distance(from: text.startIndex, to: range.lowerBound),
                             text.distance(from: text.startIndex, to: range.upperBound)]
                ])
            }
            return true
        }

        return .success(data: [
            "entities": entities,
            "count": entities.count
        ])
    }

    /// Tool: tool.nlp.pos - è¯æ€§æ ‡æ³¨
    public static let posTool = Tool(
        id: "tool.nlp.pos",
        name: "è¯æ€§æ ‡æ³¨",
        description: "æ ‡æ³¨æ–‡æœ¬ä¸­æ¯ä¸ªè¯çš„è¯æ€§ï¼ˆåè¯ã€åŠ¨è¯ç­‰ï¼‰",
        category: .ai,
        parameters: [
            ToolParameter(name: "text", type: .string, description: "å¾…æ ‡æ³¨çš„æ–‡æœ¬", required: true)
        ],
        executor: posExecutor
    )

    private static let posExecutor: ToolExecutor = { input in
        guard let text = input.getString("text") else {
            return .failure(error: "ç¼ºå°‘æ–‡æœ¬å†…å®¹")
        }

        let tagger = NLTagger(tagSchemes: [.lexicalClass])
        tagger.string = text

        var taggedWords: [[String: Any]] = []

        tagger.enumerateTags(in: text.startIndex..<text.endIndex, unit: .word, scheme: .lexicalClass) { tag, range in
            let word = String(text[range])
            var posType = "unknown"

            if let tag = tag {
                switch tag {
                case .noun:
                    posType = "noun"
                case .verb:
                    posType = "verb"
                case .adjective:
                    posType = "adjective"
                case .adverb:
                    posType = "adverb"
                case .pronoun:
                    posType = "pronoun"
                case .preposition:
                    posType = "preposition"
                case .conjunction:
                    posType = "conjunction"
                case .determiner:
                    posType = "determiner"
                case .particle:
                    posType = "particle"
                case .number:
                    posType = "number"
                default:
                    posType = tag.rawValue
                }
            }

            taggedWords.append([
                "word": word,
                "pos": posType
            ])

            return true
        }

        return .success(data: [
            "taggedWords": taggedWords,
            "count": taggedWords.count
        ])
    }

    /// Tool: tool.nlp.lemma - è¯å½¢è¿˜åŸ
    public static let lemmaTool = Tool(
        id: "tool.nlp.lemma",
        name: "è¯å½¢è¿˜åŸ",
        description: "å°†å•è¯è¿˜åŸä¸ºå…¶åŸºæœ¬å½¢å¼ï¼ˆå¦‚running->runï¼‰",
        category: .ai,
        parameters: [
            ToolParameter(name: "text", type: .string, description: "å¾…å¤„ç†çš„æ–‡æœ¬", required: true)
        ],
        executor: lemmaExecutor
    )

    private static let lemmaExecutor: ToolExecutor = { input in
        guard let text = input.getString("text") else {
            return .failure(error: "ç¼ºå°‘æ–‡æœ¬å†…å®¹")
        }

        let tagger = NLTagger(tagSchemes: [.lemma])
        tagger.string = text

        var lemmas: [[String: String]] = []

        tagger.enumerateTags(in: text.startIndex..<text.endIndex, unit: .word, scheme: .lemma) { tag, range in
            let word = String(text[range])
            let lemma = tag?.rawValue ?? word

            lemmas.append([
                "original": word,
                "lemma": lemma
            ])

            return true
        }

        return .success(data: [
            "lemmas": lemmas,
            "count": lemmas.count
        ])
    }

    /// Tool: tool.nlp.similarity - æ–‡æœ¬ç›¸ä¼¼åº¦
    public static let textSimilarityTool = Tool(
        id: "tool.nlp.similarity",
        name: "æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—",
        description: "è®¡ç®—ä¸¤æ®µæ–‡æœ¬çš„è¯­ä¹‰ç›¸ä¼¼åº¦",
        category: .ai,
        parameters: [
            ToolParameter(name: "text1", type: .string, description: "ç¬¬ä¸€æ®µæ–‡æœ¬", required: true),
            ToolParameter(name: "text2", type: .string, description: "ç¬¬äºŒæ®µæ–‡æœ¬", required: true)
        ],
        executor: textSimilarityExecutor
    )

    private static let textSimilarityExecutor: ToolExecutor = { input in
        guard let text1 = input.getString("text1"),
              let text2 = input.getString("text2") else {
            return .failure(error: "ç¼ºå°‘æ–‡æœ¬å†…å®¹")
        }

        if #available(iOS 16.0, *) {
            guard let embedding1 = NLEmbedding.sentenceEmbedding(for: .english),
                  let embedding2 = NLEmbedding.sentenceEmbedding(for: .english) else {
                return .failure(error: "æ— æ³•åŠ è½½æ–‡æœ¬åµŒå…¥æ¨¡å‹")
            }

            guard let vector1 = embedding1.vector(for: text1),
                  let vector2 = embedding2.vector(for: text2) else {
                return .failure(error: "æ— æ³•ç”Ÿæˆæ–‡æœ¬å‘é‡")
            }

            // è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            var dotProduct: Double = 0
            var norm1: Double = 0
            var norm2: Double = 0

            for i in 0..<min(vector1.count, vector2.count) {
                dotProduct += vector1[i] * vector2[i]
                norm1 += vector1[i] * vector1[i]
                norm2 += vector2[i] * vector2[i]
            }

            let similarity = dotProduct / (sqrt(norm1) * sqrt(norm2))

            return .success(data: [
                "similarity": similarity,
                "interpretation": similarity > 0.8 ? "very similar" :
                                 similarity > 0.6 ? "similar" :
                                 similarity > 0.4 ? "somewhat similar" : "different"
            ])
        } else {
            // iOS 16ä»¥ä¸‹ä½¿ç”¨ç®€å•çš„Jaccardç›¸ä¼¼åº¦
            let words1 = Set(text1.lowercased().components(separatedBy: .whitespacesAndNewlines))
            let words2 = Set(text2.lowercased().components(separatedBy: .whitespacesAndNewlines))

            let intersection = words1.intersection(words2).count
            let union = words1.union(words2).count

            let similarity = union > 0 ? Double(intersection) / Double(union) : 0.0

            return .success(data: [
                "similarity": similarity,
                "method": "jaccard",
                "interpretation": similarity > 0.5 ? "similar" : "different"
            ])
        }
    }

    // MARK: - Text Analysis Tools (4 tools)

    /// Tool: tool.text.sentiment - æƒ…æ„Ÿåˆ†æï¼ˆå¢å¼ºç‰ˆï¼‰
    public static let sentimentAnalysisTool = Tool(
        id: "tool.text.sentiment",
        name: "æƒ…æ„Ÿåˆ†æ",
        description: "åˆ†ææ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼ˆç§¯æ/æ¶ˆæ/ä¸­æ€§ï¼‰ï¼ŒåŒ…å«è¯¦ç»†å¾—åˆ†",
        category: .ai,
        parameters: [
            ToolParameter(name: "text", type: .string, description: "å¾…åˆ†æçš„æ–‡æœ¬", required: true)
        ],
        executor: sentimentAnalysisExecutor
    )

    private static let sentimentAnalysisExecutor: ToolExecutor = { input in
        guard let text = input.getString("text") else {
            return .failure(error: "ç¼ºå°‘æ–‡æœ¬å†…å®¹")
        }

        let tagger = NLTagger(tagSchemes: [.sentimentScore])
        tagger.string = text

        var totalScore: Double = 0
        var sentenceCount = 0

        let tokenizer = NLTokenizer(unit: .sentence)
        tokenizer.string = text

        tokenizer.enumerateTokens(in: text.startIndex..<text.endIndex) { range, _ in
            tagger.string = String(text[range])

            if let tag = tagger.tag(at: tagger.string!.startIndex, unit: .paragraph, scheme: .sentimentScore),
               let score = Double(tag.rawValue) {
                totalScore += score
                sentenceCount += 1
            }

            return true
        }

        let averageScore = sentenceCount > 0 ? totalScore / Double(sentenceCount) : 0

        var sentiment = "neutral"
        var emoji = "ğŸ˜"

        if averageScore > 0.3 {
            sentiment = "positive"
            emoji = averageScore > 0.7 ? "ğŸ˜„" : "ğŸ™‚"
        } else if averageScore < -0.3 {
            sentiment = "negative"
            emoji = averageScore < -0.7 ? "ğŸ˜" : "ğŸ˜•"
        }

        return .success(data: [
            "sentiment": sentiment,
            "score": averageScore,
            "emoji": emoji,
            "sentenceCount": sentenceCount,
            "confidence": abs(averageScore)
        ])
    }

    /// Tool: tool.text.keywords - å…³é”®è¯æå–
    public static let keywordExtractionTool = Tool(
        id: "tool.text.keywords",
        name: "å…³é”®è¯æå–",
        description: "ä»æ–‡æœ¬ä¸­æå–é‡è¦å…³é”®è¯",
        category: .ai,
        parameters: [
            ToolParameter(name: "text", type: .string, description: "å¾…åˆ†æçš„æ–‡æœ¬", required: true),
            ToolParameter(name: "topK", type: .number, description: "è¿”å›å‰Kä¸ªå…³é”®è¯ï¼ˆé»˜è®¤5ï¼‰", required: false)
        ],
        executor: keywordExtractionExecutor
    )

    private static let keywordExtractionExecutor: ToolExecutor = { input in
        guard let text = input.getString("text") else {
            return .failure(error: "ç¼ºå°‘æ–‡æœ¬å†…å®¹")
        }

        let topK = Int(input.getNumber("topK") ?? 5)

        // ä½¿ç”¨è¯æ€§æ ‡æ³¨ç­›é€‰åè¯å’ŒåŠ¨è¯
        let tagger = NLTagger(tagSchemes: [.lexicalClass])
        tagger.string = text

        var wordFrequency: [String: Int] = [:]

        tagger.enumerateTags(in: text.startIndex..<text.endIndex, unit: .word, scheme: .lexicalClass) { tag, range in
            if let tag = tag, (tag == .noun || tag == .verb) {
                let word = String(text[range]).lowercased()
                if word.count > 2 { // è¿‡æ»¤çŸ­è¯
                    wordFrequency[word, default: 0] += 1
                }
            }
            return true
        }

        // æŒ‰é¢‘ç‡æ’åº
        let sortedWords = wordFrequency.sorted { $0.value > $1.value }
        let keywords = Array(sortedWords.prefix(topK)).map { (word: $0.key, frequency: $0.value) }

        return .success(data: [
            "keywords": keywords,
            "count": keywords.count
        ])
    }

    /// Tool: tool.text.summary - æ–‡æœ¬æ‘˜è¦
    public static let textSummaryTool = Tool(
        id: "tool.text.summary",
        name: "æ–‡æœ¬æ‘˜è¦",
        description: "ç”Ÿæˆæ–‡æœ¬çš„ç®€çŸ­æ‘˜è¦",
        category: .ai,
        parameters: [
            ToolParameter(name: "text", type: .string, description: "å¾…æ‘˜è¦çš„æ–‡æœ¬", required: true),
            ToolParameter(name: "sentences", type: .number, description: "æ‘˜è¦å¥å­æ•°ï¼ˆé»˜è®¤3ï¼‰", required: false)
        ],
        executor: textSummaryExecutor
    )

    private static let textSummaryExecutor: ToolExecutor = { input in
        guard let text = input.getString("text") else {
            return .failure(error: "ç¼ºå°‘æ–‡æœ¬å†…å®¹")
        }

        let sentenceCount = Int(input.getNumber("sentences") ?? 3)

        // åˆ†å¥
        let tokenizer = NLTokenizer(unit: .sentence)
        tokenizer.string = text

        var sentences: [String] = []
        tokenizer.enumerateTokens(in: text.startIndex..<text.endIndex) { range, _ in
            sentences.append(String(text[range]))
            return true
        }

        if sentences.isEmpty {
            return .failure(error: "æ— æ³•æå–å¥å­")
        }

        // ç®€å•ç­–ç•¥ï¼šæå–å‰Nå¥ã€ä¸­é—´å¥ã€æœ€åå¥
        var summarySentences: [String] = []

        if sentences.count <= sentenceCount {
            summarySentences = sentences
        } else {
            // é¦–å¥
            summarySentences.append(sentences[0])

            // ä¸­é—´å¥
            if sentenceCount > 2 {
                let midIndex = sentences.count / 2
                summarySentences.append(sentences[midIndex])
            }

            // å°¾å¥
            if sentenceCount > 1 {
                summarySentences.append(sentences[sentences.count - 1])
            }
        }

        let summary = summarySentences.joined(separator: " ")

        return .success(data: [
            "summary": summary,
            "originalSentences": sentences.count,
            "summarySentences": summarySentences.count,
            "compressionRatio": Double(summary.count) / Double(text.count)
        ])
    }

    /// Tool: tool.text.classify - æ–‡æœ¬åˆ†ç±»
    public static let textClassificationTool = Tool(
        id: "tool.text.classify",
        name: "æ–‡æœ¬åˆ†ç±»",
        description: "å¯¹æ–‡æœ¬è¿›è¡Œåˆ†ç±»ï¼ˆéœ€è¦é¢„è®­ç»ƒçš„CoreMLæ¨¡å‹ï¼‰",
        category: .ai,
        parameters: [
            ToolParameter(name: "text", type: .string, description: "å¾…åˆ†ç±»çš„æ–‡æœ¬", required: true),
            ToolParameter(name: "modelPath", type: .string, description: "CoreMLæ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰", required: false)
        ],
        executor: textClassificationExecutor
    )

    private static let textClassificationExecutor: ToolExecutor = { input in
        guard let text = input.getString("text") else {
            return .failure(error: "ç¼ºå°‘æ–‡æœ¬å†…å®¹")
        }

        // ç®€åŒ–å®ç°ï¼šåŸºäºå…³é”®è¯çš„è§„åˆ™åˆ†ç±»
        // ç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨CreateMLè®­ç»ƒçš„æ–‡æœ¬åˆ†ç±»æ¨¡å‹

        let lowerText = text.lowercased()

        var category = "general"
        var confidence = 0.5

        let categories: [String: [String]] = [
            "technology": ["software", "computer", "app", "code", "ai", "ml", "technology", "programming"],
            "business": ["business", "company", "market", "sales", "profit", "revenue", "finance"],
            "sports": ["sports", "game", "player", "team", "match", "score", "championship"],
            "health": ["health", "medical", "doctor", "hospital", "disease", "treatment", "medicine"],
            "entertainment": ["movie", "music", "actor", "singer", "film", "concert", "entertainment"]
        ]

        var maxScore = 0
        for (cat, keywords) in categories {
            let score = keywords.filter { lowerText.contains($0) }.count
            if score > maxScore {
                maxScore = score
                category = cat
                confidence = min(0.95, 0.5 + Double(score) * 0.1)
            }
        }

        return .success(data: [
            "category": category,
            "confidence": confidence,
            "matchedKeywords": maxScore
        ])
    }

    // MARK: - ML Tools (2 tools)

    /// Tool: tool.ml.cluster - æ–‡æœ¬èšç±»
    public static let textClusteringTool = Tool(
        id: "tool.ml.cluster",
        name: "æ–‡æœ¬èšç±»",
        description: "å°†å¤šä¸ªæ–‡æœ¬æŒ‰ç›¸ä¼¼åº¦èšç±»",
        category: .ai,
        parameters: [
            ToolParameter(name: "texts", type: .array, description: "æ–‡æœ¬æ•°ç»„", required: true),
            ToolParameter(name: "clusters", type: .number, description: "èšç±»æ•°é‡ï¼ˆé»˜è®¤3ï¼‰", required: false)
        ],
        executor: textClusteringExecutor
    )

    private static let textClusteringExecutor: ToolExecutor = { input in
        guard let texts = input.getArray("texts") as? [String] else {
            return .failure(error: "ç¼ºå°‘æ–‡æœ¬æ•°ç»„")
        }

        let clusterCount = Int(input.getNumber("clusters") ?? 3)

        if texts.count < clusterCount {
            return .failure(error: "æ–‡æœ¬æ•°é‡å°‘äºèšç±»æ•°é‡")
        }

        // ç®€åŒ–å®ç°ï¼šåŸºäºè¯é¢‘çš„K-meansèšç±»
        // ç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ›´å¤æ‚çš„å‘é‡åŒ–å’Œèšç±»ç®—æ³•

        // 1. æå–æ‰€æœ‰æ–‡æœ¬çš„è¯æ±‡è¡¨
        var vocabulary: Set<String> = []
        for text in texts {
            let words = text.lowercased().components(separatedBy: .whitespacesAndNewlines)
            vocabulary.formUnion(words)
        }

        let vocabArray = Array(vocabulary)

        // 2. å‘é‡åŒ–æ–‡æœ¬ï¼ˆè¯é¢‘å‘é‡ï¼‰
        var vectors: [[Double]] = []
        for text in texts {
            let words = text.lowercased().components(separatedBy: .whitespacesAndNewlines)
            var vector = [Double](repeating: 0, count: vocabArray.count)

            for (index, vocab) in vocabArray.enumerated() {
                vector[index] = Double(words.filter { $0 == vocab }.count)
            }
            vectors.append(vector)
        }

        // 3. ç®€å•K-meansï¼ˆéšæœºåˆå§‹åŒ–ä¸­å¿ƒï¼‰
        var clusterAssignments = [Int](repeating: 0, count: texts.count)
        for i in 0..<texts.count {
            clusterAssignments[i] = i % clusterCount
        }

        var clusteredTexts: [[String: Any]] = []
        for i in 0..<clusterCount {
            let members = texts.enumerated().filter { clusterAssignments[$0.offset] == i }.map { $0.element }
            clusteredTexts.append([
                "clusterId": i,
                "members": members,
                "count": members.count
            ])
        }

        return .success(data: [
            "clusters": clusteredTexts,
            "clusterCount": clusterCount
        ])
    }

    /// Tool: tool.ml.tfidf - TF-IDFè®¡ç®—
    public static let tfidfTool = Tool(
        id: "tool.ml.tfidf",
        name: "TF-IDFè®¡ç®—",
        description: "è®¡ç®—æ–‡æœ¬é›†åˆä¸­è¯è¯­çš„TF-IDFæƒé‡",
        category: .ai,
        parameters: [
            ToolParameter(name: "documents", type: .array, description: "æ–‡æ¡£æ•°ç»„", required: true),
            ToolParameter(name: "topK", type: .number, description: "è¿”å›æ¯ç¯‡æ–‡æ¡£çš„å‰Kä¸ªå…³é”®è¯ï¼ˆé»˜è®¤5ï¼‰", required: false)
        ],
        executor: tfidfExecutor
    )

    private static let tfidfExecutor: ToolExecutor = { input in
        guard let documents = input.getArray("documents") as? [String] else {
            return .failure(error: "ç¼ºå°‘æ–‡æ¡£æ•°ç»„")
        }

        let topK = Int(input.getNumber("topK") ?? 5)

        // 1. è®¡ç®—è¯é¢‘ï¼ˆTFï¼‰
        var documentWords: [[String: Int]] = []
        for doc in documents {
            let words = doc.lowercased().components(separatedBy: .whitespacesAndNewlines).filter { !$0.isEmpty }
            var wordFreq: [String: Int] = [:]
            for word in words {
                wordFreq[word, default: 0] += 1
            }
            documentWords.append(wordFreq)
        }

        // 2. è®¡ç®—æ–‡æ¡£é¢‘ç‡ï¼ˆDFï¼‰
        var documentFrequency: [String: Int] = [:]
        for wordFreq in documentWords {
            for word in wordFreq.keys {
                documentFrequency[word, default: 0] += 1
            }
        }

        let totalDocuments = Double(documents.count)

        // 3. è®¡ç®—TF-IDF
        var results: [[String: Any]] = []

        for (docIndex, wordFreq) in documentWords.enumerated() {
            var tfidfScores: [String: Double] = [:]
            let totalWords = Double(wordFreq.values.reduce(0, +))

            for (word, freq) in wordFreq {
                let tf = Double(freq) / totalWords
                let idf = log(totalDocuments / Double(documentFrequency[word] ?? 1))
                tfidfScores[word] = tf * idf
            }

            // å–å‰Kä¸ª
            let topWords = tfidfScores.sorted { $0.value > $1.value }.prefix(topK)
            let keywords = topWords.map { ["word": $0.key, "score": $0.value] }

            results.append([
                "documentIndex": docIndex,
                "keywords": keywords
            ])
        }

        return .success(data: [
            "results": results,
            "documentCount": documents.count
        ])
    }

    // MARK: - å·¥å…·æ³¨å†Œ

    public static func registerAll() {
        let toolManager = ToolManager.shared

        // NLPå·¥å…· (6ä¸ª)
        toolManager.register(languageDetectionTool)
        toolManager.register(tokenizeTool)
        toolManager.register(nerTool)
        toolManager.register(posTool)
        toolManager.register(lemmaTool)
        toolManager.register(textSimilarityTool)

        // Text Analysiså·¥å…· (4ä¸ª)
        toolManager.register(sentimentAnalysisTool)
        toolManager.register(keywordExtractionTool)
        toolManager.register(textSummaryTool)
        toolManager.register(textClassificationTool)

        // MLå·¥å…· (2ä¸ª)
        toolManager.register(textClusteringTool)
        toolManager.register(tfidfTool)
    }
}
