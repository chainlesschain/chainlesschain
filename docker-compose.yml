version: '3.8'

services:
  # Ollama - 本地LLM服务（CPU版本）
  ollama:
    image: ollama/ollama:latest
    container_name: chainlesschain-ollama
    volumes:
      - ./data/ollama:/root/.ollama
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_MODELS=/root/.ollama/models
    restart: unless-stopped
    networks:
      - chainlesschain-network

  # Qdrant - 向量数据库
  qdrant:
    image: qdrant/qdrant:latest
    container_name: chainlesschain-qdrant
    volumes:
      - ./data/qdrant:/qdrant/storage
    ports:
      - "6333:6333"
      - "6334:6334"
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped
    networks:
      - chainlesschain-network

  # PostgreSQL - 项目元数据数据库
  postgres:
    image: postgres:16-alpine
    container_name: chainlesschain-postgres
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
      - ./backend/project-service/src/main/resources/db/migration:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=chainlesschain
      - POSTGRES_USER=chainlesschain
      - POSTGRES_PASSWORD=chainlesschain_pwd_2024
    restart: unless-stopped
    networks:
      - chainlesschain-network

  # Redis - 缓存和消息队列
  redis:
    image: redis:7-alpine
    container_name: chainlesschain-redis
    volumes:
      - ./data/redis:/data
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --requirepass chainlesschain_redis_2024
    restart: unless-stopped
    networks:
      - chainlesschain-network

  # AI服务 - FastAPI Python服务
  ai-service:
    build:
      context: ./backend/ai-service
      dockerfile: Dockerfile
    container_name: chainlesschain-ai-service
    volumes:
      - ./backend/ai-service:/app
      - ./data/projects:/data/projects
    ports:
      - "8001:8000"
    env_file:
      - ./.env  # 使用项目根目录的 .env 文件
    environment:
      # 基础服务连接
      - OLLAMA_HOST=http://ollama:11434
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - REDIS_HOST=redis
      - REDIS_PASSWORD=chainlesschain_redis_2024
      # LLM配置 - 默认使用云LLM（dashscope），可在.env中配置API Key
      - LLM_PROVIDER=${LLM_PROVIDER:-dashscope}
      - LLM_MODEL=${LLM_MODEL:-qwen-turbo}
      # 云LLM API Keys（从.env文件读取）
      - DASHSCOPE_API_KEY=${DASHSCOPE_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ZHIPU_API_KEY=${ZHIPU_API_KEY:-}
      - VOLCENGINE_API_KEY=${VOLCENGINE_API_KEY:-}
      - QIANFAN_API_KEY=${QIANFAN_API_KEY:-}
      - HUNYUAN_API_KEY=${HUNYUAN_API_KEY:-}
      - SPARK_API_KEY=${SPARK_API_KEY:-}
      - MINIMAX_API_KEY=${MINIMAX_API_KEY:-}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY:-}
    depends_on:
      - ollama
      - qdrant
      - redis
    restart: unless-stopped
    networks:
      - chainlesschain-network

  # 项目服务 - Spring Boot服务
  project-service:
    build:
      context: ./backend/project-service
      dockerfile: Dockerfile
    container_name: chainlesschain-project-service
    volumes:
      - ./data/projects:/data/projects
    ports:
      - "9090:9090"
    environment:
      # Spring Boot标准环境变量
      - SPRING_DATASOURCE_URL=jdbc:postgresql://postgres:5432/chainlesschain
      - SPRING_DATASOURCE_USERNAME=chainlesschain
      - SPRING_DATASOURCE_PASSWORD=chainlesschain_pwd_2024
      - SPRING_DATA_REDIS_HOST=redis
      - SPRING_DATA_REDIS_PORT=6379
      - SPRING_DATA_REDIS_PASSWORD=chainlesschain_redis_2024
      # 自定义环境变量（application.yml中使用）
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=chainlesschain
      - DB_USER=chainlesschain
      - DB_PASSWORD=chainlesschain_pwd_2024
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=chainlesschain_redis_2024
      - AI_SERVICE_URL=http://ai-service:8000
    depends_on:
      - postgres
      - redis
      - ai-service
    restart: unless-stopped
    networks:
      - chainlesschain-network

networks:
  chainlesschain-network:
    driver: bridge

volumes:
  ollama-data:
  qdrant-data:
  postgres-data:
  redis-data:
